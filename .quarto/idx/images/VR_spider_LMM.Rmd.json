{"title":"VR spiders analyses","markdown":{"yaml":{"title":"VR spiders analyses","author":"Stefan Wiens, Dani Cosme, Stephen Pierzchajlo","date":"`r Sys.Date()`","output":{"html_document":{"code_folding":"hide","df_print":"paged","highlight":"tango","theme":"united","toc":"yes","toc_float":{"collapsed":"yes","smooth_scroll":"yes"}}}},"headingText":"'echo = False' hides *all* code chunks below when knitted","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\n#'warning = F' hides *all* warnings messages below when knitted \n#'message = F' hides *all* messages below when knitted \n\nknitr::opts_chunk$set(echo = TRUE, \n                      message = FALSE, \n                      warning = FALSE,\n                      fig.path = \"figures/extra/\",\n                      fig.width=11, fig.height=5)\noptions(scipen = 999)\noptions(repos = list(CRAN=\"http://cran.rstudio.com/\"))\n```\n\n```{r prepare R, echo = FALSE, include = FALSE}\n# clear memory and set random seed\nrm(list = ls()) # clear memory\ngraphics.off()  # clear all plots\ncat(\"\\014\")     # clear console (same as Ctrl-L in console)\n\n# set seed\nset.seed(123)\n```\n\n# load packages\n```{r}\npackages <- c('tidyverse',     # data handling\n              'lmerTest', \n              'modelr',\n              'sjPlot',\n              'kableExtra',\n              'broom.mixed',\n              'gridExtra',\n              'brms',\n              'bayesplot',\n              'rstanarm',\n              'performance',\n              'tidybayes',\n              'brant')    \n# Install packages not yet installed\ninstalled_packages <- packages %in% rownames(installed.packages())\nif (any(installed_packages == FALSE)) {\n  install.packages(packages[!installed_packages], repos = c(CRAN = \"https://cran.rstudio.com\"))\n}\n# Packages loading\ninvisible(lapply(packages, library, character.only = TRUE))\n\npackv <- NULL\nfor (i in 1:length(packages)) {\n  packv = rbind(packv, c(packages[i], as.character(packageVersion(packages[i]))))\n}\ncolnames(packv) <- c(\"Package\", \"Version\") \npackv %>% \n  as_tibble %>% \n  arrange(Package) %>% \n  kable(align = \"l\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n```\n\n# define aesthetics\n```{r}\npalette <- c(\"#ED5C4D\", \"#57B5ED\", \"#FBBE4B\") # control vs each\npalette2 <- c(\"#ED5C4D\", \"#5a4491\") # control vs combined\n\nplot_aes <- theme_minimal() +\n  theme(legend.position = \"top\",\n        text = element_text(size = 20), #, family = \"Helvetica\"), does not work in Win\n        axis.text = element_text(color = \"black\"),\n        axis.line = element_line(colour = \"black\"),\n        axis.ticks.y = element_blank())\n```\n\n# functions\n```{r}\nsource('src/LMM_functions.R')\nsource('src/myround.R')\n\n# 95% confidence intervals\nci95LL <- function(data){return(t.test(data, \n                                      conf.level = 0.95, \n                                      alternative = \"two.sided\")$conf.int[1])}\nci95UL <- function(data){return(t.test(data, \n                                      conf.level = 0.95, \n                                      alternative = \"two.sided\")$conf.int[2])}\n```\n\n# set up directories\n```{r}\n# directory with input EEG log files\ndir_log <- 'data/log'\n# directory with input EEG mean amp files\ndir_meanamps <- 'data/mean_amps'\n```\n\n# check file integrity {.tabset}\nThe experimental groups were **VRET** (virtual reality exposure treatment) and **IVET** (in vivo exposure treatment). Subject numbering started from 1 for the experimental group (without any knowledge of treatment). Thus, in the experimental group, each subject (fp in Swedish) has their unique number. However, subject numbering in the control group also started from 1. Thus, the same ID number (e.g., 1) in the experimental and control group refers to different people. The script handles this by adding 100 to the ID number of the control group. Thus, there is a unique code for each subject.  \n\nBelow, session 1 refers to pre-treatment and session 2 to post-treatment.\n\n## experimental group\n```{r read in experimental group (2 sessions)}\n# according to subject notes\n# vret codes for treatment: 1= vret, 0 = ivet\nfile <- 'data/VR_spider_EEG-EG_final.tsv'\nlistEGnotes <- read.csv(file, sep = '\\t', header = T)\nlistEGnotes$sess1 <- 1\nlistEGnotes$sess1[listEGnotes$pre=='nope'] <- 0\nlistEGnotes$sess2 <- 1\nlistEGnotes$sess2[listEGnotes$post=='nope'] <- 0\n\n# EG according to EEG log files\nfps <- list.files(file.path(dir_log,'experimental'), pattern = 'fp')\nlistEGlog <- data.frame()\nfor (f in fps){ # f = fps[6]\n  fp <- substring(f, first = 3)\n  sess <- as.integer(substring(fp, first = regexpr('_',fp)[1]+1))\n  fp <- as.integer(substring(fp, first = 1, last = regexpr('_',fp)[1]-1))\n  listEGlog <- rbind(listEGlog, cbind(fp,sess))\n}\nrm(f,fp,fps,sess,file)\n\n# EG according to EEG mean amps\nfps <- list.files(file.path(dir_meanamps), pattern = 'fp')\nlistamps <- data.frame()\nfor (f in fps){ # f = fps[6]\n  fp <- substring(f, first = 3, last = 11)\n  sess <- as.integer(substring(fp, first = regexpr('_ses', fp)[1]+4))\n  fp <- as.integer(substring(fp, first = 1, last = 3))\n  listamps <- rbind(listamps, cbind(fp,sess))\n}\nlistEGamps <- listamps %>% filter(fp < 100)\nrm(f,fp,fps,sess)\n\n# check subject match between EEG amps and log\n# session 1\nif (setequal(listEGamps$fp[listEGamps$sess==1], listEGlog$fp[listEGlog$sess==1])!=T){\n  print('EG: Mismatch between EEG amps and log files: Session 1')\n  print('Unique in EEG amps')\n  print(setdiff(listEGamps$fp[listEGamps$sess==1], listEGlog$fp[listEGlog$sess==1]))\n  print('Unique in EEG log')\n  print(setdiff(listEGlog$fp[listEGlog$sess==1], listEGamps$fp[listEGamps$sess==1]))\n  stop('EG: mismatch between EEG amps and log files: Session 1')\n}\n# session 2\nif (setequal(listEGamps$fp[listEGamps$sess==2], listEGlog$fp[listEGlog$sess==2])!=T){\n  print('EG: Mismatch between EEG amps and log files: Session 2')\n  print('Unique in EEG amps')\n  print(setdiff(listEGampsfp[listEGamps$sess==2], listEGlog$fp[listEGlog$sess==2]))\n  print('Unique in EEG log')\n  print(setdiff(listEGlog$fp[listEGlog$sess==2], listEGamps$fp[listEGamps$sess==2]))\n  stop('EG: Mismatch between EEG amps and log files: Session 2')\n}\n\n# check subject match between notes and EEG log\n# session 1\nif (setequal(listEGnotes$fp[listEGnotes$sess1==1], listEGlog$fp[listEGlog$sess==1])!=T){\n  print('EG: Mismatch between notes and EEG log files: Session 1')\n  print('Unique in notes')\n  print(setdiff(listEGnotes$fp[listEGnotes$sess1==1], listEGlog$fp[listEGlog$sess==1]))\n  print('Unique in EEG log')\n  print(setdiff(listEGlog$fp[listEGlog$sess==1], listEGnotes$fp[listEGnotes$sess1==1]))\n  stop('EG: Mismatch between notes and EEG log files: Session 1')\n}\n# session 2\nif (setequal(listEGnotes$fp[listEGnotes$sess2==1], listEGlog$fp[listEGlog$sess==2])!=T){\n  print('EG: Mismatch between notes and EEG log files: Session 2')\n  print('Unique in notes')\n  print(setdiff(listEGnotes$fp[listEGnotes$sess2==1], listEGlog$fp[listEGlog$sess==2]))\n  print('Unique in EEG log')\n  print(setdiff(listEGlog$fp[listEGlog$sess==2], listEGnotes$fp[listEGnotes$sess2==1]))\n  stop('EG: Mismatch between notes and EEG log files: Session 2')\n}\n# make notes list the gold standard----\nrm(listEGlog, listEGamps)\n```\n\n## control group\n```{r read and check subjects in control group (only 1 session)}\n# The same ID number (e.g., 1) in the experimental and control group refers to different people. The script handles this by adding 100 to the ID number of the control group. Thus, there is a unique code for each subject.\n\n# according to subject notes\nfile <- 'data/VR_spider_EEG-CG_final.tsv'\nlistCGnotes <- read.csv(file, sep = '\\t', header = T)\nlistCGnotes$fp <- listCGnotes$fp + 100 # add 100 to create a unique code\n\n# CG according to EEG log files\nfps <- list.files(file.path(dir_log,'control'), pattern = 'fp')\nlistCGlog <-  data.frame()\nfor (f in fps){ # f = fps[6]\n  fp <- as.integer(substring(f, first = 3))\n  listCGlog <- rbind(listCGlog, cbind(fp))\n}\nlistCGlog$fp <- listCGlog$fp + 100 # add 100 to create a unique code\n\n# CG according to EEG mean amps\n# (data already read in for EG above)\nlistCGamps <- listamps %>% \n  filter(fp >= 100) %>% \n  select(-sess)\n\n# check subject match between EEG amps and log\nif (setequal(listCGamps$fp, listCGlog$fp)!=T){\n  print('CG: Mismatch between EEG amps and log files')\n  print('Unique in EEG amps')\n  print(setdiff(listCGamps$fp, listCGlog$fp))\n  print('Unique in EEG log')\n  print(setdiff(listCGlog$fp,listCGamps$fp))\n  stop('CG: Mismatch between EEG amps and log files')\n}\n\n# check subject match between notes and EEG log\nif (setequal(listCGnotes$fp, listCGlog$fp)!=T){\n  print('CG: Mismatch between notes and EEG log files')\n  print('Unique in notes')\n  print(setdiff(listCGnotes$fp, listCGlog$fp))\n  print('Unique in EEG log')\n  print(setdiff(listCGlog$fp, listCGnotes$fp))\n  stop('Mismatch between notes and EEG log files: Control group')\n}\n\n# make notes list the gold standard----\nrm(listCGlog, listCGamps)\n```\n\n# demographics\nDemographics are in the data files only for the control group.  \n\nMean (SD) of age = `r myround(mean(listCGnotes$age),1)` (`r myround(sd(listCGnotes$age),2)`).  \n\n```{r}\nlistCGnotes %>% \n  count(gender) %>% \n  mutate(gender = case_when(gender == 'f' ~ 'female',\n                            gender == 'm' ~ 'male')) %>% \n\n  kable(align = \"c\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n```\nHandedness:\n```{r}\nlistCGnotes %>% \n  count(handedness) %>% \n  mutate(handedness = case_when(handedness == 'l' ~ 'left',\n                                handedness == 'r' ~ 'right')) %>% \n  kable(align = \"c\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n```\n\n# detection task: questionnaire {.tabset}\nAfter the detection task (with EEG), subjects filled in a questionnaire.  \n\nQuestions:  \nQ1) Task focus: 'How much did you focus on the fixation cross? 1=never, 9=always  \nQ2) Flash visible: 'How easy to see the flash?' 1=difficult, 9=easy  \nQ3) Spiders distract: 'How distracted were you by spiders?' 1=little, 9=lots  \nQ4) Nonspiders distract: 'How distracted were you by nonspiders?' 1=little, 9=lots  \nQ5) Task easy: 'How easy was the task?' 1=difficult, 9=easy  \n```{r read questionnaire data about detection task}\n# experimental\nfile <- 'data/detection_que_experimental.tsv'\ntmpque <- read.csv(file, skip = 0, sep = '\\t', header = T)\n# sess 1\ntmp <- sort(intersect(listEGnotes$fp[listEGnotes$sess1==1],tmpque$fp[tmpque$sess==1]))\nnote1 <- paste0('EG Session 1: n = ', length(setdiff(listEGnotes$fp[listEGnotes$sess1==1], tmp)))\nQueDetect <- tmpque[tmpque$fp %in% tmp & tmpque$sess == 1,]\n# sess 2\ntmp <- sort(intersect(listEGnotes$fp[listEGnotes$sess2==1],tmpque$fp[tmpque$sess==2]))\nnote2 <- paste0('EG Session 2: n = ', length(setdiff(listEGnotes$fp[listEGnotes$sess2==1], tmp)))\nQueDetect <- rbind(QueDetect, tmpque[tmpque$fp %in% tmp & tmpque$sess == 2,])\nQueDetect$treat <- 'IVET'\ntmp <- listEGnotes$fp[listEGnotes$vret==1]\nQueDetect$treat[QueDetect$fp %in% tmp] = 'VRET'\n\n# control\nfile <- 'data/detection_que_control.tsv'\ntmpque <- read.csv(file, skip = 0, sep = '\\t', header = T) \ntmpque$fp <- tmpque$fp + 100 # add 100 to get unique ID codes\ntmp = sort(intersect(listCGnotes$fp, tmpque$fp))\nnote3 = paste0('CG: n = ', length(setdiff(listCGnotes$fp, tmp)))\ntmpque = tmpque[tmpque$fp %in% tmp,]\ntmpque$treat = 'Control'\nQueDetect = rbind(QueDetect, tmpque)\nrownames(QueDetect) = NULL\nQueDetect$sess = QueDetect$sess - 1 # recode to session 0 and 1\nQueDetect$treat = factor(QueDetect$treat, levels=c('Control', 'IVET', 'VRET'))\n\ndataque <- QueDetect %>%\n    pivot_longer(cols = c(q1, q2, q3, q4, q5), names_to = 'que', values_to = 'dv') %>% \n    mutate(fp = as.character(fp))\n\n# check that answers range between 1 and 9\ndataque %>% \n  summarise(min_dv = min(dv),\n            max_dv = max(dv), \n            .groups = 'drop') %>% \n  as.numeric() %>% \n  identical(c(1,9)) %>% \n  isFALSE() %>% \n  {if(.)(stop(\"Error: Answers min and max are not 1 and 9, respectively!\"))}\n```\n\n```{r, export que tsv}\nwrite_tsv(dataque, file.path('results/dataque.tsv'))\n```\n\n## sample size\nData are almost complete except that four subjects (not from one particular group) have missing questionnaire data. These subjects are from these groups:  \n\n* `r note1`\n* `r note2`\n* `r note3`\n\nThe variables `Pre` and `Post` show the number of participants in each. The variable `Both` shows how many of these subjects participated in both sessions. These are not additional subjects. If one wants to know the number of participants only in `Pre`, compute `Pre` minus `Both`.\n```{r}\ntmptable <- dataque %>% \n  group_by(fp) %>% \n  slice(1) %>% \n  select(fp, treat) %>% \n  group_by(treat) %>% \n  summarise(N = n(), .groups = 'drop') %>% \n  rename(\"Treatment\" = treat)\ntmptable <- dataque %>%\n  select(fp, sess, treat) %>%\n  unique() %>%\n  group_by(sess, treat) %>%\n  mutate(sess = ifelse(sess==0, 'Pre', 'Post'),\n         sess = factor(sess, levels = c('Pre', 'Post'))) %>% \n  summarise(n = n(), .groups = 'drop') %>% # grouping is dropped \n  pivot_wider(names_from = sess, values_from = n) %>%\n  mutate_if(is.numeric, ~ ifelse(is.na(.), \"--\", .)) %>% \n  cbind(tmptable, .) %>% \n  select(-treat)\ntmps1I <- dataque %>%\n  filter(treat == 'IVET',\n         sess == 0) %>%\n  distinct(., fp) %>% \n  pull()\ntmps1V <- dataque %>%\n  filter(treat == 'VRET',\n         sess == 0) %>%\n  distinct(., fp) %>% \n  pull()\ntmps2I <- dataque %>%\n  filter(treat == 'IVET',\n         sess == 1) %>%\n  distinct(., fp) %>% \n  pull()\ntmps2V <- dataque %>%\n  filter(treat == 'VRET',\n         sess == 1) %>%\n  distinct(., fp) %>% \n  pull()\ntmptable$'Both' = c('--', length(intersect(tmps1I, tmps2I)), length(intersect(tmps1V, tmps2V)))\ntmptable %>%\n  kable(align = \"c\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\nrm(tmptable, tmps1I, tmps1V, tmps2I, tmps2V)\n```\n\n## descriptives\nThe table shows means (*SD* in parentheses).  \n```{r Questionnaire Detect data}\ndataque %>%\n  mutate(sess = ifelse(sess==0, 'pre', 'post'),\n         sess = factor(sess, levels = c('pre', 'post'))) %>% \n  group_by(sess, treat, que) %>%\n  summarise(m_sd = sprintf(\"%.2f (%.2f)\", mean(dv, na.rm = TRUE),\n            sd(dv, na.rm = TRUE)), .groups = 'drop') %>%\n  # grouping is dropped\n  pivot_wider(names_from = que, values_from = m_sd) %>%\n  rename(\"Treatment\" = treat,\n         \"Session\" = sess,\n         \"Task focus\" = q1,\n         \"Flash visible\" = q2,\n         \"Spiders distract\" = q3,\n         \"Nonspiders distract\" = q4,\n         \"Task easy\" = q5) %>%\n  arrange(Treatment, Session) %>%\n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n## session 1 across treatments {.tabset}\n* standard regression model (no repeated measures)\n* use session 1 from all three groups\n* combine treatment groups\n* no plots because the comparison involves two means (treatment vs. control). The *B* in the table shows the mean difference.    \n\n### Q1\nTask focus: 'How much did you focus on the fixation cross? 1=never, 9=always  \n\nNote that the intercept shows the mean score for Controls in Session 1.  \n\nResult: The (combined) treatment group tended to be less focused on the cross. Makes sense because in Q3, they rated to be more distracted by spiders.  \n```{r}\nmylabels = c('treatment (Control)',\n             'treatment (VRET/IVET)')\nmodel_name = \"quedetect_q1_acrosstreatment\"\nmodel_formula = formula(\"dv ~ 1 + treat\")\n# fp is not included because each subject contributes one data point\ndata <- dataque %>%\n  filter(sess == 0) %>%\n  filter(que == 'q1') %>%\n  mutate(treat = ifelse(treat == 'Control', 'Control', 'VRET/IVET'),   \n         treat = factor(treat, levels = c(\"Control\", \"VRET/IVET\")))\nassign(get(\"model_name\"), lm(model_formula, data = data))\ntable_model(get(model_name),\n           dv_labels = \"Task focus\",\n           pred_labels = mylabels)\n```\n\n### Q2\nFlash visible: 'How easy to see the flash?' 1=difficult, 9=easy  \n```{r}\nmodel_name = \"quedetect_q2_acrosstreatment\"\nmodel_formula = formula(\"dv ~ 1 + treat\")\ndata <- dataque %>%\n  filter(sess == 0) %>%\n  filter(que == 'q2') %>%\n  mutate(treat = ifelse(treat == 'Control', 'Control', 'VRET/IVET'),   \n         treat = factor(treat, levels = c(\"Control\", \"VRET/IVET\")))\nassign(get(\"model_name\"), lm(model_formula, data = data))\ntable_model(get(model_name),\n           dv_labels = \"Flash visible\",\n           pred_labels = mylabels)\n```\n\n### Q3\nSpiders distract: 'How distracted were you by spiders?' 1=little, 9=lots  \n\nResult: The treatment group rated to be much more distracted by spiders.  \n```{r}\nmodel_name = \"quedetect_q3_acrosstreatment\"\nmodel_formula = formula(\"dv ~ 1 + treat\")\ndata <- dataque %>%\n  filter(sess == 0) %>%\n  filter(que == 'q3') %>%\n  mutate(treat = ifelse(treat == 'Control', 'Control', 'VRET/IVET'),   \n         treat = factor(treat, levels = c(\"Control\", \"VRET/IVET\")))\nassign(get(\"model_name\"), lm(model_formula, data = data))\ntable_model(get(model_name),\n           dv_labels = \"Spiders distract\",\n           pred_labels = mylabels)\n```\n\n### Q4\nNonspiders distract: 'How distracted were you by nonspiders?' 1=little, 9=lots  \n```{r}\nmodel_name = \"quedetect_q4_acrosstreatment\"\nmodel_formula = formula(\"dv ~ 1 + treat\")\ndata <- dataque %>%\n  filter(sess == 0) %>%\n  filter(que == 'q4') %>%\n  mutate(treat = ifelse(treat == 'Control', 'Control', 'VRET/IVET'),   \n         treat = factor(treat, levels = c(\"Control\", \"VRET/IVET\")))\nassign(get(\"model_name\"), lm(model_formula, data = data))\ntable_model(get(model_name),\n           dv_labels = \"Nonspiders distract\",\n           pred_labels = mylabels)\n```\n\n### Q3 vs Q4\nMeasure distraction by spiders versus nonspiders. That is, compute Q3 minus Q4 for each subject. Positive values mean that the subject reported being more distracted by spiders than nonspiders.  \n\nResult: Compared to controls, the treatment groups reported more distraction by spiders (vs. nonspiders) in session 1.  \n\n```{r}\nmodel_name = \"quedetect_q34_acrosstreatment\"\nmodel_formula = formula(\"dv ~ 1 + treat\")\ndata <- QueDetect %>%\n  filter(sess == 0) %>%\n  mutate(dv = q3 - q4) %>%\n  select(fp, sess, treat, dv) %>%\n  mutate(treat = ifelse(treat == 'Control', 'Control', 'VRET/IVET'),   \n         treat = factor(treat, levels = c(\"Control\", \"VRET/IVET\")))\nassign(get(\"model_name\"), lm(model_formula, data = data))\ntable_model(get(model_name),\n           dv_labels = \"Distract spiders minus nonspiders\",\n           pred_labels = mylabels)\n```\n\n### Q5\nTask easy: 'How easy was the task?' 1=difficult, 9=easy  \n```{r}\nmodel_name = \"quedetect_q5_acrosstreatment\"\nmodel_formula = formula(\"dv ~ 1 + treat\")\ndata <- dataque %>%\n  filter(sess == 0) %>%\n  filter(que == 'q5') %>%\n  mutate(treat = ifelse(treat == 'Control', 'Control', 'VRET/IVET'),   \n         treat = factor(treat, levels = c(\"Control\", \"VRET/IVET\")))\nassign(get(\"model_name\"), lm(model_formula, data = data))\ntable_model(get(model_name),\n           dv_labels = \"Task easy\",\n           pred_labels = mylabels)\n```\n\n## treatment comparison {.tabset}\n* MLM model\n* session 1 and session 2 (session 1 as reference)\n* include only treatment groups\n* IVET = -.5, VRET = .5\n\n### Q1 {.tabset}\nTask focus: 'How much did you focus on the fixation cross? 1=never, 9=always  \n\n#### model\n```{r}\nmylabels = c('treatment (VRET/IVET) / session (1)',\n             'treatment (VRET vs IVET) /  session (1)', \n             'treatment (VRET/IVET) / session (2)', \n             'treatment (VRET vs IVET) / session (2)')\nmodel_name = \"quedetect_q1_treatment\"\nmodel_formula = formula(\"dv ~ 1 + treat*sess + (1 | fp)\")\ndata <- dataque %>%\n  filter(!treat == 'Control') %>%\n  filter(que == 'q1') %>%\n  mutate(treat =  ifelse(as.character(treat) == \"IVET\", -.5, .5))\n#recode treatment as -.5 and .5\nassign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                         control = lmerControl(optimizer = \"bobyqa\",  \n                                                               optCtrl = list(maxfun = 1e5)),\n                                         data = data))\ntable_model(get(model_name),\n            dv_labels = \"Task focus\",\n            pred_labels = mylabels)\n```\n\n#### plot\n```{r, fig.width=11, fig.height=5}\nggeffects::ggpredict(get(model_name), c(\"treat\", \"sess\")) %>%\n  data.frame() %>%\n  mutate(group = ifelse(group == 0, 'pre', 'post'),\n         group = factor(group, levels = c('pre', 'post')),\n         x = ifelse(x == -.5, \"IVET\", \"VRET\")) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  scale_color_manual(values = palette[2:3], name = \"treatment\") +\n  labs(y = \"predicted rating\\n\", x = \"\\nsession\") +\n  plot_aes\n```\n\n### Q2 {.tabset}\nFlash visible: 'How easy to see the flash?' 1=difficult, 9=easy  \n\nResult: The interaction suggests that IVET rated the flash as more visible during session 1 than 2, whereas VRET rated the opposite. This effect does not seem meaningful.  \n\n#### model\n```{r}\nmodel_name = \"quedetect_q2_treatment\"\nmodel_formula = formula(\"dv ~ 1 + treat*sess + (1 | fp)\")\ndata <- dataque %>%\n  filter(!treat == 'Control') %>%\n  filter(que == 'q2') %>%\n  mutate(treat =  ifelse(as.character(treat) == \"IVET\", -.5, .5))\n#recode treatment as -.5 and .5\nassign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                         control = lmerControl(optimizer = \"bobyqa\",  \n                                                               optCtrl = list(maxfun = 1e5)),\n                                         data = data))\ntable_model(get(model_name),\n            dv_labels = \"Flash visible\",\n            pred_labels = mylabels)\n```\n\n#### plot\n```{r, fig.width=11, fig.height=5}\nggeffects::ggpredict(get(model_name), c(\"treat\", \"sess\")) %>%\n  data.frame() %>%\n  mutate(group = ifelse(group == 0, 'pre', 'post'),\n         group = factor(group, levels = c('pre', 'post')),\n         x = ifelse(x == -.5, \"IVET\", \"VRET\")) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  scale_color_manual(values = palette[2:3], name = \"treatment\") +\n  labs(y = \"predicted rating\\n\", x = \"\\nsession\") +\n  plot_aes\n```\n\n### Q3 {.tabset}\nSpiders distract: 'How distracted were you by spiders?' 1=little, 9=lots  \n\nResult: The treatment groups rated less distraction by spiders in session 2 than 1.  \nSee also the Q3 vs Q4 that uses the nonspiders as controls.\n\n#### model\n```{r}\nmodel_name = \"quedetect_q3_treatment\"\nmodel_formula = formula(\"dv ~ 1 + treat*sess + (1 | fp)\")\ndata <- dataque %>%\n  filter(!treat == 'Control') %>%\n  filter(que == 'q3') %>%\n  mutate(treat =  ifelse(as.character(treat) == \"IVET\", -.5, .5))\n#recode treatment as -.5 and .5\nassign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                         control = lmerControl(optimizer = \"bobyqa\",  \n                                                               optCtrl = list(maxfun = 1e5)),\n                                         data = data))\ntable_model(get(model_name),\n            dv_labels = \"Spider distract\",\n            pred_labels = mylabels)\n```\n\n#### plot\n```{r, fig.width=11, fig.height=5}\nggeffects::ggpredict(get(model_name), c(\"treat\", \"sess\")) %>%\n  data.frame() %>%\n  mutate(group = ifelse(group == 0, 'pre', 'post'),\n         group = factor(group, levels = c('pre', 'post')),\n         x = ifelse(x == -.5, \"IVET\", \"VRET\")) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  scale_color_manual(values = palette[2:3], name = \"treatment\") +\n  labs(y = \"predicted rating\\n\", x = \"\\nsession\") +\n  plot_aes\n```\n\n### Q4 {.tabset}\nNonspiders distract: 'How distracted were you by nonspiders?' 1=little, 9=lots  \n\n#### model\n```{r}\nmodel_name = \"quedetect_q4_treatment\"\nmodel_formula = formula(\"dv ~ 1 + treat*sess + (1 | fp)\")\ndata <- dataque %>%\n  filter(!treat == 'Control') %>%\n  filter(que == 'q4') %>%\n  mutate(treat =  ifelse(as.character(treat) == \"IVET\", -.5, .5))\n#recode treatment as -.5 and .5\nassign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                         control = lmerControl(optimizer = \"bobyqa\",  \n                                                               optCtrl = list(maxfun = 1e5)),\n                                         data = data))\ntable_model(get(model_name),\n            dv_labels = \"Nonspiders distract\",\n            pred_labels = mylabels)\n```\n\n#### plot\n```{r, fig.width=11, fig.height=5}\nggeffects::ggpredict(get(model_name), c(\"treat\", \"sess\")) %>%\n  data.frame() %>%\n  mutate(group = ifelse(group == 0, 'pre', 'post'),\n         group = factor(group, levels = c('pre', 'post')),\n         x = ifelse(x == -.5, \"IVET\", \"VRET\")) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  scale_color_manual(values = palette[2:3], name = \"treatment\") +\n  labs(y = \"predicted rating\\n\", x = \"\\nsession\") +\n  plot_aes\n```\n\n### Q3 vs Q4 {.tabset}\nMeasure distraction by spiders versus nonspiders. That is, compute Q3 minus Q4 for each subject.  \nPositive values mean that the subject reported being more distracted by spiders than nonspiders.  \n\nResult: The treatment groups rated less distraction by spiders (vs. nonspiders) in session 2 than 1.  \n\n#### model\n```{r}\nmodel_name = \"quedetect_q34_treatment\"\nmodel_formula = formula(\"dv ~ 1 + treat*sess + (1 | fp)\")\ndata <- QueDetect %>%\n  filter(!treat == 'Control') %>%\n  mutate(dv = q3 - q4) %>%\n  select(fp, sess, treat, dv) %>%\n  mutate(treat =  as.numeric(ifelse(as.character(treat) == \"IVET\", -.5, .5)))\n#recode treatment as -.5 and .5\nassign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                         control = lmerControl(optimizer = \"bobyqa\",  \n                                                               optCtrl = list(maxfun = 1e5)),\n                                         data = data))\ntable_model(get(model_name),\n            dv_labels = \"Distract spiders minus nonspiders\",\n            pred_labels = mylabels)\n```\n\n#### plot\n```{r, fig.width=11, fig.height=5}\nggeffects::ggpredict(get(model_name), c(\"treat\", \"sess\")) %>%\n  data.frame() %>%\n  mutate(group = ifelse(group == 0, 'pre', 'post'),\n         group = factor(group, levels = c('pre', 'post')),\n         x = ifelse(x == -.5, \"IVET\", \"VRET\")) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  scale_color_manual(values = palette[2:3], name = \"treatment\") +\n  labs(y = \"predicted rating\\n\", x = \"\\nsession\") +\n  plot_aes\n```\n\n### Q5 {.tabset}\nTask easy: 'How easy was the task?' 1=difficult, 9=easy  \n\nResult: The treatment groups rated the task as easier during session 2 than 1.  \n\n#### model\n```{r}\nmodel_name = \"quedetect_q5_treatment\"\nmodel_formula = formula(\"dv ~ 1 + treat*sess + (1 | fp)\")\ndata <- dataque %>%\n  filter(!treat == 'Control') %>%\n  filter(que == 'q5') %>%\n  mutate(treat =  ifelse(as.character(treat) == \"IVET\", -.5, .5))\n#recode treatment as -.5 and .5\nassign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                         control = lmerControl(optimizer = \"bobyqa\",  \n                                                               optCtrl = list(maxfun = 1e5)),\n                                         data = data))\ntable_model(get(model_name),\n            dv_labels = \"Task easy\",\n            pred_labels = mylabels)\n```\n\n#### plot\n```{r, fig.width=11, fig.height=5}\nggeffects::ggpredict(get(model_name), c(\"treat\", \"sess\")) %>%\n  data.frame() %>%\n  mutate(group = ifelse(group == 0, 'pre', 'post'),\n         group = factor(group, levels = c('pre', 'post')),\n         x = ifelse(x == -.5, \"IVET\", \"VRET\")) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  scale_color_manual(values = palette[2:3], name = \"treatment\") +\n  labs(y = \"predicted rating\\n\", x = \"\\nsession\") +\n  plot_aes\nrm(list=ls(pattern='quedetect'))\n```\n\n\n# sample size\n```{r}\nNall = sum(c(nrow(listCGnotes),listEGnotes$sess1,listEGnotes$sess2))\n```\n\nThe total number of recordings is **`r Nall`**.  A recording comprises data from two tasks of a single subject in a single session.  \n\n* Detection task (with EEG): Subjects detected flashing of the central fixation cross.  \n* Rating task: Subjects rated each picture on arousal and pleasantness. (Note that pleasantness is recoded below to unpleasantness.)  \n\nThe table shows the number of subjects in the three groups.  \n\nThe variable *Both* shows how many subjects participated in both sessions. So, these are not additional subjects.  \n```{r}\ntmptable <- listEGnotes %>%\n  select(vret, sess1, sess2) %>%\n  mutate(sess12 = ifelse(sess1==1 & sess2==1, 1, 0)) %>%\n  group_by(vret, sess1, sess2, sess12) %>%\n  summarise(n = n(), .groups = 'drop') # grouping is dropped \ntmpd = data.frame(Treatment = c('Control','IVET','VRET'),\n                  N = c(nrow(listCGnotes), \n                        length(listEGnotes$fp[listEGnotes$vret==0]),\n                        length(listEGnotes$fp[listEGnotes$vret==1])),\n                  S1 = c(nrow(listCGnotes), \n                         tmptable$n[2]+tmptable$n[3], \n                         tmptable$n[5]+tmptable$n[6]),\n                  S2 = c('--', \n                         tmptable$n[1]+tmptable$n[3], \n                         tmptable$n[4]+tmptable$n[6]),\n                  Both = c('--', tmptable$n[3], tmptable$n[6]))\ntmpd %>%\n  rename(\"Pre\" = `S1`,\n         \"Post\" = `S2`) %>%\n  kable(align = \"c\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\nrm(tmptable, tmpd)\n```\n\n# read rating/EEG data {.tabset}\nRead in the data from the detection task (with EEG) and the rating data from the rating task.\n\n## experimental group\n```{r read behavioral and mean EEG data per trial in experimental group}\n# experimental group\nfps <- c(listEGnotes$fp[listEGnotes$sess1==1], \n        listEGnotes$fp[listEGnotes$sess2==1])\nses <- as.integer(c(listEGnotes$sess1[listEGnotes$sess1==1], \n                   listEGnotes$sess2[listEGnotes$sess2==1]*2))\nvr <- as.integer(c(listEGnotes$vret[listEGnotes$sess1==1],\n                  listEGnotes$vret[listEGnotes$sess2==1]))\nRawDetect<- data.frame()\nRawRate <- data.frame()\nfor (f in 1:length(fps)){ # f = 3\n  \n  # read in detection behavioral data----\n  file <- file.path(dir_log,'experimental',sprintf('fp%s_%s/DATA_SpVR_%s_%s.txt',\n                                                  fps[f],ses[f],fps[f], ses[f]))\n  if (file.exists(file)){\n    tmp <- read.csv(file, skip = 10, sep = '\\t', header = F)[,1:13]\n    # header = T did not work because of an extra tab at the end of each row\n    colnames(tmp) <-  c('Trial',\t'Code',\t'Targ',\t'Gap',\t'Emo',\t'Pind',\t'Pcode',\n                       'PicOn',\t'ProbeOn',\t'NumResp',\t'RespOn',\t'Logcode',\t'PPTcode')\n    if (nrow(tmp) != 200){\n      print(file)\n      stop('Not 200 trials per session!')\n    }\n  }\n  \n  # read in detection EEG data----\n  # Trial\tfp\tses\tcond\tEPN\tLPP\tbad\n  file <- file.path(dir_meanamps,sprintf('fp%03.0f_ses%02.0f.tsv',\n                                          fps[f],ses[f]))\n  if (file.exists(file)){\n    tmp2 <- read.csv(file, sep = '\\t', header = T)\n    \n    if (identical(rep(fps[f],length(tmp2$fp)), as.integer(tmp2$fp)) == F){\n      print(file)\n      stop('Subject id does not match!')\n    }\n    if (identical(rep(ses[f],length(tmp2$fp)), as.integer(tmp2$ses)) == F){\n      print(file)\n      stop('Session number does not match!')\n    }\n    \n    # Some subjects had a trial missing in EEG\n    # apparently, no code was sent to the EEG\n    # fix these data\n    # Note: earlier file versions had trialonset as a variable\n    #tmp2$diff[2:length(tmp2$trialonset)] = diff(tmp2$trialonset, lag = 1)\n    # I used the timing difference to find which trial was missing\n    if (fps[f] == 13 & ses[f] == 1){\n      # trial 172 is missing; skip this trial\n      tmp2$Trial[172:199] <- 173:200\n      tmp2 <- rbind(tmp2, c(172,13,1,'pos/notarget',NA,NA,NA,NA,NA,NA,NA,NA,1))\n      tmp2 <- tmp2[order(as.numeric(tmp2$Trial)),]\n    }\n    if (fps[f] == 15 & ses[f] == 2){\n      # trial 140 is missing; skip this trial\n      tmp2$Trial[140:199] <- 141:200\n      tmp2 <- rbind(tmp2, c(140,15,1,'pos/notarget',NA,NA,NA,NA,NA,NA,NA,NA,1))\n      tmp2 <- tmp2[order(as.numeric(tmp2$Trial)),]\n    }\n    if (fps[f] == 71 & ses[f] == 1){\n      # trial 30 is missing; skip this trial\n      tmp2$Trial[30:199] <- 31:200\n      tmp2 <- rbind(tmp2, c(30,71,1,'neg/notarget',NA,NA,NA,NA,NA,NA,NA,NA,1))\n      tmp2 <- tmp2[order(as.numeric(tmp2$Trial)),]\n    }\n    \n    # Emo: 1=spi, 2=unpleasant, 3=neutral, 4=pleasant\n    tmp2$Emo <- NA\n    tmp2$Emo[grepl('spi', tmp2$cond)] <- 1\n    tmp2$Emo[grepl('neg', tmp2$cond)] <- 2\n    tmp2$Emo[grepl('neu', tmp2$cond)] <- 3\n    tmp2$Emo[grepl('pos', tmp2$cond)] <- 4\n    \n    tmp2$Targ <- 0\n    tmp2$Targ[grepl('/target', tmp2$cond)] <- 1\n    \n    if (nrow(tmp2) != 200){\n      print(file)\n      stop('Not 200 trials per session!')\n    }\n    if (identical(tmp$Emo, as.integer(tmp2$Emo)) == F){\n      print(file)\n      stop('Emotion codes do not match!')\n    }\n    if (identical(tmp$Targ, as.integer(tmp2$Targ)) == F){\n      print(file)\n      stop('Target trials do not match!')\n    }\n    \n    # copy mean amps\n    tmp$EPN <- as.numeric(tmp2$EPN_average)\n    tmp$LPP <- as.numeric(tmp2$LPP_average)\n    tmp$bad <- as.numeric(tmp2$bad)\n    \n    tmp$fp <- fps[f]\n    tmp$sess <- ses[f]-1 # code session as 0 and 1\n    tmp$treat <- ifelse(vr[f] == 1, 'VRET', 'IVET')\n    \n    RawDetect <- rbind(RawDetect, tmp)\n    rm(tmp, tmp2)\n  }\n  \n  # read in rating data----\n  file <- file.path(dir_log,'experimental',sprintf('fp%s_%s/DATA_SpVRrate_%s_%s.txt',\n                                                  fps[f],ses[f],fps[f],ses[f]))\n  if (file.exists(file)){\n    tmp <- read.csv(file, skip = 5, sep = '\\t', header = T)[-c(1:4),]\n    # delete practice rows\n    if (nrow(tmp) != 40){\n      print(file)\n      stop('Not 40 trials per session!')\n    }\n    tmp$fp <- fps[f]\n    tmp$sess <- ses[f]-1\n    tmp$treat <- ifelse(vr[f] == 1, 'VRET', 'IVET')\n    RawRate <- rbind(RawRate, tmp)\n  }\n}\nrm(fps,tmp,file,f,ses,vr)\n```\n\n## control group\n```{r read behavioral and mean EEG data per trial in control group}\n# control group\nfps <- listCGnotes$fp\nfor (f in 1:length(fps)){ # f = 1\n  \n  # read in detection data----\n  file <- file.path(dir_log,'control',sprintf('fp%s/DATA_SpVR_%s_1.txt',fps[f]-100,fps[f]-100))\n  # for log, fp number starts from 1\n  if (file.exists(file)){\n    tmp <- read.csv(file, skip = 10, sep = '\\t', header = F)[,1:13]\n    # header = T did not work because of an extra tab at the end of each row\n    colnames(tmp) <-  c('Trial',\t'Code',\t'Targ',\t'Gap',\t'Emo',\t'Pind',\t'Pcode',\n                       'PicOn',\t'ProbeOn',\t'NumResp',\t'RespOn',\t'Logcode',\t'PPTcode')\n    if (nrow(tmp) != 200){\n      print(file)\n      stop('Not 200 trials per session!')\n    }\n  }\n  \n  # read in detection EEG data----\n  file <- file.path(dir_meanamps,sprintf('fp%03.0f_ses01.tsv',\n                                          fps[f])) # fp numbers already starts from 100\n\n  if (file.exists(file)){\n    tmp2 <- read.csv(file, sep = '\\t', header = T, )\n    \n    if (identical(as.integer(rep(fps[f],length(tmp2$fp))), tmp2$fp) == F){\n      print(file)\n      stop('Subject id does not match!')\n    }\n    \n    # Emo: 1=spi, 2=unpleasant, 3=neutral, 4=pleasant\n    tmp2$Emo <- NA\n    tmp2$Emo[grepl('spi', tmp2$cond)] <- 1\n    tmp2$Emo[grepl('neg', tmp2$cond)] <- 2\n    tmp2$Emo[grepl('neu', tmp2$cond)] <- 3\n    tmp2$Emo[grepl('pos', tmp2$cond)] <- 4\n    \n    tmp2$Targ <- 0\n    tmp2$Targ[grepl('/target', tmp2$cond)] <- 1\n    \n    if (nrow(tmp2) != 200){\n      print(file)\n      stop('Not 200 trials per session!')\n    }\n    if (identical(tmp$Emo, as.integer(tmp2$Emo)) == F){\n      print(file)\n      stop('Emotion codes do not match!')\n    }\n    if (identical(tmp$Targ, as.integer(tmp2$Targ)) == F){\n      print(file)\n      stop('Target trials do not match!')\n    }\n    \n    # copy mean amps\n    tmp$EPN <- as.numeric(tmp2$EPN_average)\n    tmp$LPP <- as.numeric(tmp2$LPP_average)\n    tmp$bad <- as.numeric(tmp2$bad)\n    \n    tmp$fp <- fps[f]\n    tmp$sess <- 0 # code session as 0 and 1\n    tmp$treat <- 'Control'\n    \n    RawDetect <- rbind(RawDetect, tmp)\n    rm(tmp, tmp2)\n  }\n  \n  # read in rating data----\n  file <- file.path(dir_log,'control',sprintf('fp%s/DATA_SpVRrate_%s_1.txt',fps[f]-100,fps[f]-100))\n  # for rating, fp number starts from 1\n  if (file.exists(file)){\n    tmp <- read.csv(file, skip = 5, sep = '\\t', header = T)[-c(1:4),]\n    # delete practice rows\n    if (nrow(tmp) != 40){\n      print(file)\n      stop('Not 40 trials per session!')\n    }\n    tmp$fp <- fps[f]\n    tmp$sess <- 0 # code session as 0 and 1\n    tmp$treat <- 'Control'\n    RawRate <- rbind(RawRate, tmp)\n  }\n}\nrm(fps,tmp,file,f)\n```\n\n## recode variables\n* Subject ID (fp) as character (for an unknown reason, fp as factor messes up predicted())\n* Control group as reference category\n* Emotion categories: neutral, spider, negative, positive (in this order)\n```{r recode variables in rawdata}\nRawDetect <- RawDetect %>%\n  mutate(fp = as.character(fp),\n         treat = factor(treat, levels = c(\"Control\", \"IVET\", \"VRET\")), \n         # relevel so control is the reference\n         Emo = recode(Emo, \"1\" = \"spider\", \"2\" = \"negative\", \"3\" = \"neutral\", \"4\" = \"positive\"), \n         # recode emotion categories\n         Emo = factor(Emo, levels = c(\"neutral\", \"spider\", \"negative\", \"positive\"))) \n# relevel so that neutral is the reference\nRawRate <- RawRate %>%\n  mutate(fp = as.character(fp),\n         treat = factor(treat, levels = c(\"Control\", \"IVET\", \"VRET\")), \n         # relevel so control is the reference\n         Emo = recode(Emo, \"1\" = \"spider\", \"2\" = \"negative\", \"3\" = \"neutral\", \"4\" = \"positive\"), \n         # recode emotion categories\n         Emo = factor(Emo, levels = c(\"neutral\", \"spider\", \"negative\", \"positive\")))\n```\n\n```{r, export raw csv}\nwrite_tsv(RawDetect, file.path('results/datadetect.tsv'))\nwrite_tsv(RawRate, file.path('results/datarate.tsv'))\n```\n\n# detection task performance {.tabset}\nProcess the performance data (false alarms, hit rate, reaction time to hits) from \nthe detection task.  \n\n## false alarms\nIn the plot, subject refers to the data from a subject in a single session (*N* = `r Nall`). Most subjects made very few false alarms with a couple of exceptions. However, \nthese subjects were in the control group. So, ignore false alarms and focus on hits.\n```{r compute false alarms for detect data}\n# false alarm\ntmp <- RawDetect %>% \n  mutate(fals = ifelse(Targ==0 & NumResp>0, 1, 0)) %>%\n  group_by(fp, sess) %>%\n  summarise(sumfals = sum(fals), .groups = 'drop') %>% \n  pull(sumfals) %>% \n  mean()\nRawDetect %>% \n  mutate(fals = ifelse(Targ==0 & NumResp>0, 1, 0)) %>%\n  group_by(fp, sess) %>%\n  summarise(sumfals = sum(fals), .groups = 'drop') %>% \n  ggplot(aes(sumfals)) +\n     geom_density() +\n     theme_bw() +\n     labs(title = paste0('Number of false alarms (mean = ', myround(tmp,1),')'), \n          x = 'Number of false alarms per subject (possible max = 160)') +\n    geom_vline(xintercept = tmp, linetype = 'longdash')\nrm(tmp)\n```\n\n## hit rate {.tabset}\nHits are trials in which the flashing of the fixation cross was detected and reaction time (RT) > 200 ms.  \n\n### plot\nIn the plot, subject refers to the data from a subject in a single session (*N* = 160).  \nHit rate varied across subjects.    \n```{r compute hit rate for detect data}\n# hits\nRawDetect <- RawDetect %>% \n  mutate(hit = ifelse(Targ == 1 & NumResp > 0 & RespOn - ProbeOn > 200, 1, 0))\ntmp <- RawDetect %>% \n  filter(Targ == 1) %>% \n  group_by(fp, sess) %>%\n  summarise(mhit = mean(hit)*100, .groups = 'drop') %>% \n  pull(mhit) %>% \n  mean()\nRawDetect %>% \n  filter(Targ == 1) %>% \n  group_by(fp, sess) %>%\n  summarise(mhit = mean(hit)*100, .groups = 'drop') %>% \n  ggplot(aes(mhit)) +\n     geom_density() +\n     theme_bw() +\n     labs(title = paste0('Hit rate (mean = ', myround(tmp,1),')'), \n          x = 'Hit rate (%) per subject') +\n     geom_vline(xintercept = tmp, linetype = 'longdash')\nrm(tmp)\n```\n\n### session 1 across treatments {.tabset}\n* use session 1 from all three groups\n* combine treatment groups\n* compute mean hit rate\n* nonspiders (i.e., positive, neutral, negative) are combined\n* compare spiders versus nonspiders \n* intercept is control/nonspiders\n\nResult: In Session 1, the combined treatment groups (vs controls) tended to have lower hit rates for spiders (vs nonspiders).  \n\n#### model\n```{r}\nmylabels <- c('treatment (Control) / emotion (nonspiders)',\n             'treatment (VRET/IVET) /  emotion (nonspiders)', \n             'treatment (Control) / emotion (spiders)', \n             'treatment (VRET/IVET) / emotion (spiders)')\nmodel_name <- \"perfdetect_acrosstreatment\"\nmodel_formula <- formula(\"mhit ~ 1 + treat*Emo + (1 | fp)\")\ndata <- RawDetect %>%\n  filter(sess == 0 & Targ == 1) %>%\n  mutate(Emo = ifelse(Emo == 'spider', 'spider', 'nonspider'),   \n         Emo = factor(Emo, levels = c(\"nonspider\", \"spider\"))) %>%\n  group_by(fp, Emo) %>%\n  summarise(mhit = mean(hit)*100, .groups = 'drop') %>%\n  mutate(treat = ifelse(as.numeric(as.character(fp)) > 100,'Control', 'VRET/IVET'),   \n         treat = factor(treat, levels = c(\"Control\", \"VRET/IVET\")))\nassign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                         control = lmerControl(optimizer = \"bobyqa\",  \n                                                               optCtrl = list(maxfun = 1e5)),\n                                         data = data))\ntable_model(get(model_name),\n            dv_labels = \"Mean Hit rate (%)\",\n            pred_labels = mylabels)\n```\n\n#### plot\n```{r}\nggeffects::ggpredict(get(model_name), c(\"treat\", \"Emo\")) %>%\n  data.frame() %>%\n  mutate(group = factor(group, levels = c(\"nonspider\", \"spider\"))) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  #geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat, group = fp), alpha = .3, size = .2) +\n  # plotting individual lines is not meaningful because slopes are fixed in model\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  scale_color_manual(values = palette2, name = \"treatment\") +\n  labs(y = \"predicted hit rate\\n\", x = \"\\nemotion\") +\n  plot_aes\n```\n\n### treatment comparison {.tabset}\n* session 1 and session 2 (session 1 as reference)\n* include only treatment groups\n* IVET = -.5, VRET = .5\n* compute mean hit rate\n* nonspiders (i.e., positive, neutral, negative) are combined\n* compare spiders versus nonspiders \n* intercept is session 1/nonspiders\n\nResults do not suggest that the treatment groups differed. However, across treatment groups, there were two effects:  \n  \n* Performance was lower to spiders than nonspiders in Session 1.\n* The performance difference between spiders vs nonspiders decreased from Session 1 to Session 2.  \n\n#### model\n```{r}\nmylabels <- c('treatment (VRET/IVET) / session (1) / emotion (nonspider)',\n             'treatment (VRET vs IVET) /  session (1) / emotion (nonspider)', \n             'treatment (VRET/IVET) / session (2) / emotion (nonspider)', \n             'treatment (VRET/IVET) / session (1) / emotion (spider)',\n             'treatment (VRET vs IVET) / session (2) / emotion (nonspider)',\n             'treatment (VRET vs IVET) /  session (1) / emotion (spider)', \n             'treatment (VRET/IVET) /  session (2) / emotion (spider)', \n             'treatment (VRET vs IVET) /  session (2) / emotion (spider)')\nmodel_name <- \"perfdetect_treatment\"\nmodel_formula <- formula(\"mhit ~ 1 + treat*sess*Emo + (1 | fp)\")\ndata <- RawDetect %>%\n  filter(!treat == 'Control' & Targ == 1) %>%\n  mutate(Emo = ifelse(Emo == 'spider', 'spider', 'nonspider'),   \n         Emo = factor(Emo, levels = c(\"nonspider\", \"spider\")),\n         treat =  ifelse(as.character(treat) == \"IVET\", -.5, .5)) %>%\n  #recode treatment as -.5 and .5\n  group_by(treat, fp, sess, Emo) %>%\n  summarise(mhit = mean(hit)*100, .groups = 'drop') \nassign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                         control = lmerControl(optimizer = \"bobyqa\",  \n                                                               optCtrl = list(maxfun = 1e5)),\n                                         data = data))\ntable_model(get(model_name),\n            dv_labels = \"Mean Hit rate\",\n            pred_labels = mylabels)\n```\n\n#### plot\n```{r}\nggeffects::ggpredict(get(model_name), c(\"treat\", \"sess\", \"Emo\")) %>%\n  data.frame() %>%\n  mutate(group = ifelse(group == 0, 'pre', 'post'),\n         group = factor(group, levels = c('pre', 'post')),\n         x = ifelse(x == -.5, \"IVET\", \"VRET\")) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  facet_grid(~facet) +\n  scale_color_manual(values = palette[2:3], name = \"treatment\") +\n  labs(y = \"predicted hit rate\\n\", x = \"\\nsession\") +\n  plot_aes\n```\n\n## hits RT (ms) {.tabset}\n### session 1 across treatments {.tabset}\n* use session 1 from all three groups\n* combine treatment groups\n* compute mean hit RT (ms)\n* nonspiders (i.e., positive, neutral, negative) are combined\n* compare spiders versus nonspiders \n* intercept is control/nonspiders\n\nResults do not suggest differences in Session 1.  \n\n#### model\n```{r}\nmylabels <- c('treatment (Control) / emotion (nonspiders)',\n             'treatment (VRET/IVET) /  emotion (nonspiders)', \n             'treatment (Control) / emotion (spiders)', \n             'treatment (VRET/IVET) / emotion (spiders)')\nmodel_name <- \"perfdetectRT_acrosstreatment\"\nmodel_formula <- formula(\"mhitRT ~ 1 + treat*Emo + (1 | fp)\")\ndata <- RawDetect %>%\n  filter(sess == 0,\n         hit == 1) %>%\n  mutate(hitRT = RespOn - ProbeOn,\n         Emo = ifelse(Emo == 'spider', 'spider', 'nonspider'),   \n         Emo = factor(Emo, levels = c(\"nonspider\", \"spider\"))) %>%\n  group_by(fp, Emo) %>%\n  summarise(mhitRT = mean(hitRT), .groups = 'drop') %>%\n  mutate(treat = ifelse(as.numeric(fp) < 100,'Control', 'VRET/IVET'),   \n         treat = factor(treat, levels = c(\"Control\", \"VRET/IVET\")))\nassign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                         control = lmerControl(optimizer = \"bobyqa\",  \n                                                               optCtrl = list(maxfun = 1e5)),\n                                         data = data))\ntable_model(get(model_name),\n            dv_labels = \"Mean Hit RT (ms)\",\n            pred_labels = mylabels)\n```\n\n#### plot\n```{r}\nggeffects::ggpredict(get(model_name), c(\"treat\", \"Emo\")) %>%\n  data.frame() %>%\n  mutate(group = factor(group, levels = c(\"nonspider\", \"spider\"))) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  scale_color_manual(values = palette2, name = \"treatment\") +\n  labs(y = \"predicted hit RT (ms)\\n\", x = \"\\nemotion\") +\n  plot_aes\n```\n\n### treatment comparison {.tabset}\n* session 1 and session 2 (session 1 as reference)\n* include only treatment groups\n* IVET = -.5, VRET = .5\n* compute mean hit RT (ms)\n* nonspiders (i.e., positive, neutral, negative) are combined\n* compare spiders versus nonspiders \n* intercept is session 1/nonspiders\n\nResults suggest no differences.  \n\n#### model\n```{r}\nmylabels <- c('treatment (VRET/IVET) / session (1) / emotion (nonspider)',\n             'treatment (VRET vs IVET) /  session (1) / emotion (nonspider)', \n             'treatment (VRET/IVET) / session (2) / emotion (nonspider)', \n             'treatment (VRET/IVET) / session (1) / emotion (spider)',\n             'treatment (VRET vs IVET) / session (2) / emotion (nonspider)',\n             'treatment (VRET vs IVET) /  session (1) / emotion (spider)', \n             'treatment (VRET/IVET) /  session (2) / emotion (spider)', \n             'treatment (VRET vs IVET) /  session (2) / emotion (spider)')\nmodel_name <- \"perfdetectRT_treatment\"\nmodel_formula <- formula(\"mhitRT ~ 1 + treat*sess*Emo + (1 | fp)\")\ndata <- RawDetect %>%\n  filter(!treat == 'Control',\n         hit == 1) %>%\n  mutate(hitRT = RespOn - ProbeOn,\n         Emo = ifelse(Emo == 'spider', 'spider', 'nonspider'),   \n         Emo = factor(Emo, levels = c(\"nonspider\", \"spider\")),\n         treat =  ifelse(as.character(treat) == \"IVET\", -.5, .5)) %>%\n  #recode treatment as -.5 and .5\n  group_by(treat, fp, sess, Emo) %>%\n  summarise(mhitRT = mean(hitRT), .groups = 'drop') \nassign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                         control = lmerControl(optimizer = \"bobyqa\",  \n                                                               optCtrl = list(maxfun = 1e5)),\n                                         data = data))\ntable_model(get(model_name),\n            dv_labels = \"Mean Hit RT (ms)\",\n            pred_labels = mylabels)\n```\n\n#### plot\n```{r}\nggeffects::ggpredict(get(model_name), c(\"treat\", \"sess\", \"Emo\")) %>%\n  data.frame() %>%\n  mutate(group = ifelse(group == 0, 'pre', 'post'),\n         group = factor(group, levels = c('pre', 'post')),\n         x = ifelse(x == -.5, \"IVET\", \"VRET\")) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  facet_grid(~facet) +\n  scale_color_manual(values = palette[2:3], name = \"treatment\") +\n  labs(y = \"predicted hit RT (ms)\\n\", x = \"\\nsession\") +\n  plot_aes\n```\n\n# prepare rating/EEG subsets {.tabset}\n\n## emotion rating\nSelf-reported ratings of arousal and pleasantness during the rating task.\n```{r}\n# check min=1 and max=9\nRawRate %>% \n  summarise(min_aro = min(Aro),\n            max_aro = max(Aro),\n            min_uple = min(Ple),\n            max_uple = max(Ple), .groups = 'drop') %>% \n  as.numeric() %>% \n  identical(c(1,9,1,9)) %>% \n  isFALSE() %>% \n  {if(.)(stop(\"Error: Rating min and max are not 1 and 9, respectively!\"))}\n\nrate <- RawRate\n\n# arousal and pleasantness separately\n# ====================================\n# subset baseline data\nrate_baseline <- rate %>%\n  filter(sess == 0) %>%\n  pivot_longer(cols = c(Ple, Aro), names_to = 'rating_type', values_to = 'rating') %>%\n  mutate(rating_type = factor(rating_type, levels = c(\"Aro\", \"Ple\")))\n\n# combine treatments\n# (IVET and VRET have different fp, ie subject ids)\nrate_baseline_acrosstreatment <- rate_baseline %>%\n  mutate(treat = ifelse(treat == \"Control\", \"Control\", \"IVET/VRET\"), \n         treat = factor(treat, levels = c(\"Control\", \"IVET/VRET\")))\n\n# pivot_longer rating types and filter out control\nrate_only_treat <- rate %>%\n  filter(!treat == \"Control\") %>%\n  pivot_longer(cols = c(Ple, Aro), names_to = 'rating_type', values_to = 'rating') \n\n# recode treatment\nrate_only_treat_recode <- rate_only_treat %>%\n  mutate(treat =  ifelse(as.character(treat) == \"IVET\", -.5, .5))\n         #recode treatment as -.5 and .5\n\n# subtract the average across neutral pictures from each trial\nneutral_rate <- rate %>%\n  filter(Emo == \"neutral\") %>%\n  group_by(fp, sess) %>%\n  summarise(neutral_avg_Aro = mean(Aro, na.rm = TRUE),\n            neutral_avg_Ple = mean(Ple, na.rm = TRUE),\n            .groups = 'drop') # grouping is dropped\n\nrate_diffneutral <- rate %>%\n  filter(!Emo == \"neutral\") %>%\n  left_join(., neutral_rate, by = c(\"fp\", \"sess\")) %>%\n  mutate(Aro_diff  = Aro - neutral_avg_Aro,\n         Ple_diff = Ple - neutral_avg_Ple,\n         Emo = factor(Emo, levels = c(\"spider\", \"negative\", \"positive\")),\n         treat = factor(treat))\n\n```\n\n## detection task (EEG){.tabset}\n* remove bad trials from the EEG data\n* remove outliers\n* remove target trials from the EEG data (20% target trials)\n* remove false alarms\n\n### all trials\nNumber of trials = `r nrow(RawDetect)`. \n```{r}\nRawDetect %>% \n  pivot_longer(cols = c(EPN,LPP), names_to = 'ERP_type', values_to = 'amp' ) %>% \n  ggplot() +\n  geom_violin(aes(x = ERP_type, y = amp)) +\n  theme_bw() +\n  labs(title = paste0('Mean amplitude (V) per trial (N = ', nrow(RawDetect),')'), \n       x = 'ERP interval')\n```\n\n### remove bad trials\nBelow, the bad trials were removed. These were marked during the initial data preparation.  \n\nNumber of trials = `r nrow(RawDetect %>% filter(bad == 0))`. Percentage of remaining trials = `r myround(nrow(RawDetect %>% filter(bad == 0)) / nrow(RawDetect) *100,1)`.  \n\nThe figure suggests that some outliers remained. The figure suggests that +/-25 V is a reasonable cut off for these outliers.  \n```{r}\nRawDetect %>% \n  filter(bad == 0) %>% # remove bad EEG trials\n  pivot_longer(cols = c(EPN,LPP), names_to = 'ERP_type', values_to = 'amp' ) %>% \n  ggplot() +\n  geom_violin(aes(x = ERP_type, y = amp)) +\n  geom_hline(aes(yintercept = 25), linetype = 'longdash') +\n  geom_hline(aes(yintercept = -25), linetype = 'longdash') +\n  theme_bw() +\n  labs(title = paste0('Mean amplitude (V) per trial (N = ', nrow(RawDetect %>% filter(bad == 0)),')'), \n       x = 'ERP interval')\n# remove outliers\ntmp <- nrow(RawDetect %>% filter(bad == 0))\nRawDetect <- RawDetect %>% \n  mutate(bad = ifelse(abs(EPN) > 25 | abs(LPP) > 25 | is.na(EPN) | is.na(LPP), 1, bad))\ntmp2 <- nrow(RawDetect %>% filter(bad == 0))\n```\n\n### remove outliers\nThe outliers were identified with the previous violin plot. \nNumber of trials that were excluded: `r tmp-tmp2`.  \nNumber of remaining trials = `r nrow(RawDetect %>% filter(bad == 0))`. Percentage of remaining trials = `r myround(nrow(RawDetect %>% filter(bad == 0)) / nrow(RawDetect)*100,1)`.\n\n```{r}\nrm(tmp, tmp2)\nRawDetect %>% \n  filter(bad == 0) %>% # remove bad trials and outliers\n  pivot_longer(cols = c(EPN,LPP), names_to = 'ERP_type', values_to = 'amp' ) %>% \n  ggplot() +\n  geom_violin(aes(x = ERP_type, y = amp)) +\n  geom_hline(aes(yintercept = 25), linetype = 'longdash') +\n  geom_hline(aes(yintercept = -25), linetype = 'longdash') +\n  theme_bw() +\n  labs(title = paste0('Mean amplitude (V) per trial (N = ', nrow(RawDetect %>% filter(bad == 0)),')'), \n       x = 'ERP interval')\n```\n\n### check distribution\nCheck how bad trials are distributed between spider and nonspiders. The expected percentages for bad spider trials is 25% (1 of 4 picture categories).\n\n```{r}\nRawDetect %>% \n  mutate(Treatment = ifelse(treat == 'Control', 'Control', 'IVET/VRET'),\n         spider = ifelse(Emo == 'spider', 'spider', 'nonspider')) %>% \n  group_by(Treatment, spider) %>% \n  summarize(bad = sum(bad), .groups = 'drop') %>% \n  pivot_wider(names_from = 'spider', values_from = 'bad') %>% \n  mutate(bad_percent = spider/(spider+nonspider)*100) %>% \n  kable(align = \"c\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n```\n\n### N trials\nPercentage of good EEG trials per recording.\n```{r}\nRawDetect %>% \n  group_by(treat, sess, fp) %>% \n  summarize(good = (1-sum(bad)/n())*100,.groups = 'drop') %>% \n  pull(good) %>% \n  summary()\n```\n\n### N trials by group\nPercentage of good EEG trials per participant and group.\n```{r}\nRawDetect %>% \n  group_by(treat, sess, fp) %>% \n  summarize(good = (1-sum(bad)/n())*100,.groups = 'drop') %>% \n  mutate(sess = ifelse(sess == 0, 'pre', 'post')) %>% \n  unite(Condition, treat, sess, sep = \" \") %>% \n  mutate(Condition = ifelse(Condition == 'Control pre', 'Control', Condition)) %>% \n  mutate(Condition = factor(Condition, levels=unique(as.character(Condition)))) %>% \n  group_by(Condition) %>% \n  summarize(N = n(),\n            Mean = myround(mean(good),2),\n            SD = myround(sd(good),2),\n            .groups = 'drop') %>% \n  kable(align = \"c\") %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))\n```\n\n### N trials per block {.tabset}\n\n#### plot\n\n```{r}\nRawDetect %>% \n  filter(bad == 0) %>% # remove bad trials and outliers\n  mutate(block = case_when(\n          Trial < 51 ~ 1,\n          Trial < 101 ~ 2,\n          Trial < 151 ~ 3,\n          Trial < 201 ~ 4)) %>%  \n  group_by(treat, sess, fp, Emo, block) %>% \n  summarize(ntrial = n(), .groups = 'drop') %>% \n  mutate(sess = ifelse(sess == 0, 'pre', 'post')) %>% \n  unite(Condition, treat, sess, sep = \" \") %>% \n  mutate(Condition = ifelse(Condition == 'Control pre', 'Control', Condition)) %>% \n  group_by(Condition, Emo, block) %>% \n  summarise(N = paste0('(n=',n(),')'),\n            Mean = mean(ntrial),\n            .groups = 'drop') %>% \n  unite(Condition, Condition, N, sep = \" \") %>% \n  ggplot(aes(x=block, y=Mean, by=Condition, color=Emo)) + \n  geom_line() +\n  theme_bw() + # get rid of background\n  facet_grid(~Condition) + \n  ylim(c(11, 13)) +\n  labs(title = \"Mean N valid EEG trials\",\n       y = \"N trials\")\n```\n#### analysis {.tabset}\n\nfocus on spider and neutral pictures\n\ngroup average is baseline (because of sum coding)\n\nnote: the models did not converge for a complex random-effects structure\n\nresults do not suggest any interaction effects with block\n\n##### summary \n```{r}\ndf_n <- RawDetect %>% \n  filter(bad == 0) %>% # remove bad trials and outliers\n  filter(Emo %in% c(\"spider\", \"neutral\")) %>% \n  mutate(block = case_when(\n          Trial < 51 ~ 0,\n          Trial < 101 ~ 1,\n          Trial < 151 ~ 2,\n          Trial < 201 ~ 3)) %>%  \n  group_by(treat, sess, fp, Emo, block) %>% \n  summarize(ngood = n(), .groups = 'drop') %>% \n  mutate(sess = ifelse(sess == 0, 'pre', 'post')) %>% \n  unite(Condition, treat, sess, sep = \" \") %>% \n  mutate(Condition = ifelse(Condition == 'Control pre', 'Control', Condition))\n\ntmp <- RawDetect %>% \n  filter(bad == 1) %>% # keep bad trials\n  filter(Emo %in% c(\"spider\", \"neutral\")) %>% \n  mutate(block = case_when(\n          Trial < 51 ~ 0,\n          Trial < 101 ~ 1,\n          Trial < 151 ~ 2,\n          Trial < 201 ~ 3)) %>%  \n  group_by(treat, sess, fp, Emo, block) %>% \n  summarize(nbad = n(), .groups = 'drop') %>% \n  mutate(sess = ifelse(sess == 0, 'pre', 'post')) %>% \n  unite(Condition, treat, sess, sep = \" \") %>% \n  mutate(Condition = ifelse(Condition == 'Control pre', 'Control', Condition))\n\ndf_n <- left_join(df_n, tmp) %>% \n  mutate(nbad = ifelse(is.na(nbad), 0, nbad),\n         Condition = as.factor(Condition))\nrm(tmp)\n\ncontrasts(df_n$Condition) <- contr.treatment(5)\n\nn_mod <- glmer(cbind(ngood, nbad) ~ -1 + block * Emo * Condition + (1 | fp),\n               data = df_n,\n               family = binomial, \n               control = glmerControl(optimizer = \"bobyqa\"))\nsummary(n_mod)\n```\n\n##### table\n```{r}\ntidy(n_mod, conf.int = TRUE) %>% \n  select(-group) %>% \n  kable() %>%\n  kable_styling()\n```\n\n```{r, export Detect without outliers csv}\nwrite_tsv(RawDetect, file.path('results/datadetect_clean.tsv'))\n```\n\n### prepare files\n```{r}\ndetect <- RawDetect %>%\n  filter(bad == 0) #%>% # remove bad EEG trials and outliers\n # # target trials\n # filter(Targ == 0) %>%\n # # false alarms\n # mutate(fals = ifelse(Targ==0 & NumResp>0, 1, 0)) %>%\n # filter(fals == 0) %>%\n # select(-fals)\n\n# subset baseline data\ndetect_baseline <- detect %>%\n  filter(sess == 0)\n\n# combine treatments\n# (IVET and VRET have different fp, ie subject ids)\ndetect_baseline_acrosstreatment <- detect_baseline %>%\n  mutate(treat = ifelse(treat == \"Control\", \"Control\", \"IVET/VRET\"), \n         treat = factor(treat, levels = c(\"Control\", \"IVET/VRET\")))\n\n# filter out control\ndetect_only_treat <- detect %>%\n  filter(!treat == \"Control\") %>%\n  mutate(treat = factor(treat))\n\n# recode treatment as -.5 and .5\ndetect_only_treat_recode <- detect_only_treat %>%\n  mutate(treat =  ifelse(as.character(treat) == \"IVET\", -.5, .5)) #recode rating_type as -.5 and .5\n\n# subtract the average across neutral pictures from each trial and re-reference\nneutral_ERP <- detect %>%\n  filter(Emo == \"neutral\") %>%\n  group_by(fp, sess) %>%\n  summarise(neutral_avg_LPP = mean(LPP, na.rm = TRUE),\n            neutral_avg_EPN = mean(EPN, na.rm = TRUE),\n            .groups = 'drop') # grouping is dropped\n\ndetect_diffneutral <- detect %>%\n  filter(!Emo == \"neutral\") %>%\n  left_join(., neutral_ERP, by = c(\"fp\", \"sess\")) %>%\n  mutate(LPP_diff = LPP - neutral_avg_LPP,\n         EPN_diff = EPN - neutral_avg_EPN,\n         Emo = factor(Emo, levels = c(\"spider\", \"negative\", \"positive\")),\n         treat = factor(treat))\n\ndetect_diffneutralEG <- detect_diffneutral %>%\n  filter(!treat == \"Control\") %>%\n  mutate(treat =  ifelse(as.character(treat) == \"IVET\", -.5, .5))\n```\n\n# descriptives with figures {.tabset}\n\n## emotion ratings {.tabset}\n### means\nThe table shows means (*SD* in parentheses).  \n```{r}\nrate %>%\n  pivot_longer(cols = c(Ple, Aro), names_to = 'rating_type', values_to = 'rating') %>%\n  group_by(fp, sess, treat, Emo, rating_type) %>%\n  summarise(mean = mean(rating, na.rm = TRUE), .groups = 'drop') %>% \n  # grouping is dropped \n  mutate(rating_type = ifelse(rating_type == \"Aro\", \"arousal\", \"pleasantness\")) %>%\n  ungroup() %>%\n  mutate(sess = ifelse(sess == 0, \"pre\", \"post\"),\n         sess = factor(sess, levels = c('pre', 'post'))) %>%\n  unite(emo_rating, rating_type, Emo, sep = \" \") %>%\n  group_by(sess, treat, emo_rating) %>%\n  summarise(N = n(),\n            m_sd = sprintf(\"%.2f (%.2f)\", mean(mean, na.rm = TRUE), \n                           sd(mean, na.rm = TRUE)), .groups = 'drop') %>%\n  # grouping is dropped\n  pivot_wider(names_from = emo_rating, values_from = m_sd) %>%\n  rename(\"Treatment\" = treat,\n         \"Session\" = sess) %>%\n  arrange(Treatment) %>%\n  kable() %>%\n  kable_styling()\n```\n\n### change scores\nCompute difference scores relative to neutral pictures. For example, spider = spider - neutral.\n```{r}\nrate_diffneutral %>%\n  pivot_longer(cols = c(Aro_diff, Ple_diff), names_to = 'rating_type', values_to = 'rating') %>% \n  group_by(fp, sess, treat, Emo, rating_type) %>%\n  summarise(rating = mean(rating, na.rm = TRUE), .groups = 'drop') %>% \n  # grouping is dropped \n  mutate(sess = ifelse(sess == 0, \"pre\", \"post\"),\n         sess = factor(sess, levels = c('pre', 'post'))) %>% \n  group_by(sess, treat, Emo, rating_type) %>%\n  summarise(N = n(),\n            Mean = mean(rating),\n            LL = ci95LL(rating),\n            UL = ci95UL(rating),\n           .groups = 'drop') %>% \n  relocate(rating_type) %>% \n  arrange(rating_type, Emo, treat, sess) %>%\n  rename(\"Rating\" = rating_type,\n         \"Treatment\" = treat,\n         \"Session\" = sess, \n         \"Category\" = Emo) %>%\n  kable() %>%\n  kable_styling()\n```\n\n### plot\nPlot change scores for spiders\n```{r}\nfig_rating <- rate_diffneutral %>%\n  filter(Emo == \"spider\") %>% \n  pivot_longer(cols = c(Aro_diff, Ple_diff), names_to = 'rating_type', values_to = 'rating') %>% \n  group_by(fp, sess, treat, Emo, rating_type) %>%\n  summarise(rating = mean(rating, na.rm = TRUE), .groups = 'drop') %>% \n  # grouping is dropped \n  mutate(sess = ifelse(sess == 0, \"pre\", \"post\"),\n         sess = factor(sess, levels = c('pre', 'post')),\n         rating_type = \n           ifelse(rating_type == \"Aro_diff\", \"Arousal\", \"Pleasantness\")) %>% \n  group_by(sess, treat, rating_type) %>%\n  summarise(N = paste0('(n=',n(),')'),\n            Mean = mean(rating),\n            LL = ci95LL(rating),\n            UL = ci95UL(rating),\n           .groups = 'drop') %>% \n  relocate(rating_type) %>% \n  arrange(rating_type, treat, sess) %>%\n  unite(Condition, treat, sess, sep = \"-\") %>% \n  mutate(Condition = ifelse(Condition == 'Control-pre', 'Control', Condition)) %>% \n  unite(Condition, Condition, N, sep = \"\\n\") %>% \n  mutate(Condition = factor(Condition, levels=unique(as.character(Condition)))) %>% \n  ggplot(aes(x=Condition, y=Mean)) + \n  geom_bar(stat=\"identity\"\n          ,fill=\"gray\"\n          ,color=\"black\" # add black border to each bar\n          ,position=position_dodge()) + # separate bars\n  theme_bw() + # get rid of background\n  geom_errorbar(position=position_dodge(.9), width=.25, \n                aes(ymin=LL, ymax=UL)) +\n  facet_wrap(~rating_type, nrow = 1) +\n  labs(title = \"Picture ratings\") +\n  # theme(axis.text.x = element_text(angle = 90, hjust = 1))+\n  labs(x = \"Group by session\") +\n  labs(y = \"Rating difference (spiders-neutral)\") \nfig_rating\nggsave('results/figures/fig_rating.png')\n```\n\n\n## mean amplitudes (EEG) {.tabset}\n### means\nThe table shows means (*SD* in parentheses).  \n```{r}\ndetect %>%\n  pivot_longer(cols = c(EPN, LPP), names_to = 'erp_type', values_to = 'value') %>%\n  group_by(fp, sess, treat, Emo, erp_type) %>%\n  summarise(mean = mean(value, na.rm = TRUE), .groups = 'drop') %>% \n  # grouping is dropped\n  mutate(sess = ifelse(sess == 0, \"pre\", \"post\"),\n         sess = factor(sess, levels = c('pre', 'post'))) %>%\n  unite(emo_rating, erp_type, Emo, sep = \" \") %>%\n  group_by(sess, treat, emo_rating) %>%\n  summarise(N = n(),\n            m_sd = sprintf(\"%.2f (%.2f)\", \n                           mean(mean, na.rm = TRUE), \n                           sd(mean, na.rm = TRUE)), \n                           .groups = 'drop') %>% \n  # grouping is dropped\n  pivot_wider(names_from = emo_rating, values_from = m_sd) %>%\n  rename(\"Treatment\" = treat,\n         \"Session\" = sess) %>%\n  arrange(Treatment) %>%\n  kable() %>%\n  kable_styling()\n```\n\n### change scores\nCompute difference scores relative to neutral pictures. For example, spider = spider - neutral. Thus, the dependent variables capture EPN and LPP.  \n```{r}\ndetect_diffneutral %>%\n  group_by(fp, sess, treat, Emo) %>%\n  summarise(EPN = mean(EPN_diff, na.rm = TRUE),\n            LPP = mean(LPP_diff, na.rm = TRUE), .groups = 'drop') %>% # grouping is dropped \n  mutate(sess = ifelse(sess == 0, \"pre\", \"post\"),\n         sess = factor(sess, levels = c('pre', 'post'))) %>% \n  group_by(sess, treat, Emo) %>%\n  summarise(N = n(),\n            EPN_Mean = mean(EPN),\n            EPN_LL = ci95LL(EPN),\n            EPN_UL = ci95UL(EPN),\n            LPP_Mean = mean(LPP),\n            LPP_LL = ci95LL(LPP),\n            LPP_UL = ci95UL(LPP),\n            .groups = 'drop') %>% \n  arrange(Emo, sess, treat) %>%\n  rename(\"Treatment\" = treat,\n         \"Session\" = sess, \n         \"Category\" = Emo) %>%\n  kable() %>%\n  kable_styling()\n```\n\n### plot\nPlot change scores for spiders\n```{r}\ntmpdata <- detect_diffneutral %>%\n  filter(Emo == 'spider') %>% \n  pivot_longer(cols = c(EPN_diff, LPP_diff), names_to = 'erp_type', \n               values_to = 'value') %>%\n  mutate(erp_type = ifelse(erp_type == 'EPN_diff','EPN','LPP')) %>% \n  group_by(fp, sess, treat, erp_type) %>%\n  summarise(value = mean(value, na.rm = TRUE), .groups = 'drop') %>% \n  # grouping is dropped\n  mutate(sess = ifelse(sess == 0, \"pre\", \"post\"),\n         sess = factor(sess, levels = c('pre', 'post'))) %>% \n  group_by(sess, treat, erp_type) %>%\n  summarise(N = paste0('(n=',n(),')'),\n            Mean = mean(value),\n            LL = ci95LL(value),\n            UL = ci95UL(value),\n            .groups = 'drop') %>% \n  arrange(treat, sess) %>% \n  unite(Condition, treat, sess, sep = \" \") %>% \n  mutate(Condition = ifelse(Condition == 'Control pre', 'Control', Condition)) %>% \n  unite(Condition, Condition, N, sep = \"\\n\") %>% \n  mutate(Condition = factor(Condition, levels=unique(as.character(Condition))))\nfig_epn <- tmpdata %>% \n  filter(erp_type == 'EPN') %>% \n  ggplot(aes(x=Condition, y=Mean)) + \n  geom_bar(stat=\"identity\"\n          ,fill=\"gray\"\n          ,color=\"black\" # add black border to each bar\n          ,position=position_dodge()) + # separate bars\n  theme_bw() + # get rid of background\n  geom_errorbar(position=position_dodge(.9), width=.25, \n                aes(ymin=LL, ymax=UL)) +\n  labs(title = \"EPN to spiders (vs neutral)\") +\n    theme(plot.title = element_text(hjust = 0.5),\n          text = element_text(size = 20),\n          axis.text.x = element_text(size = 14)) +\n  labs(x = \"Group by session\") +\n  labs(y = \"Mean amplitude (V)\")\nfig_epn\nggsave('results/figures/fig_meanamps_EPN.png', plot = fig_epn)\nfig_lpp <- tmpdata %>% \n  filter(erp_type == 'LPP') %>% \n  ggplot(aes(x=Condition, y=Mean)) + \n  geom_bar(stat=\"identity\"\n          ,fill=\"gray\"\n          ,color=\"black\" # add black border to each bar\n          ,position=position_dodge()) + # separate bars\n  theme_bw() + # get rid of background\n  geom_errorbar(position=position_dodge(.9), width=.25, \n                aes(ymin=LL, ymax=UL)) +\n  labs(title = \"LPP to spiders (vs neutral)\") +\n    theme(plot.title = element_text(hjust = 0.5),\n          text = element_text(size = 20),\n          axis.text.x = element_text(size = 14)) +\n  labs(x = \"Group by session\") +\n  labs(y = \"Mean amplitude (V)\")\nfig_lpp\nggsave('results/figures/fig_meanamps_LPP.png', plot = fig_lpp)\n#fig_amp <- grid.arrange(fig_epn, fig_lpp, ncol = 2)\n```\n\n### save EPN and LPP\n```{r}\ndetect %>%\n  group_by(fp, sess, treat, Emo) %>%\n  summarise(EPN = mean(EPN, na.rm = TRUE),\n            LPP = mean(LPP, na.rm = TRUE), .groups = 'drop') %>% # grouping is dropped \n  write_tsv(file.path('results/datameanamps.tsv'))\n```\n\n\n# arousal ratings\nSelf-reported ratings of arousal during the rating task.\n\n## session 1 three groups{.tabset}\n* use session 1 from all three groups  \n* examine if IVET and VRET differ from controls in spider (vs neutral) ratings in session 1\n* compare IVET and VRET separately to the control group\n* does not test whether the treatments differ from each other\n* use neutral pictures as reference emotion\n* save the model to save time  \n\n```{r arousal ratings}\nmodel_name <- \"session_pre_all_groups_rating_arousal\"\nmodel_formula <- formula(\"rating ~ 1 + treat*Emo + (1 + Emo | fp)\")\ndata <- rate_baseline %>% \n  filter(rating_type == \"Aro\")\nif (file.exists(sprintf(\"results/models/model_%s.RDS\", model_name))) {\n  assign(get(\"model_name\"), readRDS(sprintf(\"results/models/model_%s.RDS\", model_name)))\n} else {\n  assign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                           control = lmerControl(optimizer = \"bobyqa\",\n                                                                 optCtrl = list(maxfun = 1e5)),\n                                           data = data))\n  saveRDS(eval(parse(text = model_name)), sprintf(\"results/models/model_%s.RDS\", model_name))\n}\n```\n\n### plots {.tabset}\n#### all categories\n```{r}\nfits <- data %>%\n  modelr::data_grid(treat, Emo, fp) %>%\n  mutate(predicted_re = predict(get(model_name), .),\n         fp_treat = sprintf(\"%s_%s\", fp, treat)) %>%\n  filter(fp_treat %in% sprintf(\"%s_%s\", data$fp, data$treat))\nggeffects::ggpredict(get(model_name), c(\"treat\", \"Emo\")) %>%\n  data.frame() %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(data = fits, aes(x = Emo, y = predicted_re, color = treat,\n                             group = interaction(fp, treat)), alpha = .3, size = .2) +\n  geom_line(aes(group = x), position = position_dodge(width = .15), size = 1) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .15), size = .5) +\n  scale_color_manual(values = palette, name = \"treatment\") +\n  labs(y = \"Predicted arousal\\n\", x = \"\\nemotion\") +\n  plot_aes \nggsave('results/figures/fig_rating_arousal_pre.png', plot = last_plot())\n```\n\n### summarize model\n```{r}\nsummary(get(model_name))\ntidied_model <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\n\n### model table {.tabset}\n#### table of labels\n```{r}\neffectlbls <- data.frame(\n  num = as.character(seq(1:12)), \n  original = tidied_model$term[1:12],\n  standard = c(\"intercept (control, neutral)\", \n               \"treatment (IVET)\", \n               \"treatment (VRET)\", \n               \"emotion (spider)\", \n               \"emotion (negative)\", \n               \"emotion (positive)\",\n               \"treatment (IVET) x emotion (spider)\",\n               \"treatment (VRET) x emotion (spider)\",\n               \"treatment (IVET) x emotion (negative)\", \n               \"treatment (VRET) x emotion (negative)\",\n               \"treatment (IVET) x emotion (positive)\", \n               \"treatment (VRET) x emotion (positive)\"),\n  condition =  c(\"treatment (control) / emotion (neutral)\", \n                 \"treatment (IVET) / emotion (neutral)\", \n                 \"treatment (VRET) / emotion (neutral)\", \n                 \"treatment (control) / emotion (spider)\", \n                 \"treatment (control) / emotion (negative)\", \n                 \"treatment (control) / emotion (positive)\",\n                 \"treatment (IVET) / emotion (spider)\", \n                 \"treatment (VRET) / emotion (spider)\",\n                 \"treatment (IVET) / emotion (negative)\", \n                 \"treatment (VRET) / emotion (negative)\",\n                 \"treatment (IVET) / emotion (positive)\", \n                 \"treatment (VRET) / emotion (positive)\"),\n  stringsAsFactors = F)\neffectlbls %>%\n  kable() %>%\n  kable_styling()\n```\n\n#### standard labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"session 1\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,3]))\n```\n\n#### condition labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"session 1\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,4]))\n```\n\n### interpretation\n```{r}\ntm <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\nThe goal is to examine whether IVET and VRET differ from controls in spider (vs neutral) ratings in the first session (but not in any other picture category). The analysis compares IVET and VRET separately to the control group and does not test whether the treatments differ from each other.\n\nThe formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  \nUp to Emo as random effects: This means that the emo effect can differ between subjects. \n\nIntercept = treatment(control) / emotion(neutral).  \n\nThe effect for the intercept = **`r myround(tm$estimate[tm$term==\"(Intercept)\"],2)`**. This is the mean rating for the intercept that contains treatment(control) and emotion(neutral) and is thus the marginal mean for the control group for neutral pictures.  \n\nThe effect of the interaction is added to this together with lower-order terms to get the marginal mean. An interaction parameter is how much it differs from the lower order terms and the t-test is for the null hypothesis that the difference between these parameters is 0. When testing higher effects, the lower effects are removed. That is, the higher effects test for something over and above the lower effects. Accordingly, the estimated marginal means are the intercept + lower effects + estimate for higher effect. \n\nWe want to see whether IVET and VRET differ from controls in their spider ratings. Because the intercept contains treatment(control) and emotion(neutral), we are interested in these tests:   \n  \n  **For IVET**:  \n  `r pickme = \"treatIVET:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format = \"e\")`  \nThis is the interaction of treatment(IVET vs control) x emotion (spider vs neutral) across ratings.  \n\n**For VRET (same test as for IVET)**:  \n  `r pickme = \"treatVRET:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nThis is the interaction of treatment(VRET vs control) x emotion (spider vs neutral) across ratings.  \n\n### estimated means {.tabset}\n```{r}\nmmeans1 <- data %>%\n  modelr::data_grid(treat, Emo) %>%\n  mutate(marginal_mean = predict(get(model_name), ., re.form = NA)) %>%\n  pivot_wider(names_from = Emo, values_from = marginal_mean)\nmmeans1 %>%\n  kable(digits = 2) %>%\n  kable_styling()\n```\n\n## session 1 across treatments {.tabset}\n* use session 1 from all three groups\n* combine treatment groups\n* use neutral pictures as reference emotion\n* save the model to save time\n\n```{r}\nmodel_name <- \"session_pre_across_treat_rating_arousal\"\nmodel_formula <- formula(\"rating ~ 1 + treat*Emo + (1 + Emo | fp)\")\ndata <- rate_baseline_acrosstreatment %>% \n  filter(rating_type == \"Aro\")\nif (file.exists(sprintf(\"results/models/model_%s.RDS\", model_name))) {\n  assign(get(\"model_name\"), readRDS(sprintf(\"results/models/model_%s.RDS\", model_name)))\n} else {\n  assign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                           control = lmerControl(optimizer = \"bobyqa\", optCtrl = list(maxfun = 1e5)),\n                                           data = data))\n  saveRDS(eval(parse(text = model_name)), sprintf(\"results/models/model_%s.RDS\", model_name))\n}\n```\n\n### plots {.tabset}\n```{r}\nfits <- data %>%\n  modelr::data_grid(treat, Emo, fp) %>%\n  mutate(predicted_re = predict(get(model_name), .),\n         fp_treat = sprintf(\"%s_%s\", fp, treat)) %>%\n  filter(fp_treat %in% sprintf(\"%s_%s\", data$fp, data$treat))\nggeffects::ggpredict(get(model_name), c(\"treat\", \"Emo\")) %>%\n  data.frame() %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(data = fits, aes(x = Emo, y = predicted_re, color = treat,\n                             group = interaction(fp, treat)), alpha = .3, size = .2) +\n  geom_line(aes(group = x), position = position_dodge(width = .15), size = 1) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .15), size = .5) +\n  scale_color_manual(values = palette2, name = \"treatment\") +\n  labs(y = \"predicted arousal\\n\", x = \"\\nemotion\") +\n  plot_aes\n```\n### summarize model\n```{r}\nsummary(get(model_name))\ntidied_model <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\n\n### model table {.tabset}\n#### table of labels\n```{r}\neffectlbls <- data.frame(\n  num = as.character(seq(1:8)), \n  original = tidied_model$term[1:8],\n  standard = c(\"intercept (control, neutral)\", \n               \"treatment (IVET/VRET)\", \n               \"emotion (spider)\", \n               \"emotion (negative)\", \n               \"emotion (positive)\",\n               \"treatment (IVET/VRET) x emotion (spider)\",\n               \"treatment (IVET/VRET) x emotion (negative)\", \n               \"treatment (IVET/VRET) x emotion (positive)\"), \n  condition =  c(\"treatment (control) / emotion (neutral)\", \n                 \"treatment (IVET/VRET) / emotion (neutral)\", \n                 \"treatment (control) / emotion (spider)\", \n                 \"treatment (control) / emotion (negative)\", \n                 \"treatment (control) / emotion (positive)\",\n                 \"treatment (IVET/VRET) / emotion (spider)\", \n                 \"treatment (IVET/VRET) / emotion (negative)\", \n                 \"treatment (IVET/VRET) / emotion (positive)\"),\n  stringsAsFactors = F)\neffectlbls %>%\n  kable() %>%\n  kable_styling()\n```\n\n#### standard labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"session 1\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,3]))\n```\n\n#### condition labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"session 1\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,4]))\n```\n\n### interpretation\n```{r}\ntm <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\nThe goal is to examine whether the combined treatment groups (IVET and VRET) differ from controls in spider (vs neutral) ratings in the first session (but not in any other picture category). The analysis compares the combined IVET and VRET to the control group and does not test whether the treatments differ from each other.\n\nThe formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  \nUp to Emo as random effects: This means that the emo effect can differ between subjects. \n\nIntercept = treatment(control) / emotion(neutral).  \n\nThe effect for the intercept = **`r myround(tm$estimate[tm$term==\"(Intercept)\"], 2)`**. This is the mean rating for the intercept that contains treatment(control) and emotion(neutral) and is thus the marginal mean for the control group for neutral pictures.  \n\nThe effect of the interaction is added to this together with lower-order terms to get the marginal mean. An interaction parameter is how much it differs from the lower order terms and the t-test is for the null hypothesis that the difference between these parameters is 0. When testing higher effects, the lower effects are removed. That is, the higher effects test for something over and above the lower effects. Accordingly, the estimated marginal means are the intercept + lower effects + estimate for higher effect. \n\nWe want to see whether the combined treatment groups (IVET and VRET) differ from controls in their spider ratings. Because the intercept contains treatment(control) and emotion(neutral), we are interested in these tests:   \n  \n  `r pickme = \"treatIVET/VRET:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nThis is the interaction of treatment(IVET/VRET vs control) x emotion (spider vs neutral) across ratings.  \n\n### estimated means {.tabset}\n```{r}\ndata %>%\n  modelr::data_grid(treat, Emo) %>%\n  mutate(marginal_mean = predict(get(model_name), ., re.form = NA)) %>%\n  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%\n  kable(digits = 2) %>%\n  kable_styling()\n```\n\n### Bayes {.tabset}\n#### ordinal model\n```{r}\nratings_arousal_sess1 <- rate_baseline_acrosstreatment %>%\n  filter(rating_type == \"Aro\") %>% \n  filter(Emo %in% c('spider', 'neutral')) %>%\n  mutate(fp = as.factor(fp))\n# Ordinal Regression Model.\nratings_arousal.sess1.model <- brm(rating ~ 1 + treat*Emo + (1 + Emo | fp),\n                             family = cumulative(\"probit\"),\n                             data = na.omit(ratings_arousal_sess1),\n                             prior = c(prior(normal(0, 4), class = Intercept),\n                                       prior(normal(0, 4), class = b)),\n                             chains = 4,\n                             file = \"results/models/ratings_arousal.sess1.model\", \n                             # file to save/reuse model\n                             cores = 4,\n                             iter = 3000,\n                             warmup = 1000,\n                             init_r = 0.5,\n                             save_pars = save_pars(all = TRUE))\n# Model Summary.\nsummary(ratings_arousal.sess1.model)\n```\n\n### Bayes factor {.tabset}\nonly spider and neutral\n\n#### computations\n```{r}\nnull_arousal.sess1.model <- brm(rating ~ 1 + (1 + Emo | fp),\n                          family = cumulative(\"probit\"),\n                          data = ratings_arousal_sess1,\n                          prior = prior(normal(0, 4), class = Intercept),\n                          chains = 4,\n                          file = \"results/models/rating_arousal.sess1.null\", \n                          # Specify file to save/reuse model\n                          cores = 4, \n                          iter = 3000,\n                          warmup = 1000,\n                          init_r = 0.5,\n                          save_pars = save_pars(all = TRUE))\nemo_arousal.sess1.model <- brm(rating ~ 1 + Emo + (1 + Emo | fp),\n                         family = cumulative(\"probit\"),\n                         data = ratings_arousal_sess1,\n                         prior = c(prior(normal(0, 4), class = Intercept),\n                                   prior(normal(0, 4), class = b)),\n                         chains = 4,\n                         file = \"results/models/rating_arousal.sess1.emo\", \n                         # Specify file to save/reuse model\n                         cores = 4, \n                         iter = 3000,\n                         warmup = 1000,\n                         init_r = 0.5,\n                         save_pars = save_pars(all = TRUE))\ntreat_arousal.sess1.model <- brm(rating ~ 1 + treat + (1 + Emo | fp),\n                           family = cumulative(\"probit\"),\n                           data = ratings_arousal_sess1,\n                           prior = c(prior(normal(0, 4), class = Intercept),\n                                     prior(normal(0, 4), class = b)),\n                           chains = 4,\n                           file = \"results/models/rating_arousal.sess1.treat\", \n                           # Specify file to save/reuse model\n                           cores = 4, \n                           iter = 3000,\n                           warmup = 1000,\n                           init_r = 0.5,\n                           save_pars = save_pars(all = TRUE))\n```\n\nCompute bayes factor approximations (via bridge sampling)\n```{r}\n# Bayes factor comparisons are in favor of alternative hypothesis.\nfull_arousal.sess1.bayes <- bayes_factor(ratings_arousal.sess1.model, null_arousal.sess1.model)\ntreat_arousal.sess1.bayes <- bayes_factor(treat_arousal.sess1.model, null_arousal.sess1.model)\nemo_arousal.sess1.bayes <- bayes_factor(emo_arousal.sess1.model, null_arousal.sess1.model)\n\nfull_arousal.sess1.bayes\ntreat_arousal.sess1.bayes\nemo_arousal.sess1.bayes\n```\n\n#### compare with null\n```{r}\ntibble(model = c(\"TreatxEmo\", \"Treat\", \"Emo\"),\n       Compared_To_Null = format(c(full_arousal.sess1.bayes$bf, \n                                   treat_arousal.sess1.bayes$bf, \n                                   emo_arousal.sess1.bayes$bf), scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### compare with Emo\n```{r}\ntibble(model = c(\"TreatxEmo\", \"Treat\", \"Emo\"),\n       Compared_To_Emo =  \n         format(c(full_arousal.sess1.bayes$bf/emo_arousal.sess1.bayes$bf, \n         treat_arousal.sess1.bayes$bf/emo_arousal.sess1.bayes$bf,\n         emo_arousal.sess1.bayes$bf/emo_arousal.sess1.bayes$bf), \n                                scientific = TRUE),\n       BF01 = \n         format(c(emo_arousal.sess1.bayes$bf/full_arousal.sess1.bayes$bf, \n         emo_arousal.sess1.bayes$bf/treat_arousal.sess1.bayes$bf,\n         emo_arousal.sess1.bayes$bf/emo_arousal.sess1.bayes$bf), \n                                scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### check assumptions\nAn ordinal regression has four assumptions:  \n\n1. The dependent variables are ordered.\n2. One or more of the independent variables are either continuous, categorical, or ordinal.\n3. No multi-collinearity.\n4. Proportional odds.\n\nCheck vif and tolerance (multicollinearity)\n```{r}\ncheck_collinearity(ratings_arousal.sess1.model)\n```\n\n## treatment comparison {.tabset}\n* session 1 and session 2 (session 1 as reference)\n* include only treatment groups\n* IVET = -.5, VRET = .5\n* use neutral pictures as reference emotion\n```{r}\nmodel_name <- \"only_treat_rating_arousal\"\nmodel_formula <- formula(\"rating ~ 1 + treat*sess*Emo + (1 + sess*Emo | fp)\")\ndata <- rate_only_treat_recode %>% \n  filter(rating_type == \"Aro\")\nif (file.exists(sprintf(\"results/models/model_%s.RDS\", model_name))) {\n  assign(get(\"model_name\"), readRDS(sprintf(\"results/models/model_%s.RDS\", model_name)))\n} else {\n  assign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                           control = lmerControl(optimizer = \"nloptwrap\",\n                                                                 optCtrl = list(maxfun = 1e7),\n                                                                 calc.derivs = FALSE),\n                                           data = data))\n  saveRDS(eval(parse(text = model_name)), sprintf(\"results/models/model_%s.RDS\", model_name))\n}\n```\n\n### plots {.tabset}\n#### all categories\n```{r}\nfits <- data %>%\n  modelr::data_grid(treat, sess, Emo, fp) %>%\n  mutate(predicted_re = predict(get(model_name), .),\n         fp_treat = sprintf(\"%s_%s\", fp, treat)) %>%\n  filter(fp_treat %in% sprintf(\"%s_%s\", data$fp, data$treat)) %>%\n  mutate(sess = ifelse(sess == 0, 'pre', 'post'),\n         sess = factor(sess, levels = c('pre', 'post')),\n         treat = ifelse(treat == -.5, \"IVET\", \"VRET\"))\nggeffects::ggpredict(get(model_name), c(\"treat\", \"sess\", \"Emo\")) %>%\n  data.frame() %>%\n  mutate(group = ifelse(group == 0, 'pre', 'post'),\n         group = factor(group, levels = c('pre', 'post')),\n         x = ifelse(x == -.5, \"IVET\", \"VRET\"),\n         Emo = facet) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat,\n                             group = interaction(fp, treat, Emo)), alpha = .3, size = .2) +\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  facet_grid(~Emo) +\n  scale_color_manual(values = palette[2:3], name = \"treatment\") +\n  labs(y = \"predicted arousal\\n\", x = \"\\nsession\") +\n  plot_aes\n```\n\n#### spider and neutral ratings\n```{r}\nfits <- data %>%\n  modelr::data_grid(treat, sess, Emo, fp) %>%\n  mutate(predicted_re = predict(get(model_name), .),\n         fp_treat = sprintf(\"%s_%s\", fp, treat)) %>%\n  filter(fp_treat %in% sprintf(\"%s_%s\", data$fp, data$treat)) %>%\n  filter(Emo %in% c(\"neutral\", \"spider\")) %>%\n  mutate(sess = ifelse(sess == 0, 'pre', 'post'),\n         sess = factor(sess, levels = c('pre', 'post')),\n         treat = ifelse(treat == -.5, \"IVET\", \"VRET\"))\nggeffects::ggpredict(get(model_name), c(\"treat\", \"sess\", \"Emo\")) %>%\n  data.frame() %>%\n  filter(facet %in% c(\"neutral\", \"spider\")) %>%\n  mutate(group = ifelse(group == 0, 'pre', 'post'),\n         group = factor(group, levels = c('pre', 'post')),\n         x = ifelse(x == -.5, \"IVET\", \"VRET\"),\n         Emo = facet) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat,\n                             group = interaction(fp, treat, Emo)), alpha = .3, size = .2) +\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  facet_grid(~Emo) +\n  scale_color_manual(values = palette[2:3], name = \"treatment\") +\n  labs(y = \"Predicted arousal\\n\", x = \"\\nsession\") +\n  plot_aes\nggsave('results/figures/fig_rating_arousal_treat.png', plot = last_plot())\n```\n\n### summarize model\n```{r}\nsummary(get(model_name))\ntidied_model <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\n\n### model table {.tabset}\n#### table of labels\n```{r}\neffectlbls <- data.frame(\n  num = as.character(seq(1:16)), \n  original = tidied_model$term[1:16],\n  standard = c(\"intercept (avr_treat, session (1), neutral)\",\n               \"treatment (VRET vs IVET)\",\n               \"session (2)\",\n               \"emotion (spider)\",\n               \"emotion (negative)\",\n               \"emotion (positive)\",\n               \"treatment (VRET vs IVET) x session\",\n               \"treatment (VRET vs IVET) x emotion (spider)\",\n               \"treatment (VRET vs IVET) x emotion (negative)\",\n               \"treatment (VRET vs IVET) x emotion (positive)\",\n               \"session x emotion (spider)\",\n               \"session x emotion (negative)\",\n               \"session x emotion (positive)\",\n               \"treatment (VRET vs IVET) x session x emotion (spider)\",\n               \"treatment (VRET vs IVET) x session x emotion (negative)\",\n               \"treatment (VRET vs IVET) x session x emotion (positive)\"),\n  condition = c(\"treatment (avr_treat) / session (1) / emotion (neutral)\",\n                \"treatment (VRET vs IVET) / sess (1) / emotion (neutral)\",\n                \"treatment (avr_treat) / sess (2) / emotion (neutral)\",\n                \"treatment (avr_treat) / sess (1) / emotion (spider)\",\n                \"treatment (avr_treat) / sess (1) / emotion (negative)\",\n                \"treatment (avr_treat) / sess (1) / emotion (positive)\",\n                \"treatment (VRET vs IVET) / sess (2) / emotion (neutral)\",\n                \"treatment (VRET vs IVET) / sess (1) / emotion (spider)\",\n                \"treatment (VRET vs IVET) / sess (1) / emotion (negative)\",\n                \"treatment (VRET vs IVET) / sess (1) / emotion (positive)\",\n                \"treatment (avr_treat) / sess (2) / emotion (spider)\",\n                \"treatment (avr_treat) / sess (2) / emotion (negative)\",\n                \"treatment (avr_treat) / sess (2) / emotion (positive)\",\n                \"treatment (VRET vs IVET) / sess (2) / emotion (spider)\",\n                \"treatment (VRET vs IVET) / sess (2) / emotion (negative)\",\n                \"treatment (VRET vs IVET) / sess (2) / emotion (positive)\"),\n  stringsAsFactors = F)\neffectlbls %>%\n  kable() %>%\n  kable_styling()\n```\n\n#### standard labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"only treat model\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,3]))\n```\n\n#### condition labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"only treat model\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,4]))\n```\n\n### interpretation\n```{r}\ntm <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\nThe goal is to examine whether IVET and VRET differ from each other in spider (vs neutral) ratings in the first session and between the first and second session (but not in any other picture category). \n\nThe formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  \nEmo by sess as random effects: This means that emo, session, and the emo by session can differ between subjects. \n\nIntercept = treatment(avr_treat) / session (1) / emotion (neutral).  \navr_treat is the mean of IVET and VRET.  \n\nThe effect for the intercept = **`r myround(tm$estimate[tm$term==\"(Intercept)\"], 2)`**. This is the mean rating for the intercept that contains the average across treatments in session 1 to neutral pictures.  \n\nThe effect of the interaction is added to this together with lower-order terms to get the marginal mean. An interaction parameter is how much it differs from the lower order terms and the t-test is for the null hypothesis that the difference between these parameters is 0. When testing higher effects, the lower effects are removed. That is, the higher effects test for something over and above the lower effects. Accordingly, the estimated marginal means are the intercept + lower effects + estimate for higher effect. \n\nWe want to see whether the groups rated spiders differently from neutral pictures in session 1.  \n`r pickme = \"Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nIndeed, spiders are rated more emotional.  \n(Note that the session 1 analysis with three groups tested each treatment compared to the control group.)  \n\nDid the groups differ in how they rated spiders from neutral pictures in session 1? The next analysis suggests: No.  \n`r pickme = \"treat:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \n(Note that the session 1 analysis with three groups tested each treatment compared to the control group.)  \n\nNext, we examine whether the effect of spiders differed between sessions. \n`r pickme = \"sess:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nIndeed, spiders (vs neutral) are rated less emotional in session 2 than session 1.  \n\nCritically, did this effect vary with treatment?  \n  `r pickme = \"treat:sess:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nNo, it does not look like that the treatment groups differed.  \n\nAll the other tests concern pictures other than spiders. \n\n### estimated means {.tabset}\n```{r}\ndata %>%\n  modelr::data_grid(treat, Emo, sess) %>%\n  mutate(marginal_mean = predict(get(model_name), ., re.form = NA),\n         treat = ifelse(treat == -.5, \"IVET\", \"VRET\"),\n         sess = ifelse(sess == 0, 'pre', 'post'),\n         sess = factor(sess, levels = c('pre', 'post'))) %>%\n  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%\n  kable(digits = 2) %>%\n  kable_styling()\n```\n\n### Bayes {.tabset}\n#### ordinal model\n```{r}\nratings_arousal_treat <- rate_only_treat_recode %>% \n  filter(rating_type == \"Aro\") %>% \n  filter(Emo %in% c('spider', 'neutral')) %>% \n  mutate(fp = as.factor(fp))\n# Ordinal Regression Model.\nratings_arousal.treat.model <- brm(rating ~ 1 + treat*sess*Emo + (1 + sess*Emo | fp), \n                             family = cumulative(\"probit\"),\n                             data = na.omit(ratings_arousal_treat),\n                             prior = c(prior(normal(0, 4), class = Intercept),\n                                       prior(normal(0, 4), class = b)),\n                             chains = 4,\n                             file = \"results/models/ratings_arousal.treat.model\", \n                             # file to save/reuse model\n                             cores = 4, \n                             iter = 3000,\n                             warmup = 1000,\n                             init_r = 0.5,\n                             save_pars = save_pars(all = TRUE))\n# Model Summary.\nsummary(ratings_arousal.treat.model)\n```\n\n### Bayes factor {.tabset}\nonly spider and neutral\n\n#### computations\n```{r}\nnull_arousal.treat.model <- brm(rating ~ 1 + (1 + sess*Emo | fp),\n                          family = cumulative(\"probit\"),\n                          data = ratings_arousal_treat,\n                          prior = prior(normal(0, 4), class = Intercept),\n                          chains = 4,\n                          file = \"results/models/rating_arousal.treat.null\", \n                          # Specify file to save/reuse model\n                          cores = 4, \n                          iter = 3000,\n                          warmup = 1000,\n                          init_r = 0.5,\n                          save_pars = save_pars(all = TRUE))\nsess_emo.treat_arousal.model <- brm(rating ~ 1 + sess*Emo + (1 + sess*Emo | fp),\n                              family = cumulative(\"probit\"),\n                              data = ratings_arousal_treat,\n                              prior = c(prior(normal(0, 4), class = Intercept),\n                                        prior(normal(0, 4), class = b)),\n                              chains = 4,\n                              file = \"results/models/rating_arousal.treat.sess_emo\", \n                              cores = 4, \n                              iter = 3000,\n                              warmup = 1000,\n                              save_pars = save_pars(all = TRUE))\nemo.treat_arousal.model <- brm(rating ~ 1 + Emo + (1 + sess*Emo | fp),\n                         family = cumulative(\"probit\"),\n                         data = ratings_arousal_treat,\n                         prior = c(prior(normal(0, 4), class = Intercept),\n                                   prior(normal(0, 4), class = b)),\n                         chains = 4,\n                         file = \"results/models/rating_arousal.treat.emo\", \n                         cores = 4, \n                         iter = 3000,\n                         warmup = 1000,\n                         save_pars = save_pars(all = TRUE))\n```\n\nCompute bayes factor approximations (via bridge sampling)\n```{r}\n# Bayes factor comparisons are in favor of alternative hypothesis.\nfull.treat_arousal.bayes <- bayes_factor(ratings_arousal.treat.model, null_arousal.treat.model)\nsess_emo.treat_arousal.bayes <- bayes_factor(sess_emo.treat_arousal.model, null_arousal.treat.model)\nemo.treat_arousal.bayes <- bayes_factor(emo.treat_arousal.model, null_arousal.treat.model)\n\nfull.treat_arousal.bayes\nsess_emo.treat_arousal.bayes\nemo.treat_arousal.bayes\n```\n\n#### compare with null\n```{r}\ntibble(model = c(\"TreatxSessxEmo\", \"SessxEmo\", \"Emo\"),\n       Compared_To_Null = format(c(full.treat_arousal.bayes$bf, \n                                   sess_emo.treat_arousal.bayes$bf, \n                                   emo.treat_arousal.bayes$bf), scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### compare with Sess x Emo\n```{r}\ntibble(model = c(\"TreatxSessxEmo\", \"SessxEmo\", \"Emo\"),\n       Compared_To_SessxEmo =     \n         format(c(full.treat_arousal.bayes$bf/sess_emo.treat_arousal.bayes$bf,\n                  sess_emo.treat_arousal.bayes$bf/sess_emo.treat_arousal.bayes$bf,\n                  emo.treat_arousal.bayes$bf/sess_emo.treat_arousal.bayes$bf),\n                                               scientific = TRUE),\n         BF01 =   format(c(sess_emo.treat_arousal.bayes$bf/full.treat_arousal.bayes$bf,\n                  sess_emo.treat_arousal.bayes$bf/sess_emo.treat_arousal.bayes$bf,\n                  sess_emo.treat_arousal.bayes$bf/emo.treat_arousal.bayes$bf))) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### compare with Treat x Sess x Emo\n```{r}\ntibble(model = c(\"TreatxSessxEmo\", \"SessxEmo\", \"Emo\"),\n       Compared_To_TreatxSessxEmo =   \n         format(c(full.treat_arousal.bayes$bf/full.treat_arousal.bayes$bf,\n                  sess_emo.treat_arousal.bayes$bf/full.treat_arousal.bayes$bf, \n                  emo.treat_arousal.bayes$bf/full.treat_arousal.bayes$bf),\n                                               scientific = TRUE),\n       BF01 =   format(c(full.treat_arousal.bayes$bf/full.treat_arousal.bayes$bf,\n                  full.treat_arousal.bayes$bf/sess_emo.treat_arousal.bayes$bf, \n                  full.treat_arousal.bayes$bf/emo.treat_arousal.bayes$bf))) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### check assumptions\nAn ordinal regression has four assumptions:  \n\n1. The dependent variables are ordered.\n2. One or more of the independent variables are either continuous, categorical, or ordinal.\n3. No multi-collinearity.\n4. Proportional odds.\n\nCheck vif and tolerance (multicollinearity)\n```{r}\ncheck_collinearity(ratings_arousal.treat.model)\n```\n\n# valence ratings\nSelf-reported ratings of valence during the rating task.\n\n## session 1 three groups{.tabset}\n* use session 1 from all three groups  \n* examine if IVET and VRET differ from controls in spider (vs neutral) ratings in session 1\n* compare IVET and VRET separately to the control group\n* does not test whether the treatments differ from each other\n* use neutral pictures as reference emotion\n* save the model to save time  \n\n```{r valence ratings}\nmodel_name <- \"session_pre_all_groups_rating_valence\"\nmodel_formula <- formula(\"rating ~ 1 + treat*Emo + (1 + Emo | fp)\")\ndata <- rate_baseline %>% \n  filter(rating_type == \"Ple\")\nif (file.exists(sprintf(\"results/models/model_%s.RDS\", model_name))) {\n  assign(get(\"model_name\"), readRDS(sprintf(\"results/models/model_%s.RDS\", model_name)))\n} else {\n  assign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                           control = lmerControl(optimizer = \"bobyqa\",\n                                                                 optCtrl = list(maxfun = 1e5)),\n                                           data = data))\n  saveRDS(eval(parse(text = model_name)), sprintf(\"results/models/model_%s.RDS\", model_name))\n}\n```\n\n### plots {.tabset}\n```{r}\nfits <- data %>%\n  modelr::data_grid(treat, Emo, fp) %>%\n  mutate(predicted_re = predict(get(model_name), .),\n         fp_treat = sprintf(\"%s_%s\", fp, treat)) %>%\n  filter(fp_treat %in% sprintf(\"%s_%s\", data$fp, data$treat))\nggeffects::ggpredict(get(model_name), c(\"treat\", \"Emo\")) %>%\n  data.frame() %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(data = fits, aes(x = Emo, y = predicted_re, color = treat,\n                             group = interaction(fp, treat)), alpha = .3, size = .2) +\n  geom_line(aes(group = x), position = position_dodge(width = .15), size = 1) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .15), size = .5) +\n  scale_color_manual(values = palette, name = \"treatment\") +\n  labs(y = \"Predicted valence\\n\", x = \"\\nemotion\") +\n  plot_aes\nggsave('results/figures/fig_rating_valence_pre.png', plot = last_plot())\n```\n\n### summarize model\n```{r}\nsummary(get(model_name))\ntidied_model <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\n\n### model table {.tabset}\n#### table of labels\n```{r}\neffectlbls <- data.frame(\n  num = as.character(seq(1:12)), \n  original = tidied_model$term[1:12],\n  standard = c(\"intercept (control, neutral)\", \n               \"treatment (IVET)\", \n               \"treatment (VRET)\", \n               \"emotion (spider)\", \n               \"emotion (negative)\", \n               \"emotion (positive)\",\n               \"treatment (IVET) x emotion (spider)\",\n               \"treatment (VRET) x emotion (spider)\",\n               \"treatment (IVET) x emotion (negative)\", \n               \"treatment (VRET) x emotion (negative)\",\n               \"treatment (IVET) x emotion (positive)\", \n               \"treatment (VRET) x emotion (positive)\"),\n  condition =  c(\"treatment (control) / emotion (neutral)\", \n                 \"treatment (IVET) / emotion (neutral)\", \n                 \"treatment (VRET) / emotion (neutral)\", \n                 \"treatment (control) / emotion (spider)\", \n                 \"treatment (control) / emotion (negative)\", \n                 \"treatment (control) / emotion (positive)\",\n                 \"treatment (IVET) / emotion (spider)\", \n                 \"treatment (VRET) / emotion (spider)\",\n                 \"treatment (IVET) / emotion (negative)\", \n                 \"treatment (VRET) / emotion (negative)\",\n                 \"treatment (IVET) / emotion (positive)\", \n                 \"treatment (VRET) / emotion (positive)\"),\n  stringsAsFactors = F)\neffectlbls %>%\n  kable() %>%\n  kable_styling()\n```\n\n#### standard labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"session 1\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,3]))\n```\n\n#### condition labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"session 1\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,4]))\n```\n\n### interpretation\n```{r}\ntm <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\nThe goal is to examine whether IVET and VRET differ from controls in spider (vs neutral) ratings in the first session (but not in any other picture category). The analysis compares IVET and VRET separately to the control group and does not test whether the treatments differ from each other.\n\nThe formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  \nUp to Emo as random effects: This means that the emo effect can differ between subjects. \n\nIntercept = treatment(control) / emotion(neutral).  \n\nThe effect for the intercept = **`r myround(tm$estimate[tm$term==\"(Intercept)\"],2)`**. This is the mean rating for the intercept that contains treatment(control) and emotion(neutral) and is thus the marginal mean for the control group for neutral pictures.  \n\nThe effect of the interaction is added to this together with lower-order terms to get the marginal mean. An interaction parameter is how much it differs from the lower order terms and the t-test is for the null hypothesis that the difference between these parameters is 0. When testing higher effects, the lower effects are removed. That is, the higher effects test for something over and above the lower effects. Accordingly, the estimated marginal means are the intercept + lower effects + estimate for higher effect. \n\nWe want to see whether IVET and VRET differ from controls in their spider ratings. Because the intercept contains treatment(control) and emotion(neutral), we are interested in these tests:   \n  \n  **For IVET**:  \n  `r pickme = \"treatIVET:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format = \"e\")`  \nThis is the interaction of treatment(IVET vs control) x emotion (spider vs neutral) across ratings.  \n\n**For VRET (same test as for IVET)**:  \n  `r pickme = \"treatVRET:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nThis is the interaction of treatment(VRET vs control) x emotion (spider vs neutral) across ratings.  \n\n### estimated means {.tabset}\n```{r}\nmmeans1 <- data %>%\n  modelr::data_grid(treat, Emo) %>%\n  mutate(marginal_mean = predict(get(model_name), ., re.form = NA)) %>%\n  pivot_wider(names_from = Emo, values_from = marginal_mean)\nmmeans1 %>%\n  kable(digits = 2) %>%\n  kable_styling()\n```\n\n## session 1 across treatments {.tabset}\n* use session 1 from all three groups\n* combine treatment groups\n* use neutral pictures as reference emotion\n* save the model to save time\n```{r}\nmodel_name <- \"session_pre_across_treat_rating_valence\"\nmodel_formula <- formula(\"rating ~ 1 + treat*Emo + (1 + Emo | fp)\")\ndata <- rate_baseline_acrosstreatment %>% \n  filter(rating_type == \"Ple\")\nif (file.exists(sprintf(\"results/models/model_%s.RDS\", model_name))) {\n  assign(get(\"model_name\"), readRDS(sprintf(\"results/models/model_%s.RDS\", model_name)))\n} else {\n  assign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                           control = lmerControl(optimizer = \"bobyqa\", optCtrl = list(maxfun = 1e5)),\n                                           data = data))\n  saveRDS(eval(parse(text = model_name)), sprintf(\"results/models/model_%s.RDS\", model_name))\n}\n```\n\n### plots {.tabset}\n```{r}\nfits <- data %>%\n  modelr::data_grid(treat, Emo, fp) %>%\n  mutate(predicted_re = predict(get(model_name), .),\n         fp_treat = sprintf(\"%s_%s\", fp, treat)) %>%\n  filter(fp_treat %in% sprintf(\"%s_%s\", data$fp, data$treat))\nggeffects::ggpredict(get(model_name), c(\"treat\", \"Emo\")) %>%\n  data.frame() %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(data = fits, aes(x = Emo, y = predicted_re, color = treat,\n                             group = interaction(fp, treat)), alpha = .3, size = .2) +\n  geom_line(aes(group = x), position = position_dodge(width = .15), size = 1) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .15), size = .5) +\n  scale_color_manual(values = palette2, name = \"treatment\") +\n  labs(y = \"predicted valence\\n\", x = \"\\nemotion\") +\n  plot_aes\n```\n### summarize model\n```{r}\nsummary(get(model_name))\ntidied_model <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\n\n### model table {.tabset}\n#### table of labels\n```{r}\neffectlbls <- data.frame(\n  num = as.character(seq(1:8)), \n  original = tidied_model$term[1:8],\n  standard = c(\"intercept (control, neutral)\", \n               \"treatment (IVET/VRET)\", \n               \"emotion (spider)\", \n               \"emotion (negative)\", \n               \"emotion (positive)\",\n               \"treatment (IVET/VRET) x emotion (spider)\",\n               \"treatment (IVET/VRET) x emotion (negative)\", \n               \"treatment (IVET/VRET) x emotion (positive)\"), \n  condition =  c(\"treatment (control) / emotion (neutral)\", \n                 \"treatment (IVET/VRET) / emotion (neutral)\", \n                 \"treatment (control) / emotion (spider)\", \n                 \"treatment (control) / emotion (negative)\", \n                 \"treatment (control) / emotion (positive)\",\n                 \"treatment (IVET/VRET) / emotion (spider)\", \n                 \"treatment (IVET/VRET) / emotion (negative)\", \n                 \"treatment (IVET/VRET) / emotion (positive)\"),\n  stringsAsFactors = F)\neffectlbls %>%\n  kable() %>%\n  kable_styling()\n```\n\n#### standard labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"session 1\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,3]))\n```\n\n#### condition labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"session 1\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,4]))\n```\n\n### interpretation\n```{r}\ntm <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\nThe goal is to examine whether the combined treatment groups (IVET and VRET) differ from controls in spider (vs neutral) ratings in the first session (but not in any other picture category). The analysis compares the combined IVET and VRET to the control group and does not test whether the treatments differ from each other.\n\nThe formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  \nUp to Emo as random effects: This means that the emo effect can differ between subjects. \n\nIntercept = treatment(control) / emotion(neutral).  \n\nThe effect for the intercept = **`r myround(tm$estimate[tm$term==\"(Intercept)\"], 2)`**. This is the mean rating for the intercept that contains treatment(control) and emotion(neutral) and is thus the marginal mean for the control group for neutral pictures.  \n\nThe effect of the interaction is added to this together with lower-order terms to get the marginal mean. An interaction parameter is how much it differs from the lower order terms and the t-test is for the null hypothesis that the difference between these parameters is 0. When testing higher effects, the lower effects are removed. That is, the higher effects test for something over and above the lower effects. Accordingly, the estimated marginal means are the intercept + lower effects + estimate for higher effect. \n\nWe want to see whether the combined treatment groups (IVET and VRET) differ from controls in their spider ratings. Because the intercept contains treatment(control) and emotion(neutral), we are interested in these tests:   \n  \n  `r pickme = \"treatIVET/VRET:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nThis is the interaction of treatment(IVET/VRET vs control) x emotion (spider vs neutral) across ratings.  \n\n### estimated means {.tabset}\n```{r}\ndata %>%\n  modelr::data_grid(treat, Emo) %>%\n  mutate(marginal_mean = predict(get(model_name), ., re.form = NA)) %>%\n  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%\n  kable(digits = 2) %>%\n  kable_styling()\n```\n\n### Bayes {.tabset}\n#### ordinal model\n```{r}\nratings_valence_sess1 <- rate_baseline_acrosstreatment %>%\n  filter(rating_type == \"Ple\") %>% \n  filter(Emo %in% c('spider', 'neutral')) %>%\n  mutate(fp = as.factor(fp))\n# Ordinal Regression Model.\nratings_valence.sess1.model <- brm(rating ~ 1 + treat*Emo + (1 + Emo | fp),\n                             family = cumulative(\"probit\"),\n                             data = na.omit(ratings_valence_sess1),\n                             prior = c(prior(normal(0, 4), class = Intercept),\n                                       prior(normal(0, 4), class = b)),\n                             chains = 4,\n                             file = \"results/models/ratings_valence.sess1.model\", \n                             # file to save/reuse model\n                             cores = 4,\n                             iter = 3000,\n                             warmup = 1000,\n                             init_r = 0.5,\n                             save_pars = save_pars(all = TRUE))\n# Model Summary.\nsummary(ratings_valence.sess1.model)\n```\n\n### Bayes factor {.tabset}\nonly spider and neutral\n\n#### computations\n```{r}\nnull_valence.sess1.model <- brm(rating ~ 1 + (1 + Emo | fp),\n                          family = cumulative(\"probit\"),\n                          data = ratings_valence_sess1,\n                          prior = prior(normal(0, 4), class = Intercept),\n                          chains = 4,\n                          file = \"results/models/rating_valence.sess1.null\", \n                          # Specify file to save/reuse model\n                          cores = 4, \n                          iter = 3000,\n                          warmup = 1000,\n                          init_r = 0.5,\n                          save_pars = save_pars(all = TRUE))\nemo_valence.sess1.model <- brm(rating ~ 1 + Emo + (1 + Emo | fp),\n                         family = cumulative(\"probit\"),\n                         data = ratings_valence_sess1,\n                         prior = c(prior(normal(0, 4), class = Intercept),\n                                   prior(normal(0, 4), class = b)),\n                         chains = 4,\n                         file = \"results/models/rating_valence.sess1.emo\", \n                         # Specify file to save/reuse model\n                         cores = 4, \n                         iter = 3000,\n                         warmup = 1000,\n                         init_r = 0.5,\n                         save_pars = save_pars(all = TRUE))\ntreat_valence.sess1.model <- brm(rating ~ 1 + treat + (1 + Emo | fp),\n                           family = cumulative(\"probit\"),\n                           data = ratings_valence_sess1,\n                           prior = c(prior(normal(0, 4), class = Intercept),\n                                     prior(normal(0, 4), class = b)),\n                           chains = 4,\n                           file = \"results/models/rating_valence.sess1.treat\", \n                           # Specify file to save/reuse model\n                           cores = 4, \n                           iter = 3000,\n                           warmup = 1000,\n                           init_r = 0.5,\n                           save_pars = save_pars(all = TRUE))\n```\n\nCompute bayes factor approximations (via bridge sampling)\n```{r}\n# Bayes factor comparisons are in favor of alternative hypothesis.\nfull_valence.sess1.bayes <- bayes_factor(ratings_valence.sess1.model, null_valence.sess1.model)\ntreat_valence.sess1.bayes <- bayes_factor(treat_valence.sess1.model, null_valence.sess1.model)\nemo_valence.sess1.bayes <- bayes_factor(emo_valence.sess1.model, null_valence.sess1.model)\n\nfull_valence.sess1.bayes\ntreat_valence.sess1.bayes\nemo_valence.sess1.bayes\n```\n\n#### compare with null\n```{r}\ntibble(model = c(\"TreatxEmo\", \"Treat\", \"Emo\"),\n       Compared_To_Null = format(c(full_valence.sess1.bayes$bf, \n                                   treat_valence.sess1.bayes$bf, \n                                   emo_valence.sess1.bayes$bf), scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### compare with Emo\n```{r}\ntibble(model = c(\"TreatxEmo\", \"Treat\", \"Emo\"),\n       Compared_To_Emo =\n         format(c(full_valence.sess1.bayes$bf/emo_valence.sess1.bayes$bf, \n                  treat_valence.sess1.bayes$bf/emo_valence.sess1.bayes$bf,\n                  emo_valence.sess1.bayes$bf/emo_valence.sess1.bayes$bf), \n                                scientific = TRUE),  \n         BF01 = \n         format(c(emo_valence.sess1.bayes$bf/full_valence.sess1.bayes$bf, \n         emo_valence.sess1.bayes$bf/treat_valence.sess1.bayes$bf,\n         emo_valence.sess1.bayes$bf/emo_valence.sess1.bayes$bf), \n                                scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n\n#### check assumptions\nAn ordinal regression has four assumptions:  \n\n1. The dependent variables are ordered.\n2. One or more of the independent variables are either continuous, categorical, or ordinal.\n3. No multi-collinearity.\n4. Proportional odds.\n\nCheck vif and tolerance (multicollinearity)\n```{r}\ncheck_collinearity(ratings_valence.sess1.model)\n```\n\n## treatment comparison {.tabset}\n* session 1 and session 2 (session 1 as reference)\n* include only treatment groups\n* IVET = -.5, VRET = .5\n* use neutral pictures as reference emotion\n```{r}\nmodel_name <- \"only_treat_rating_valence\"\nmodel_formula <- formula(\"rating ~ 1 + treat*sess*Emo + (1 + sess*Emo | fp)\")\ndata <- rate_only_treat_recode %>% \n  filter(rating_type == \"Ple\")\nif (file.exists(sprintf(\"results/models/model_%s.RDS\", model_name))) {\n  assign(get(\"model_name\"), readRDS(sprintf(\"results/models/model_%s.RDS\", model_name)))\n} else {\n  assign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                           control = lmerControl(optimizer = \"nloptwrap\",\n                                                                 optCtrl = list(maxfun = 1e7),\n                                                                 calc.derivs = FALSE),\n                                           data = data))\n  saveRDS(eval(parse(text = model_name)), sprintf(\"results/models/model_%s.RDS\", model_name))\n}\n```\n\n### plots {.tabset}\n#### all categories\n```{r}\nfits <- data %>%\n  modelr::data_grid(treat, sess, Emo, fp) %>%\n  mutate(predicted_re = predict(get(model_name), .),\n         fp_treat = sprintf(\"%s_%s\", fp, treat)) %>%\n  filter(fp_treat %in% sprintf(\"%s_%s\", data$fp, data$treat)) %>%\n  mutate(sess = ifelse(sess == 0, 'pre', 'post'),\n         sess = factor(sess, levels = c('pre', 'post')),\n         treat = ifelse(treat == -.5, \"IVET\", \"VRET\"))\nggeffects::ggpredict(get(model_name), c(\"treat\", \"sess\", \"Emo\")) %>%\n  data.frame() %>%\n  mutate(group = ifelse(group == 0, 'pre', 'post'),\n         group = factor(group, levels = c('pre', 'post')),\n         x = ifelse(x == -.5, \"IVET\", \"VRET\"),\n         Emo = facet) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat,\n                             group = interaction(fp, treat, Emo)), alpha = .3, size = .2) +\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  facet_grid(~Emo) +\n  scale_color_manual(values = palette[2:3], name = \"treatment\") +\n  labs(y = \"predicted valence\\n\", x = \"\\nsession\") +\n  plot_aes\n```\n\n#### spider and neutral ratings\n```{r}\nfits <- data %>%\n  modelr::data_grid(treat, sess, Emo, fp) %>%\n  mutate(predicted_re = predict(get(model_name), .),\n         fp_treat = sprintf(\"%s_%s\", fp, treat)) %>%\n  filter(fp_treat %in% sprintf(\"%s_%s\", data$fp, data$treat)) %>%\n  filter(Emo %in% c(\"neutral\", \"spider\")) %>%\n  mutate(sess = ifelse(sess == 0, 'pre', 'post'),\n         sess = factor(sess, levels = c('pre', 'post')),\n         treat = ifelse(treat == -.5, \"IVET\", \"VRET\"))\nggeffects::ggpredict(get(model_name), c(\"treat\", \"sess\", \"Emo\")) %>%\n  data.frame() %>%\n  filter(facet %in% c(\"neutral\", \"spider\")) %>%\n  mutate(group = ifelse(group == 0, 'pre', 'post'),\n         group = factor(group, levels = c('pre', 'post')),\n         x = ifelse(x == -.5, \"IVET\", \"VRET\"),\n         Emo = facet) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat,\n                             group = interaction(fp, treat, Emo)), alpha = .3, size = .2) +\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  facet_grid(~Emo) +\n  scale_color_manual(values = palette[2:3], name = \"treatment\") +\n  labs(y = \"Predicted valence\\n\", x = \"\\nsession\") +\n  plot_aes\nggsave('results/figures/fig_rating_valence_treat.png', plot = last_plot())\n```\n\n### summarize model\n```{r}\nsummary(get(model_name))\ntidied_model <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\n\n### model table {.tabset}\n#### table of labels\n```{r}\neffectlbls <- data.frame(\n  num = as.character(seq(1:16)), \n  original = tidied_model$term[1:16],\n  standard = c(\"intercept (avr_treat, session (1), neutral)\",\n               \"treatment (VRET vs IVET)\",\n               \"session (2)\",\n               \"emotion (spider)\",\n               \"emotion (negative)\",\n               \"emotion (positive)\",\n               \"treatment (VRET vs IVET) x session\",\n               \"treatment (VRET vs IVET) x emotion (spider)\",\n               \"treatment (VRET vs IVET) x emotion (negative)\",\n               \"treatment (VRET vs IVET) x emotion (positive)\",\n               \"session x emotion (spider)\",\n               \"session x emotion (negative)\",\n               \"session x emotion (positive)\",\n               \"treatment (VRET vs IVET) x session x emotion (spider)\",\n               \"treatment (VRET vs IVET) x session x emotion (negative)\",\n               \"treatment (VRET vs IVET) x session x emotion (positive)\"),\n  condition = c(\"treatment (avr_treat) / session (1) / emotion (neutral)\",\n                \"treatment (VRET vs IVET) / sess (1) / emotion (neutral)\",\n                \"treatment (avr_treat) / sess (2) / emotion (neutral)\",\n                \"treatment (avr_treat) / sess (1) / emotion (spider)\",\n                \"treatment (avr_treat) / sess (1) / emotion (negative)\",\n                \"treatment (avr_treat) / sess (1) / emotion (positive)\",\n                \"treatment (VRET vs IVET) / sess (2) / emotion (neutral)\",\n                \"treatment (VRET vs IVET) / sess (1) / emotion (spider)\",\n                \"treatment (VRET vs IVET) / sess (1) / emotion (negative)\",\n                \"treatment (VRET vs IVET) / sess (1) / emotion (positive)\",\n                \"treatment (avr_treat) / sess (2) / emotion (spider)\",\n                \"treatment (avr_treat) / sess (2) / emotion (negative)\",\n                \"treatment (avr_treat) / sess (2) / emotion (positive)\",\n                \"treatment (VRET vs IVET) / sess (2) / emotion (spider)\",\n                \"treatment (VRET vs IVET) / sess (2) / emotion (negative)\",\n                \"treatment (VRET vs IVET) / sess (2) / emotion (positive)\"),\n  stringsAsFactors = F)\neffectlbls %>%\n  kable() %>%\n  kable_styling()\n```\n\n#### standard labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"only treat model\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,3]))\n```\n\n#### condition labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"only treat model\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,4]))\n```\n\n### interpretation\n```{r}\ntm <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\nThe goal is to examine whether IVET and VRET differ from each other in spider (vs neutral) ratings in the first session and between the first and second session (but not in any other picture category). \n\nThe formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  \nEmo by sess as random effects: This means that emo, session, and the emo by session can differ between subjects. \n\nIntercept = treatment(avr_treat) / session (1) / emotion (neutral).  \navr_treat is the mean of IVET and VRET.  \n\nThe effect for the intercept = **`r myround(tm$estimate[tm$term==\"(Intercept)\"], 2)`**. This is the mean rating for the intercept that contains the average across treatments in session 1 to neutral pictures.  \n\nThe effect of the interaction is added to this together with lower-order terms to get the marginal mean. An interaction parameter is how much it differs from the lower order terms and the t-test is for the null hypothesis that the difference between these parameters is 0. When testing higher effects, the lower effects are removed. That is, the higher effects test for something over and above the lower effects. Accordingly, the estimated marginal means are the intercept + lower effects + estimate for higher effect. \n\nWe want to see whether the groups rated spiders differently from neutral pictures in session 1.  \n`r pickme = \"Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nIndeed, spiders are rated more emotional.  \n(Note that the session 1 analysis with three groups tested each treatment compared to the control group.)  \n\nDid the groups differ in how they rated spiders from neutral pictures in session 1? The next analysis suggests: No.  \n`r pickme = \"treat:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \n(Note that the session 1 analysis with three groups tested each treatment compared to the control group.)  \n\nNext, we examine whether the effect of spiders differed between sessions. \n`r pickme = \"sess:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nIndeed, spiders (vs neutral) are rated less emotional in session 2 than session 1.  \n\nCritically, did this effect vary with treatment?  \n  `r pickme = \"treat:sess:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nNo, it does not look like that the treatment groups differed.  \n\nAll the other tests concern pictures other than spiders. \n\n### estimated means {.tabset}\n```{r}\ndata %>%\n  modelr::data_grid(treat, Emo, sess) %>%\n  mutate(marginal_mean = predict(get(model_name), ., re.form = NA),\n         treat = ifelse(treat == -.5, \"IVET\", \"VRET\"),\n         sess = ifelse(sess == 0, 'pre', 'post'),\n         sess = factor(sess, levels = c('pre', 'post'))) %>%\n  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%\n  kable(digits = 2) %>%\n  kable_styling()\n```\n\n### Bayes {.tabset}\n#### ordinal model\n```{r}\nratings_valence_treat <- rate_only_treat_recode %>% \n  filter(rating_type == \"Ple\") %>% \n  filter(Emo %in% c('spider', 'neutral')) %>% \n  mutate(fp = as.factor(fp))\n# Ordinal Regression Model.\nratings_valence.treat.model <- brm(rating ~ 1 + treat*sess*Emo + (1 + sess*Emo | fp), \n                             family = cumulative(\"probit\"),\n                             data = na.omit(ratings_valence_treat),\n                             prior = c(prior(normal(0, 4), class = Intercept),\n                                       prior(normal(0, 4), class = b)),\n                             chains = 4,\n                             file = \"results/models/ratings_valence.treat.model\", \n                             # file to save/reuse model\n                             cores = 4, \n                             iter = 3000,\n                             warmup = 1000,\n                             init_r = 0.5,\n                             save_pars = save_pars(all = TRUE))\n# Model Summary.\nsummary(ratings_valence.treat.model)\n```\n\n\n### Bayes factor {.tabset}\nonly spider and neutral\n\n#### computations\n```{r}\nnull_valence.treat.model <- brm(rating ~ 1 + (1 + sess*Emo | fp),\n                          family = cumulative(\"probit\"),\n                          data = ratings_valence_treat,\n                          prior = prior(normal(0, 4), class = Intercept),\n                          chains = 4,\n                          file = \"results/models/rating_valence.treat.null\", \n                          # Specify file to save/reuse model\n                          cores = 4, \n                          iter = 3000,\n                          warmup = 1000,\n                          init_r = 0.5,\n                          save_pars = save_pars(all = TRUE))\nsess_emo.treat_valence.model <- brm(rating ~ 1 + sess*Emo + (1 + sess*Emo | fp),\n                              family = cumulative(\"probit\"),\n                              data = ratings_valence_treat,\n                              prior = c(prior(normal(0, 4), class = Intercept),\n                                        prior(normal(0, 4), class = b)),\n                              chains = 4,\n                              file = \"results/models/rating_valence.treat.sess_emo\", \n                              cores = 4, \n                              iter = 3000,\n                              warmup = 1000,\n                              save_pars = save_pars(all = TRUE))\nemo.treat_valence.model <- brm(rating ~ 1 + Emo + (1 + sess*Emo | fp),\n                         family = cumulative(\"probit\"),\n                         data = ratings_valence_treat,\n                         prior = c(prior(normal(0, 4), class = Intercept),\n                                   prior(normal(0, 4), class = b)),\n                         chains = 4,\n                         file = \"results/models/rating_valence.treat.emo\", \n                         cores = 4, \n                         iter = 3000,\n                         warmup = 1000,\n                         save_pars = save_pars(all = TRUE))\n```\n\nCompute bayes factor approximations (via bridge sampling)\n```{r}\n# Bayes factor comparisons are in favor of alternative hypothesis.\nfull.treat_valence.bayes <- bayes_factor(ratings_valence.treat.model, null_valence.treat.model)\nsess_emo.treat_valence.bayes <- bayes_factor(sess_emo.treat_valence.model, null_valence.treat.model)\nemo.treat_valence.bayes <- bayes_factor(emo.treat_valence.model, null_valence.treat.model)\n\nfull.treat_valence.bayes\nsess_emo.treat_valence.bayes\nemo.treat_valence.bayes\n```\n\n#### compare with null\n```{r}\ntibble(model = c(\"TreatxSessxEmo\", \"SessxEmo\", \"Emo\"),\n       Compared_To_Null = format(c(full.treat_valence.bayes$bf, \n                                   sess_emo.treat_valence.bayes$bf, \n                                   emo.treat_valence.bayes$bf), scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### compare with Sess x Emo\n```{r}\ntibble(model = c(\"TreatxSessxEmo\", \"SessxEmo\", \"Emo\"),\n       Compared_To_SessxEmo =     \n         format(c(full.treat_valence.bayes$bf/sess_emo.treat_valence.bayes$bf,\n                  sess_emo.treat_valence.bayes$bf/sess_emo.treat_valence.bayes$bf,\n                  emo.treat_valence.bayes$bf/sess_emo.treat_valence.bayes$bf),\n                                               scientific = TRUE),\n         BF01 =   format(c(sess_emo.treat_valence.bayes$bf/full.treat_valence.bayes$bf,\n                  sess_emo.treat_valence.bayes$bf/sess_emo.treat_valence.bayes$bf,\n                  sess_emo.treat_valence.bayes$bf/emo.treat_valence.bayes$bf),\n                                              scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### compare with Treat x Sess x Emo\n```{r}\ntibble(model = c(\"TreatxSessxEmo\", \"SessxEmo\", \"Emo\"),\n       Compared_To_TreatxSessxEmo =   \n         format(c(full.treat_valence.bayes$bf/full.treat_valence.bayes$bf,\n                  sess_emo.treat_valence.bayes$bf/full.treat_valence.bayes$bf, \n                  emo.treat_valence.bayes$bf/full.treat_valence.bayes$bf),\n                                               scientific = TRUE),\n       BF01 =   format(c(full.treat_valence.bayes$bf/full.treat_valence.bayes$bf,\n                  full.treat_valence.bayes$bf/sess_emo.treat_valence.bayes$bf, \n                  full.treat_valence.bayes$bf/emo.treat_valence.bayes$bf),\n                                               scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### check assumptions\nAn ordinal regression has four assumptions:  \n\n1. The dependent variables are ordered.\n2. One or more of the independent variables are either continuous, categorical, or ordinal.\n3. No multi-collinearity.\n4. Proportional odds.\n\nCheck vif and tolerance (multicollinearity)\n```{r}\ncheck_collinearity(ratings_valence.treat.model)\n```\n\n# EEG: EPN-relevant amplitude\nEEG data during the detection task  \n\n## session 1 three groups {.tabset}\n* use session 1 from all three groups  \n* examine whether IVET and VRET differ from controls to spiders (vs neutral) in session 1\n* compare IVET and VRET separately to the control group\n* do not test whether the treatments differ from each other\n* use neutral pictures as reference emotion\n* save the model to save time  \n```{r}\nmodel_name <- \"session_pre_all_groups_EPN\"\nmodel_formula <- formula(\"EPN ~ 1 + treat*Emo + (1 + Emo | fp)\")\ndata <- detect_baseline\nif (file.exists(sprintf(\"results/models/model_%s.RDS\", model_name))) {\n  assign(get(\"model_name\"), readRDS(sprintf(\"results/models/model_%s.RDS\", model_name)))\n} else {\n  assign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                           control = lmerControl(optimizer = \"nloptwrap\",\n                                                                 optCtrl = list(maxfun = 1e7),\n                                                                 calc.derivs = FALSE), \n                                           data = data))\n  saveRDS(eval(parse(text = model_name)), sprintf(\"results/models/model_%s.RDS\", model_name))\n}\n# with nloptwrap: Model failed to converge with 1 negative eigenvalue: -1.5e+03\n# Nelder_Mead: Model failed to converge with 1 negative eigenvalue: -2.3e+02\n# results looked similar\n```\n\n### plot {.tabset}\n```{r}\nfits <- data %>%\n  modelr::data_grid(treat, Emo, fp) %>%\n  mutate(predicted_re = predict(get(model_name), .),\n         fp_treat = sprintf(\"%s_%s\", fp, treat)) %>%\n  filter(fp_treat %in% sprintf(\"%s_%s\", data$fp, data$treat))\nggeffects::ggpredict(get(model_name), c(\"treat\", \"Emo\")) %>%\n  data.frame() %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(data = fits, aes(x = Emo, y = predicted_re, color = treat,\n                             group = interaction(fp, treat)), alpha = .3, size = .2) +\n  geom_line(aes(group = x), position = position_dodge(width = .15), size = 1) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .15), size = .5) +\n  scale_color_manual(values = palette, name = \"treatment\") +\n  labs(y = \"Predicted amp (V)\\n\", x = \"\\nemotion\") +\n  plot_aes\nggsave('results/figures/fig_meanamps_EPN_pre.png', plot = last_plot())\n```\n\n\n### summarize model\n```{r}\nsummary(get(model_name))\ntidied_model <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\n\n### model table {.tabset}\n#### table of labels\n```{r}\neffectlbls <- data.frame(\n  num = as.character(seq(1:12)), \n  original = tidied_model$term[1:12],\n  standard = c(\"intercept (control, neutral)\", \n               \"treatment (IVET)\", \n               \"treatment (VRET)\", \n               \"emotion (spider)\", \n               \"emotion (negative)\", \n               \"emotion (positive)\",\n               \"treatment (IVET) x emotion (spider)\",\n               \"treatment (VRET) x emotion (spider)\",\n               \"treatment (IVET) x emotion (negative)\", \n               \"treatment (VRET) x emotion (negative)\",\n               \"treatment (IVET) x emotion (positive)\", \n               \"treatment (VRET) x emotion (positive)\"),\n  condition = c(\"treatment (control) / emotion (neutral)\", \n                \"treatment (IVET) / emotion (neutral)\", \n                \"treatment (VRET) / emotion (neutral)\", \n                \"treatment (control) / emotion (spider)\", \n                \"treatment (control) / emotion (negative)\", \n                \"treatment (control) / emotion (positive)\",\n                \"treatment (IVET) / emotion (spider)\", \n                \"treatment (VRET) / emotion (spider)\",\n                \"treatment (IVET) / emotion (negative)\", \n                \"treatment (VRET) / emotion (negative)\",\n                \"treatment (IVET) / emotion (positive)\", \n                \"treatment (VRET) / emotion (positive)\"),\n  stringsAsFactors = F)\neffectlbls %>%\n  kable() %>%\n  kable_styling()\n```\n\n#### standard labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"session 1\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,3]))\n```\n\n#### condition labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"session 1\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,4]))\n```\n\n### interpretation\n```{r}\ntm <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\nThe goal is to examine whether IVET and VRET differ from controls in spider (vs neutral) mean amplitude in the first session (but not in any other picture category). The analysis compares IVET and VRET separately to the control group and does not test whether the treatments differ from each other.\n\nThe formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  \nEmo as random effect.  \n\nIntercept = treatment(control) / emotion(neutral).  \n\nThe effect for the intercept = **`r myround(tm$estimate[tm$term==\"(Intercept)\"], 2)`**. This is the mean amplitude for the intercept that contains treatment(control) and emotion(neutral) and is thus the marginal mean for the control group for neutral pictures.  \n\nThe first effect shows that there is an effect of spider (vs neutral). It shows that for the control group, spiders have lower amps than neutral pictures. This relative negativity supports an EPN. But, this effect is not of particular interest because it is only for the control group.  \n\n`r pickme = \"Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \n\nThe main interest is to see whether IVET and VRET differ from controls in their amps to spiders. Particularly, the difference between spiders and neutral pictures should be more negative for each treatment group compared to controls. Because the intercept contains treatment(control) and emotion(neutral), we are interested in these tests:   \n  \n  **For IVET**:  \n  `r pickme = \"treatIVET:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nThis is the interaction of treatment(IVET vs control) x emotion (spider vs neutral).  \n\n**For VRET (same test as for IVET)**:  \n  `r pickme = \"treatVRET:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nThis is the interaction of treatment(VRET vs control) x emotion (spider vs neutral).  \n\n### estimated means\n```{r}\ndata %>%\n  modelr::data_grid(treat, Emo) %>%\n  mutate(marginal_mean = predict(get(model_name), ., re.form = NA),) %>%\n  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%\n  kable(digits = 2) %>%\n  kable_styling()\n```\n\n## session 1 across treatments {.tabset}\n* use session 1 from all three groups\n* combine treatment groups\n* use neutral pictures as reference emotion\n* save the model to save time\n```{r}\nmodel_name <- \"session_pre_across_treat_EPN\"\nmodel_formula <- formula(\"EPN ~ 1 + treat*Emo + (1 + Emo | fp)\")\ndata <- detect_baseline_acrosstreatment\nif (file.exists(sprintf(\"results/models/model_%s.RDS\", model_name))) {\n  assign(get(\"model_name\"), readRDS(sprintf(\"results/models/model_%s.RDS\", model_name)))\n} else {\n  assign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                           control = lmerControl(optimizer = \"nloptwrap\",\n                                                                 optCtrl = list(maxfun = 1e7),\n                                                                 calc.derivs = FALSE), \n                                           data = data))\n  saveRDS(eval(parse(text = model_name)), sprintf(\"results/models/model_%s.RDS\", model_name))\n}\n```\n\n### plot {.tabset}\n```{r}\nfits <- data %>%\n  modelr::data_grid(treat, Emo, fp) %>%\n  mutate(predicted_re = predict(get(model_name), .),\n         fp_treat = sprintf(\"%s_%s\", fp, treat)) %>%\n  filter(fp_treat %in% sprintf(\"%s_%s\", data$fp, data$treat))\nggeffects::ggpredict(get(model_name), c(\"treat\", \"Emo\")) %>%\n  data.frame() %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(data = fits, aes(x = Emo, y = predicted_re, color = treat,\n                             group = interaction(fp, treat)), alpha = .3, size = .2) +\n  geom_line(aes(group = x), position = position_dodge(width = .1), size = 1) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1), size = .5) +\n  scale_color_manual(values = palette2, name = \"treatment\") +\n  labs(y = \"predicted mean amplitude (V)\\n\", x = \"\\nemotion\") +\n  plot_aes\n```\n\n### summarize model\n```{r}\nsummary(get(model_name))\ntidied_model <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\n\n### model table {.tabset}\n#### table of labels\n```{r}\neffectlbls <- data.frame(\n  num = as.character(seq(1:8)), \n  original = tidied_model$term[1:8],\n  standard = c(\"intercept (control, neutral)\", \n               \"treatment (IVET/VRET)\", \n               \"emotion (spider)\", \n               \"emotion (negative)\", \n               \"emotion (positive)\",\n               \"treatment (IVET/VRET) x emotion (spider)\",\n               \"treatment (IVET/VRET) x emotion (negative)\", \n               \"treatment (IVET/VRET) x emotion (positive)\"), \n  condition = c(\"treatment (control) / emotion (neutral)\", \n                \"treatment (IVET/VRET) / emotion (neutral)\", \n                \"treatment (control) / emotion (spider)\", \n                \"treatment (control) / emotion (negative)\", \n                \"treatment (control) / emotion (positive)\",\n                \"treatment (IVET/VRET) / emotion (spider)\", \n                \"treatment (IVET/VRET) / emotion (negative)\", \n                \"treatment (IVET/VRET) / emotion (positive)\"), \n  stringsAsFactors = F)\neffectlbls %>%\n  kable() %>%\n  kable_styling()\n```\n\n#### standard labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"session 1\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,3]))\n```\n\n#### condition labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"session 1\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,4]))\n```\n\n### interpretation\n```{r}\ntm <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\nThe goal is to examine whether the combined treatment groups (IVET and VRET) differ from controls in spider (vs neutral) mean amplitude in the first session (but not in any other picture category). The analysis compares the combined IVET and VRET to the control group and does not test whether the treatments differ from each other.\n\nThe formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  \nEmo as random effect.  \n\nIntercept = treatment(control) / emotion(neutral).  \n\nThe effect for the intercept = **`r myround(tm$estimate[tm$term==\"(Intercept)\"], 2)`**. This is the mean amplitude for the intercept that contains treatment(control) and emotion(neutral) and is thus the marginal mean for the control group for neutral pictures.  \n\nThe first effect shows that there is an effect of spider (vs neutral). It shows that for the control group, spiders have lower amps than neutral pictures. This relative negativity supports an EPN. But, this effect is not of particular interest because it is only for the control group.  \n\n`r pickme = \"Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \n\nThe main interest is to see whether the combined treatment groups (IVET and VRET) differ from controls in their amps to spiders. Particularly, the difference between spiders and neutral pictures should be more negative across treatment groups compared to controls. Because the intercept contains treatment(control) and emotion(neutral), we are interested in this test:   \n  \n  `r pickme = \"treatIVET/VRET:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nThis is the interaction of treatment(IVET/VRET vs control) x emotion (spider vs neutral).  \n\n### estimated means\n```{r}\ndata %>%\n  modelr::data_grid(treat, Emo) %>%\n  mutate(marginal_mean = predict(get(model_name), ., re.form = NA),) %>%\n  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%\n  kable(digits = 2) %>%\n  kable_styling()\n```\n\n### Bayes {.tabset}\nonly spider and neutral\n\n#### gaussian model\n```{r}\n# Prepare dataframe.\ndetect_sess1 <- detect_baseline_acrosstreatment %>% \n  select(Emo, EPN, LPP, fp, sess, treat) %>% \n  filter(Emo %in% c('spider', 'neutral')) %>% \n  mutate(fp = as.factor(fp),\n         Emo = factor(Emo, levels = c('neutral','spider'))) %>% \n  na.omit()\n# Regression Model.\nEPN.sess1.model <- brm(EPN ~ 1 + treat*Emo + (1 + Emo | fp), \n                       family = gaussian(),\n                       data = detect_sess1,\n                       prior = c(prior(normal(0, 4), class = Intercept),\n                                 prior(normal(0, 4), class = b)),\n                       chains = 4,\n                       file = \"results/models/EPN.sess1.model\", # file to save/reuse model\n                       cores = 4, \n                       iter = 3000,\n                       warmup = 1000,\n                       init_r = 0.5,\n                       save_pars = save_pars(all = TRUE))\n# Model Summary.\nsummary(EPN.sess1.model)\n```\n\n### Bayes factor {.tabset}\nonly spider and neutral\n\n#### computations\n```{r}\nnull.sess1.model <- brm(EPN ~ 1 + (1 + Emo | fp),\n                        family = gaussian(),\n                        data = detect_sess1,\n                        prior = prior(normal(0, 4), class = Intercept),\n                        chains = 4,\n                        file = \"results/models/EPN.sess1.null\", \n                        # Specify file to save/reuse model\n                        cores = 4, \n                        iter = 3000,\n                        warmup = 1000,\n                        init_r = 0.5,\n                        save_pars = save_pars(all = TRUE))\nemo.sess1.model <- brm(EPN ~ 1 + Emo + (1 + Emo | fp),\n                       family =  gaussian(),\n                       data = detect_sess1,\n                       prior = c(prior(normal(0, 4), class = Intercept),\n                                 prior(normal(0, 4), class = b)),\n                       chains = 4,\n                       file = \"results/models/EPN.sess1.emo\", \n                       # Specify file to save/reuse model\n                       cores = 4, \n                       iter = 3000,\n                       warmup = 1000,\n                       init_r = 0.5,\n                       save_pars = save_pars(all = TRUE))\ntreat.sess1.model <- brm(EPN ~ 1 + treat + (1 + Emo | fp),\n                         family =  gaussian(),\n                         data = detect_sess1,\n                         prior = c(prior(normal(0, 4), class = Intercept),\n                                   prior(normal(0, 4), class = b)),\n                         chains = 4,\n                         file = \"results/models/EPN.sess1.treat\", \n                         # Specify file to save/reuse model\n                         cores = 4, \n                         iter = 3000,\n                         warmup = 1000,\n                         init_r = 0.5,\n                         save_pars = save_pars(all = TRUE))\n```\n\nCompute bayes factor approximations (via bridge sampling)\n```{r}\n# Bayes factor comparisons are in favor of alternative hypothesis.\nfull.sess1.bayes <- bayes_factor(EPN.sess1.model, null.sess1.model)\ntreat.sess1.bayes <- bayes_factor(treat.sess1.model, null.sess1.model)\nemo.sess1.bayes <- bayes_factor(emo.sess1.model, null.sess1.model)\n\nfull.sess1.bayes\ntreat.sess1.bayes\nemo.sess1.bayes\n```\n\n#### compare with null\n```{r}\ntibble(model = c(\"TreatxEmo\", \"Treat\", \"Emo\"),\n       Compared_To_Null = format(c(full.sess1.bayes$bf, \n                                   treat.sess1.bayes$bf, \n                                   emo.sess1.bayes$bf), scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### compare with Emo\n```{r}\ntibble(model = c(\"TreatxEmo\", \"Treat\", \"Emo\"),\n       Compared_To_Emo = format(c(full.sess1.bayes$bf/emo.sess1.bayes$bf, \n                                  treat.sess1.bayes$bf/emo.sess1.bayes$bf,\n                                  emo.sess1.bayes$bf/emo.sess1.bayes$bf), \n                                scientific = TRUE), \n           BF01 = format(c(emo.sess1.bayes$bf/full.sess1.bayes$bf, \n                           emo.sess1.bayes$bf/treat.sess1.bayes$bf,\n                           emo.sess1.bayes$bf/emo.sess1.bayes$bf), \n                                scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### check assumptions {.tabset}\nLinear regression has these assumptions:  \n\n1. Linear association\n2. Normality of residuals\n3. No heteroskedasticity\n4. No multicollinearity\n\n##### linearity\n```{r}\n# Check linearity\nna.omit(detect_sess1) %>%\n  #add_residual_draws(EPN.sess1.model) %>%\n  add_residual_draws(EPN.sess1.model, ndraws = 1) %>%\n  ggplot(aes(x = .row, y = .residual)) +\n  stat_pointinterval()\n```\n\n##### normality\n```{r}\n# Check normality\nna.omit(detect_sess1) %>%\n  add_residual_draws(EPN.sess1.model, ndraws = 1) %>%\n  median_qi() %>%\n  ggplot(aes(sample = .residual)) +\n  geom_qq() +\n  geom_qq_line()\n```\n\n##### multicollinearity\n```{r}\n# Check vif and tolerance\ncheck_collinearity(EPN.sess1.model)\n```\n\n## treatment comparison {.tabset}\n* session 1 and session 2 (session 1 as reference)\n* include only treatment groups\n* IVET = -.5, VRET = .5\n* use neutral pictures as reference emotion\n```{r}\nmodel_name <- \"only_treat_EPN\"\nmodel_formula <- formula(\"EPN ~ 1 + treat*sess*Emo + (1 + sess * Emo | fp)\")\ndata <- detect_only_treat_recode\nif (file.exists(sprintf(\"results/models/model_%s.RDS\", model_name))) {\n  assign(get(\"model_name\"), readRDS(sprintf(\"results/models/model_%s.RDS\", model_name)))\n} else {\n  assign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                           control = lmerControl(optimizer = \"nloptwrap\",\n                                                                 optCtrl = list(maxfun = 1e7),\n                                                                 calc.derivs = FALSE), \n                                           data = data))\n  saveRDS(eval(parse(text = model_name)), sprintf(\"results/models/model_%s.RDS\", model_name))\n}\n```\n\n### plot {.tabset}\n#### all categories\n```{r}\nfits <- data %>%\n  modelr::data_grid(treat, sess, Emo, fp) %>%\n  mutate(predicted_re = predict(get(model_name), .),\n         fp_treat = sprintf(\"%s_%s\", fp, treat)) %>%\n  filter(fp_treat %in% sprintf(\"%s_%s\", data$fp, data$treat)) %>%\n  mutate(sess = ifelse(sess == 0, 'pre', 'post'),\n         sess = factor(sess, levels = c('pre', 'post')),\n         treat = ifelse(treat == -.5, \"IVET\", \"VRET\"))\nggeffects::ggpredict(get(model_name), c(\"treat\", \"sess\", \"Emo\")) %>%\n  data.frame() %>%\n  mutate(group = ifelse(group == 0, 'pre', 'post'),\n         group = factor(group, levels = c('pre', 'post')),\n         x = ifelse(x == -.5, \"IVET\", \"VRET\"),\n         Emo = facet) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat,\n                             group = interaction(fp, treat, Emo)), alpha = .3, size = .2) +\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  facet_grid(~Emo) +\n  scale_color_manual(values = palette[2:3], name = \"treatment\") +\n  labs(y = \"predicted mean amplitude (V)\\n\", x = \"\\nsession\") +\n  plot_aes\n```\n\n#### spider and neutral\n```{r}\nfits <- data %>%\n  modelr::data_grid(treat, sess, Emo, fp) %>%\n  mutate(predicted_re = predict(get(model_name), .),\n         fp_treat = sprintf(\"%s_%s\", fp, treat)) %>%\n  filter(fp_treat %in% sprintf(\"%s_%s\", data$fp, data$treat)) %>%\n  filter(Emo %in% c(\"neutral\", \"spider\")) %>%\n  mutate(sess = ifelse(sess == 0, 'pre', 'post'),\n         sess = factor(sess, levels = c('pre', 'post')),\n         treat = ifelse(treat == -.5, \"IVET\", \"VRET\"))\nggeffects::ggpredict(get(model_name), c(\"treat\", \"sess\", \"Emo\")) %>%\n  data.frame() %>%\n  filter(facet %in% c(\"neutral\", \"spider\")) %>%\n  mutate(group = ifelse(group == 0, 'pre', 'post'),\n         group = factor(group, levels = c('pre', 'post')),\n         x = ifelse(x == -.5, \"IVET\", \"VRET\"),\n         Emo = facet) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat,\n                             group = interaction(fp, treat, Emo)), alpha = .3, size = .2) +\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  facet_grid(~Emo) +\n  scale_color_manual(values = palette[2:3], name = \"treatment\") +\n  labs(y = \"Predicted amp (V)\\n\", x = \"\\nsession\") +\n  plot_aes\nggsave('results/figures/fig_estimated_EPN_treat.png', plot = last_plot())\n```\n\n### summarize model\n```{r}\nsummary(get(model_name))\ntidied_model <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\n\n### model table {.tabset}\n#### table of labels\n```{r}\neffectlbls <- data.frame(\n  num = as.character(seq(1:16)), \n  original = tidied_model$term[1:16],\n  standard = c(\"intercept (avr_treat, session (1), neutral)\",\n               \"treatment (VRET vs IVET)\",\n               \"session (2)\",\n               \"emotion (spider)\",\n               \"emotion (negative)\",\n               \"emotion (positive)\",\n               \"treatment (VRET vs IVET) x session\",\n               \"treatment (VRET vs IVET) x emotion (spider)\",\n               \"treatment (VRET vs IVET) x emotion (negative)\",\n               \"treatment (VRET vs IVET) x emotion (positive)\",\n               \"session x emotion (spider)\",\n               \"session x emotion (negative)\",\n               \"session x emotion (positive)\",\n               \"treatment (VRET vs IVET) x session x emotion (spider)\",\n               \"treatment (VRET vs IVET) x session x emotion (negative)\",\n               \"treatment (VRET vs IVET) x session x emotion (positive)\"),\n  condition = c(\"treatment (avr_treat) / session (1) / emotion (neutral)\",\n                \"treatment (VRET vs IVET) / sess (1) / emotion (neutral)\",\n                \"treatment (avr_treat) / sess (2) / emotion (neutral)\",\n                \"treatment (avr_treat) / sess (1) / emotion (spider)\",\n                \"treatment (avr_treat) / sess (1) / emotion (negative)\",\n                \"treatment (avr_treat) / sess (1) / emotion (positive)\",\n                \"treatment (VRET vs IVET) / sess (2) / emotion (neutral)\",\n                \"treatment (VRET vs IVET) / sess (1) / emotion (spider)\",\n                \"treatment (VRET vs IVET) / sess (1) / emotion (negative)\",\n                \"treatment (VRET vs IVET) / sess (1) / emotion (positive)\",\n                \"treatment (avr_treat) / sess (2) / emotion (spider)\",\n                \"treatment (avr_treat) / sess (2) / emotion (negative)\",\n                \"treatment (avr_treat) / sess (2) / emotion (positive)\",\n                \"treatment (VRET vs IVET) / sess (2) / emotion (spider)\",\n                \"treatment (VRET vs IVET) / sess (2) / emotion (negative)\",\n                \"treatment (VRET vs IVET) / sess (2) / emotion (positive)\"),\n  stringsAsFactors = F)\neffectlbls %>%\n  kable() %>%\n  kable_styling()\n```\n\n#### standard labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"only treat model\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,3]))\n```\n\n#### condition labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"only treat model\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,4]))\n```\n\n### interpretation\n```{r}\ntm <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\nThe goal is to examine whether IVET and VRET differ from each other in spider (vs neutral) mean amps in the first session and between the first and second session (but not in any other picture category). \n\nThe formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  \nSess * Emo as random effects: This means that emo, session, and the 2-way interaction can differ between subjects. \n\nIntercept = treatment(avr_treat) / session (1) / emotion (neutral).  \navr_treat is the mean of IVET and VRET.  \n\nThe effect for the intercept = **`r myround(tm$estimate[tm$term==\"(Intercept)\"], 2)`**. This is the mean amp for the intercept that contains the average across treatments in session 1 to neutral pictures.  \n\nThe effect of the interaction is added to this together with lower-order terms to get the marginal mean. An interaction parameter is how much it differs from the lower order terms and the t-test is for the null hypothesis that the difference between these parameters is 0. When testing higher effects, the lower effects are removed. That is, the higher effects test for something over and above the lower effects. Accordingly, the estimated marginal means are the intercept + lower effects + estimate for higher effect. \n\nWe want to see whether the groups showed lower amps to spiders than neutral pictures in session 1.  \n`r pickme = \"Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nIndeed, mean amps are relatively negative to spiders.  \n\nDid the groups differ in how they responded to spiders versus neutral pictures in session 1? No.  \n`r pickme = \"treat:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \n\nDid the effect of spiders differ between sessions: No difference! \n  `r pickme = \"sess:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \n\nCritically, did this effect vary with treatment? No difference!  \n  `r pickme = \"treat:sess:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \n\n### estimated means\n```{r}\ndata %>%\n  modelr::data_grid(treat, Emo, sess) %>%\n  mutate(marginal_mean = predict(get(model_name), ., re.form = NA),\n         treat = ifelse(treat == -.5, \"IVET\", \"VRET\"),\n         sess = ifelse(sess == 0, 'pre', 'post'),\n         sess = factor(sess, levels = c('pre', 'post'))) %>%\n  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%\n  kable(digits = 2) %>%\n  kable_styling()\n```\n\n### Bayes {.tabset}\nonly spider and neutral\n\n#### gaussian model\n```{r}\ndetect_treat <- detect_only_treat_recode %>% \n  select(Emo, EPN, LPP, fp, sess, treat) %>% \n  filter(Emo %in% c('spider', 'neutral')) %>% \n  mutate(fp = as.factor(fp),\n         Emo = factor(Emo, levels = c('neutral','spider'))) %>% \n  na.omit()\n# Regression Model.\nEPN.treat.model <- brm(EPN ~ 1 + treat*sess*Emo + (1 + sess*Emo | fp), \n                       family = gaussian(),\n                       data = detect_treat,\n                       prior = c(prior(normal(0, 4), class = Intercept),\n                                 prior(normal(0, 4), class = b)),\n                       chains = 4,\n                       file = \"results/models/EPN.treat.model\", # file to save/reuse model\n                       cores = 4, \n                       iter = 3000,\n                       warmup = 1000,\n                       init_r = 0.5,\n                       save_pars = save_pars(all = TRUE))\n# Model Summary.\nsummary(EPN.treat.model)\n```\n\n### Bayes factor {.tabset}\nonly spider and neutral\n\n#### computations\n```{r}\nnull.treat.model <- brm(EPN ~ 1 + (1 + sess*Emo | fp),\n                        family = gaussian(),\n                        data = detect_treat,\n                        prior = prior(normal(0, 4), class = Intercept),\n                        chains = 4,\n                        file = \"results/models/EPN.treat.null\", \n                        # Specify file to save/reuse model\n                        cores = 4, \n                        iter = 3000,\n                        warmup = 1000,\n                        init_r = 0.5,\n                        save_pars = save_pars(all = TRUE))\nsess_emo.treat.model <- brm(EPN ~ 1 + sess*Emo + (1 + sess*Emo | fp),\n                            family = gaussian(),\n                            data = detect_treat,\n                            prior = c(prior(normal(0, 4), class = Intercept),\n                                      prior(normal(0, 4), class = b)),\n                            chains = 4,\n                            file = \"results/models/EPN.treat.sess_emo\", \n                            cores = 4, \n                            iter = 3000,\n                            warmup = 1000,\n                            save_pars = save_pars(all = TRUE))\nemo.treat.model <- brm(EPN ~ 1 + Emo + (1 + sess*Emo | fp),\n                       family = gaussian(),\n                       data = detect_treat,\n                       prior = c(prior(normal(0, 4), class = Intercept),\n                                 prior(normal(0, 4), class = b)),\n                       chains = 4,\n                       file = \"results/models/EPN.treat.emo\", \n                       cores = 4, \n                       iter = 3000,\n                       warmup = 1000,\n                       save_pars = save_pars(all = TRUE))\n```\n\nCompute bayes factor approximations (via bridge sampling)\n```{r}\n# Bayes factor comparisons are in favor of alternative hypothesis.\nfull.treat.bayes <- bayes_factor(EPN.treat.model, null.treat.model)\nsess_emo.treat.bayes <- bayes_factor(sess_emo.treat.model, null.treat.model)\nemo.treat.bayes <- bayes_factor(emo.treat.model, null.treat.model)\n\nfull.treat.bayes\nsess_emo.treat.bayes\nemo.treat.bayes\n```\n\n#### compare with null\n```{r}\ntibble(model = c(\"TreatxSessxEmo\", \"SessxEmo\", \"Emo\"),\n       Compared_To_Null = format(c(full.treat.bayes$bf, \n                                   sess_emo.treat.bayes$bf, \n                                   emo.treat.bayes$bf), scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### compare with Treat x Sess x Emo\n```{r}\ntibble(model = c(\"TreatxSessxEmo\", \"SessxEmo\", \"Emo\"),\n       Compared_To_Treat.Sess.Emo = \n         format(c(full.treat.bayes$bf/full.treat.bayes$bf, \n                  sess_emo.treat.bayes$bf/full.treat.bayes$bf, \n                  emo.treat.bayes$bf/full.treat.bayes$bf),\n                                           scientific = TRUE),\n       BF01 = \n         format(c(full.treat.bayes$bf/full.treat.bayes$bf, \n                  full.treat.bayes$bf/sess_emo.treat.bayes$bf, \n                  full.treat.bayes$bf/emo.treat.bayes$bf),\n                                           scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### compare with Sess x Emo\n```{r}\ntibble(model = c(\"TreatxSessxEmo\", \"SessxEmo\", \"Emo\"),\n       Compared_To_Sess.Emo = format(c(full.treat.bayes$bf/sess_emo.treat.bayes$bf, \n                                       sess_emo.treat.bayes$bf/sess_emo.treat.bayes$bf,\n                                       emo.treat.bayes$bf/sess_emo.treat.bayes$bf),\n                                     scientific = TRUE),\n       BF01 = format(c(sess_emo.treat.bayes$bf/full.treat.bayes$bf, \n                       sess_emo.treat.bayes$bf/sess_emo.treat.bayes$bf,\n                       sess_emo.treat.bayes$bf/emo.treat.bayes$bf),\n                                     scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### compare with Emo\n```{r}\ntibble(model = c(\"TreatxSessxEmo\", \"SessxEmo\", \"Emo\"),\n       Compared_To_Emo = format(c(full.treat.bayes$bf/emo.treat.bayes$bf, \n                                  sess_emo.treat.bayes$bf/emo.treat.bayes$bf, \n                                  emo.treat.bayes$bf/emo.treat.bayes$bf),\n                                scientific = TRUE),\n       BF01 = format(c(emo.treat.bayes$bf/full.treat.bayes$bf, \n                       emo.treat.bayes$bf/sess_emo.treat.bayes$bf, \n                       emo.treat.bayes$bf/emo.treat.bayes$bf),\n                                scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### check assumptions {.tabset}\nLinear regression has these assumptions:  \n\n1. Linear association\n2. Normality of residuals\n3. No heteroskedasticity\n4. No multicollinearity\n\n##### linearity\n```{r}\n# Check linearity\nna.omit(detect_treat) %>%\n  add_residual_draws(EPN.treat.model, ndraws = 1) %>%  \n  ggplot(aes(x = .row, y = .residual)) +\n  stat_pointinterval()\n```\n\n##### normality\n```{r}\n# Check normality\nna.omit(detect_treat) %>%\n  add_residual_draws(EPN.treat.model, ndraws = 1) %>%\n  median_qi() %>%\n  ggplot(aes(sample = .residual)) +\n  geom_qq() +\n  geom_qq_line()\n```\n\n##### multicollinearity\n```{r}\n# Check vif and tolerance\ncheck_collinearity(EPN.treat.model)\n```\n\n# EEG: LPP-relevant amplitude\nEEG data during the detection task  \n\n## session 1 three groups {.tabset}\n* use session 1 from all three groups  \n* examine whether IVET and VRET differ from controls to spiders (vs neutral) in session 1\n* compare IVET and VRET separately to the control group\n* do not test whether the treatments differ from each other\n* use neutral pictures as reference emotion\n* save the model to save time  \n```{r}\nmodel_name <- \"session_pre_all_groups_LPP\"\nmodel_formula <- formula(\"LPP ~ 1 + treat*Emo + (1 + Emo | fp)\")\ndata <- detect_baseline\nif (file.exists(sprintf(\"results/models/model_%s.RDS\", model_name))) {\n  assign(get(\"model_name\"), readRDS(sprintf(\"results/models/model_%s.RDS\", model_name)))\n} else {\n  assign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                           control = lmerControl(optimizer = \"Nelder_Mead\",\n                                                                 optCtrl = list(maxfun = 1e7),\n                                                                 calc.derivs = FALSE), \n                                           data = data))\n  saveRDS(eval(parse(text = model_name)), sprintf(\"results/models/model_%s.RDS\", model_name))\n}\n# nloptwrap: Model failed to converge with 1 negative eigenvalue: -8.0e+02\n```\n\n### plot {.tabset}\n```{r}\nfits <- data %>%\n  modelr::data_grid(treat, Emo, fp) %>%\n  mutate(predicted_re = predict(get(model_name), .),\n         fp_treat = sprintf(\"%s_%s\", fp, treat)) %>%\n  filter(fp_treat %in% sprintf(\"%s_%s\", data$fp, data$treat))\nggeffects::ggpredict(get(model_name), c(\"treat\", \"Emo\")) %>%\n  data.frame() %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(data = fits, aes(x = Emo, y = predicted_re, color = treat,\n                             group = interaction(fp, treat)), alpha = .3, size = .2) +\n  geom_line(aes(group = x), position = position_dodge(width = .15), size = 1) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .15), size = .5) +\n  scale_color_manual(values = palette, name = \"treatment\") +\n  labs(y = \"Predicted amp (V)\\n\", x = \"\\nemotion\") +\n  plot_aes\nggsave('results/figures/fig_meanamps_LPP_pre.png', plot = last_plot())\n```\n\n### summarize model\n```{r}\nsummary(get(model_name))\ntidied_model <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\n\n### model table {.tabset}\n#### table of labels\n```{r}\neffectlbls <- data.frame(\n  num = as.character(seq(1:12)), \n  original = tidied_model$term[1:12],\n  standard = c(\"intercept (control, neutral)\", \n               \"treatment (IVET)\", \n               \"treatment (VRET)\", \n               \"emotion (spider)\", \n               \"emotion (negative)\", \n               \"emotion (positive)\",\n               \"treatment (IVET) x emotion (spider)\",\n               \"treatment (VRET) x emotion (spider)\",\n               \"treatment (IVET) x emotion (negative)\", \n               \"treatment (VRET) x emotion (negative)\",\n               \"treatment (IVET) x emotion (positive)\", \n               \"treatment (VRET) x emotion (positive)\"),\n  condition = c(\"treatment (control) / emotion (neutral)\", \n                \"treatment (IVET) / emotion (neutral)\", \n                \"treatment (VRET) / emotion (neutral)\", \n                \"treatment (control) / emotion (spider)\", \n                \"treatment (control) / emotion (negative)\", \n                \"treatment (control) / emotion (positive)\",\n                \"treatment (IVET) / emotion (spider)\", \n                \"treatment (VRET) / emotion (spider)\",\n                \"treatment (IVET) / emotion (negative)\", \n                \"treatment (VRET) / emotion (negative)\",\n                \"treatment (IVET) / emotion (positive)\", \n                \"treatment (VRET) / emotion (positive)\"),\n  stringsAsFactors = F)\neffectlbls %>%\n  kable() %>%\n  kable_styling()\n```\n\n#### standard labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"session 1\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,3]))\n```\n\n#### condition labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"session 1\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,4]))\n```\n\n### interpretation\n```{r}\ntm <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\nThe goal is to examine whether IVET and VRET differ from controls in spider (vs neutral) mean amplitude in the first session (but not in any other picture category). The analysis compares IVET and VRET separately to the control group and does not test whether the treatments differ from each other.\n\nThe formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  \nEmo as random effect.  \n\nIntercept = treatment(control) / emotion(neutral).  \n\nThe effect for the intercept = **`r myround(tm$estimate[tm$term==\"(Intercept)\"], 2)`**. This is the mean amplitude for the intercept that contains treatment(control) and emotion(neutral) and is thus the marginal mean for the control group for neutral pictures.  \n\nThe first effect shows that there is an effect of spider (vs neutral). It shows that for the control group, spiders have higher amps than neutral pictures. This relative positivity supports an LPP. But, this effect is not of particular interest because it is only for the control group.  \n\n`r pickme = \"Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \n\nThe main interest is to see whether IVET and VRET differ from controls in their amps to spiders. Particularly, the difference between spiders and neutral pictures should be more positive for each treatment group compared to controls. Because the intercept contains treatment(control) and emotion(neutral), we are interested in these tests:   \n  \n  **For IVET**:  \n  `r pickme = \"treatIVET:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nThis is the interaction of treatment(IVET vs control) x emotion (spider vs neutral).  \n\n**For VRET (same test as for IVET)**:  \n  `r pickme = \"treatVRET:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nThis is the interaction of treatment(VRET vs control) x emotion (spider vs neutral).  \n\n### estimated means\n```{r}\ndata %>%\n  modelr::data_grid(treat, Emo) %>%\n  mutate(marginal_mean = predict(get(model_name), ., re.form = NA),) %>%\n  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%\n  kable(digits = 2) %>%\n  kable_styling()\n```\n\n## session 1 across treatments {.tabset}\n* use session 1 from all three groups\n* combine treatment groups\n* use neutral pictures as reference emotion\n* save the model to save time\n```{r}\nmodel_name <- \"session_pre_across_treat_LPP\"\nmodel_formula <- formula(\"LPP ~ 1 + treat*Emo + (1 + Emo | fp)\")\ndata <- detect_baseline_acrosstreatment\nif (file.exists(sprintf(\"results/models/model_%s.RDS\", model_name))) {\n  assign(get(\"model_name\"), readRDS(sprintf(\"results/models/model_%s.RDS\", model_name)))\n} else {\n  assign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                           control = lmerControl(optimizer = \"nloptwrap\",\n                                                                 optCtrl = list(maxfun = 1e7),\n                                                                 calc.derivs = FALSE), \n                                           data = data))\n  saveRDS(eval(parse(text = model_name)), sprintf(\"results/models/model_%s.RDS\", model_name))\n}\n```\n\n### plot {.tabset}\n```{r}\nfits <- data %>%\n  modelr::data_grid(treat, Emo, fp) %>%\n  mutate(predicted_re = predict(get(model_name), .),\n         fp_treat = sprintf(\"%s_%s\", fp, treat)) %>%\n  filter(fp_treat %in% sprintf(\"%s_%s\", data$fp, data$treat))\nggeffects::ggpredict(get(model_name), c(\"treat\", \"Emo\")) %>%\n  data.frame() %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(data = fits, aes(x = Emo, y = predicted_re, color = treat,\n                             group = interaction(fp, treat)), alpha = .3, size = .2) +\n  geom_line(aes(group = x), position = position_dodge(width = .1), size = 1) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1), size = .5) +\n  scale_color_manual(values = palette2, name = \"treatment\") +\n  labs(y = \"predicted mean amplitude (V)\\n\", x = \"\\nemotion\") +\n  plot_aes\n```\n\n### summarize model\n```{r}\nsummary(get(model_name))\ntidied_model <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\n\n### model table {.tabset}\n#### table of labels\n```{r}\neffectlbls <- data.frame(\n  num = as.character(seq(1:8)), \n  original = tidied_model$term[1:8],\n  standard = c(\"intercept (control, neutral)\", \n               \"treatment (IVET/VRET)\", \n               \"emotion (spider)\", \n               \"emotion (negative)\", \n               \"emotion (positive)\",\n               \"treatment (IVET/VRET) x emotion (spider)\",\n               \"treatment (IVET/VRET) x emotion (negative)\", \n               \"treatment (IVET/VRET) x emotion (positive)\"), \n  condition = c(\"treatment (control) / emotion (neutral)\", \n                \"treatment (IVET/VRET) / emotion (neutral)\", \n                \"treatment (control) / emotion (spider)\", \n                \"treatment (control) / emotion (negative)\", \n                \"treatment (control) / emotion (positive)\",\n                \"treatment (IVET/VRET) / emotion (spider)\", \n                \"treatment (IVET/VRET) / emotion (negative)\", \n                \"treatment (IVET/VRET) / emotion (positive)\"), \n  stringsAsFactors = F)\neffectlbls %>%\n  kable() %>%\n  kable_styling()\n```\n\n#### standard labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"session 1\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,3]))\n```\n\n#### condition labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"session 1\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,4]))\n```\n\n### interpretation\n```{r}\ntm <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\nThe goal is to examine whether the combined treatment groups (IVET and VRET) differ from controls in spider (vs neutral) mean amplitude in the first session (but not in any other picture category). The analysis compares the combined IVET and VRET to the control group and does not test whether the treatments differ from each other.\n\nThe formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  \nEmo as random effect.  \n\nIntercept = treatment(control) / emotion(neutral).  \n\nThe effect for the intercept = **`r myround(tm$estimate[tm$term==\"(Intercept)\"], 2)`**. This is the mean amplitude for the intercept that contains treatment(control) and emotion(neutral) and is thus the marginal mean for the control group for neutral pictures.  \n\nThe first effect shows that there is an effect of spider (vs neutral). It shows that for the control group, spiders have higher amps than neutral pictures. This relative positivity supports an LPP. But, this effect is not of particular interest because it is only for the control group.  \n\n`r pickme = \"Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \n\nThe main interest is to see whether the combined treatment groups (IVET and VRET) differ from controls in their amps to spiders. Particularly, the difference between spiders and neutral pictures should be more positive across treatment groups compared to controls. Because the intercept contains treatment(control) and emotion(neutral), we are interested in this test:   \n  \n  `r pickme = \"treatIVET/VRET:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nThis is the interaction of treatment(IVET/VRET vs control) x emotion (spider vs neutral) across ratings.  \n\n### estimated means\n```{r}\ndata %>%\n  modelr::data_grid(treat, Emo) %>%\n  mutate(marginal_mean = predict(get(model_name), ., re.form = NA),) %>%\n  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%\n  kable(digits = 2) %>%\n  kable_styling()\n```\n\n### Bayes {.tabset}\nonly spider and neutral\n\n#### gaussian model\n```{r}\n# Prepare dataframe.\ndetect_sess1 <- detect_baseline_acrosstreatment %>% \n  select(Emo, EPN, LPP, fp, sess, treat) %>% \n  filter(Emo %in% c('spider', 'neutral')) %>% \n  mutate(fp = as.factor(fp),\n         Emo = factor(Emo, levels = c('neutral','spider'))) %>% \n  na.omit()\n# Regression Model.\nLPP.sess1.model <- brm(LPP ~ 1 + treat*Emo + (1 + Emo | fp), \n                       family = gaussian(),\n                       data = detect_sess1,\n                       prior = c(prior(normal(0, 4), class = Intercept),\n                                 prior(normal(0, 4), class = b)),\n                       chains = 4,\n                       file = \"results/models/LPP.sess1.model\", \n                       # file to save/reuse model\n                       cores = 4, \n                       iter = 3000,\n                       warmup = 1000,\n                       init_r = 0.5,\n                       save_pars = save_pars(all = TRUE))\n# Model Summary.\nsummary(LPP.sess1.model)\n```\n\n### Bayes factor {.tabset}\nonly spider and neutral\n\n#### computations\n```{r}\nnull.sess1.model <- brm(LPP ~ 1 + (1 + Emo | fp),\n                        family = gaussian(),\n                        data = detect_sess1,\n                        prior = prior(normal(0, 4), class = Intercept),\n                        chains = 4,\n                        file = \"results/models/LPP.sess1.null\", \n                        # Specify file to save/reuse model\n                        cores = 4, \n                        iter = 3000,\n                        warmup = 1000,\n                        init_r = 0.5,\n                        save_pars = save_pars(all = TRUE))\nemo.sess1.model <- brm(LPP ~ 1 + Emo + (1 + Emo | fp),\n                       family =  gaussian(),\n                       data = detect_sess1,\n                       prior = c(prior(normal(0, 4), class = Intercept),\n                                 prior(normal(0, 4), class = b)),\n                       chains = 4,\n                       file = \"results/models/LPP.sess1.emo\", \n                       # Specify file to save/reuse model\n                       cores = 4, \n                       iter = 3000,\n                       warmup = 1000,\n                       init_r = 0.5,\n                       save_pars = save_pars(all = TRUE))\ntreat.sess1.model <- brm(LPP ~ 1 + treat + (1 + Emo | fp),\n                         family =  gaussian(),\n                         data = detect_sess1,\n                         prior = c(prior(normal(0, 4), class = Intercept),\n                                   prior(normal(0, 4), class = b)),\n                         chains = 4,\n                         file = \"results/models/LPP.sess1.treat\", \n                         # Specify file to save/reuse model\n                         cores = 4, \n                         iter = 3000,\n                         warmup = 1000,\n                         init_r = 0.5,\n                         save_pars = save_pars(all = TRUE))\n```\n\nCompute bayes factor approximations (via bridge sampling)\n```{r}\n# Bayes factor comparisons are in favor of alternative hypothesis.\nfull.sess1.bayes <- bayes_factor(LPP.sess1.model, null.sess1.model)\ntreat.sess1.bayes <- bayes_factor(treat.sess1.model, null.sess1.model)\nemo.sess1.bayes <- bayes_factor(emo.sess1.model, null.sess1.model)\n\nfull.sess1.bayes\ntreat.sess1.bayes\nemo.sess1.bayes\n```\n\n#### compare with null\n```{r}\ntibble(model = c(\"TreatxEmo\", \"Treat\", \"Emo\"),\n       Compared_To_Null = format(c(full.sess1.bayes$bf, \n                                   treat.sess1.bayes$bf, \n                                   emo.sess1.bayes$bf), scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### compare with Emo\n```{r}\ntibble(model = c(\"TreatxEmo\", \"Treat\", \"Emo\"),\n       Compared_To_Emo = format(c(full.sess1.bayes$bf/emo.sess1.bayes$bf, \n                                  treat.sess1.bayes$bf/emo.sess1.bayes$bf,\n                                  emo.sess1.bayes$bf/emo.sess1.bayes$bf), \n                                scientific = TRUE), \n           BF01 = format(c(emo.sess1.bayes$bf/full.sess1.bayes$bf, \n                           emo.sess1.bayes$bf/treat.sess1.bayes$bf,\n                           emo.sess1.bayes$bf/emo.sess1.bayes$bf), \n                                scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### check assumptions {.tabset}\nLinear regression has these assumptions:  \n\n1. Linear association\n2. Normality of residuals\n3. No heteroskedasticity\n4. No multicollinearity\n\n##### linearity\n```{r}\n# Check linearity\nna.omit(detect_sess1) %>%\n  add_residual_draws(LPP.sess1.model, ndraws = 1) %>%\n  ggplot(aes(x = .row, y = .residual)) +\n  stat_pointinterval()\n```\n\n##### normality\n```{r}\n# Check normality\nna.omit(detect_sess1) %>%\n  add_residual_draws(LPP.sess1.model, ndraws = 1) %>%\n  median_qi() %>%\n  ggplot(aes(sample = .residual)) +\n  geom_qq() +\n  geom_qq_line()\n```\n\n##### multicollinearity\n```{r}\n# Check vif and tolerance\ncheck_collinearity(LPP.sess1.model)\n```\n\n## treatment comparison {.tabset}\n* session 1 and session 2 (session 1 as reference)\n* include only treatment groups\n* IVET = -.5, VRET = .5\n* use neutral pictures as reference emotion\n```{r}\nmodel_name <- \"only_treat_LPP\"\nmodel_formula <- formula(\"LPP ~ 1 + treat*sess*Emo + (1 + sess * Emo | fp)\")\ndata <- detect_only_treat_recode\nif (file.exists(sprintf(\"results/models/model_%s.RDS\", model_name))) {\n  assign(get(\"model_name\"), readRDS(sprintf(\"results/models/model_%s.RDS\", model_name)))\n} else {\n  assign(get(\"model_name\"), lmerTest::lmer(model_formula,\n                                           control = lmerControl(optimizer = \"Nelder_Mead\",\n                                                                 optCtrl = list(maxfun = 1e7),\n                                                                 calc.derivs = FALSE), \n                                           data = data))\n  saveRDS(eval(parse(text = model_name)), sprintf(\"results/models/model_%s.RDS\", model_name))\n}\n# nloptwrap: Model failed to converge with 4 negative eigenvalues: -1.3e-02 -7.1e-02 -1.7e-01 -7.8e+01\n# Nelder_Mead: Model failed to converge with 2 negative eigenvalues: -3.5e+01 -4.4e+01\n```\n\n### plot {.tabset}\n#### all categories\n```{r}\nfits <- data %>%\n  modelr::data_grid(treat, sess, Emo, fp) %>%\n  mutate(predicted_re = predict(get(model_name), .),\n         fp_treat = sprintf(\"%s_%s\", fp, treat)) %>%\n  filter(fp_treat %in% sprintf(\"%s_%s\", data$fp, data$treat)) %>%\n  mutate(sess = ifelse(sess == 0, 'pre', 'post'),\n         sess = factor(sess, levels = c('pre', 'post')),\n         treat = ifelse(treat == -.5, \"IVET\", \"VRET\"))\nggeffects::ggpredict(get(model_name), c(\"treat\", \"sess\", \"Emo\")) %>%\n  data.frame() %>%\n  mutate(group = ifelse(group == 0, 'pre', 'post'),\n         group = factor(group, levels = c('pre', 'post')),\n         x = ifelse(x == -.5, \"IVET\", \"VRET\"),\n         Emo = facet) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat,\n                             group = interaction(fp, treat, Emo)), alpha = .3, size = .2) +\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  facet_grid(~Emo) +\n  scale_color_manual(values = palette[2:3], name = \"treatment\") +\n  labs(y = \"predicted mean amplitude (V)\\n\", x = \"\\nsession\") +\n  plot_aes\n```\n\n#### spider and neutral\n```{r}\nfits <- data %>%\n  modelr::data_grid(treat, sess, Emo, fp) %>%\n  mutate(predicted_re = predict(get(model_name), .),\n         fp_treat = sprintf(\"%s_%s\", fp, treat)) %>%\n  filter(fp_treat %in% sprintf(\"%s_%s\", data$fp, data$treat)) %>%\n  filter(Emo %in% c(\"neutral\", \"spider\")) %>%\n  mutate(sess = ifelse(sess == 0, 'pre', 'post'),\n         sess = factor(sess, levels = c('pre', 'post')),\n         treat = ifelse(treat == -.5, \"IVET\", \"VRET\"))\nggeffects::ggpredict(get(model_name), c(\"treat\", \"sess\", \"Emo\")) %>%\n  data.frame() %>%\n  filter(facet %in% c(\"neutral\", \"spider\")) %>%\n  mutate(group = ifelse(group == 0, 'pre', 'post'),\n         group = factor(group, levels = c('pre', 'post')),\n         x = ifelse(x == -.5, \"IVET\", \"VRET\"),\n         Emo = facet) %>%\n  ggplot(aes(group, predicted, color = x)) +\n  geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat,\n                             group = interaction(fp, treat, Emo)), alpha = .3, size = .2) +\n  geom_line(aes(group = x), position = position_dodge(width = .1)) +\n  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +\n  facet_grid(~Emo) +\n  scale_color_manual(values = palette[2:3], name = \"treatment\") +\n  labs(y = \"Predicted amp (V)\\n\", x = \"\\nsession\") +\n  plot_aes\nggsave('results/figures/fig_estimated_LPP_treat.png', plot = last_plot())\n```\n\n### summarize model\n```{r}\nsummary(get(model_name))\ntidied_model <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\n\n### model table {.tabset}\n#### table of labels\n```{r}\neffectlbls <- data.frame(\n  num = as.character(seq(1:16)), \n  original = tidied_model$term[1:16],\n  standard = c(\"intercept (avr_treat, session (1), neutral)\",\n               \"treatment (VRET vs IVET)\",\n               \"session (2)\",\n               \"emotion (spider)\",\n               \"emotion (negative)\",\n               \"emotion (positive)\",\n               \"treatment (VRET vs IVET) x session\",\n               \"treatment (VRET vs IVET) x emotion (spider)\",\n               \"treatment (VRET vs IVET) x emotion (negative)\",\n               \"treatment (VRET vs IVET) x emotion (positive)\",\n               \"session x emotion (spider)\",\n               \"session x emotion (negative)\",\n               \"session x emotion (positive)\",\n               \"treatment (VRET vs IVET) x session x emotion (spider)\",\n               \"treatment (VRET vs IVET) x session x emotion (negative)\",\n               \"treatment (VRET vs IVET) x session x emotion (positive)\"),\n  condition = c(\"treatment (avr_treat) / session (1) / emotion (neutral)\",\n                \"treatment (VRET vs IVET) / sess (1) / emotion (neutral)\",\n                \"treatment (avr_treat) / sess (2) / emotion (neutral)\",\n                \"treatment (avr_treat) / sess (1) / emotion (spider)\",\n                \"treatment (avr_treat) / sess (1) / emotion (negative)\",\n                \"treatment (avr_treat) / sess (1) / emotion (positive)\",\n                \"treatment (VRET vs IVET) / sess (2) / emotion (neutral)\",\n                \"treatment (VRET vs IVET) / sess (1) / emotion (spider)\",\n                \"treatment (VRET vs IVET) / sess (1) / emotion (negative)\",\n                \"treatment (VRET vs IVET) / sess (1) / emotion (positive)\",\n                \"treatment (avr_treat) / sess (2) / emotion (spider)\",\n                \"treatment (avr_treat) / sess (2) / emotion (negative)\",\n                \"treatment (avr_treat) / sess (2) / emotion (positive)\",\n                \"treatment (VRET vs IVET) / sess (2) / emotion (spider)\",\n                \"treatment (VRET vs IVET) / sess (2) / emotion (negative)\",\n                \"treatment (VRET vs IVET) / sess (2) / emotion (positive)\"),\n  stringsAsFactors = F)\neffectlbls %>%\n  kable() %>%\n  kable_styling()\n```\n\n#### standard labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"only treat model\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,3]))\n```\n\n#### condition labels\n```{r}\ntable_model(get(model_name), \n            dv_labels = \"only treat model\",\n            pred_labels = paste(effectlbls[,1], effectlbls[,4]))\n```\n\n### interpretation\n```{r}\ntm <- get(model_name) %>%\n  broom.mixed::tidy(conf.int = TRUE)\n```\nThe goal is to examine whether IVET and VRET differ from each other in spider (vs neutral) mean amps in the first session and between the first and second session (but not in any other picture category). \n\nThe formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  \nSess * Emo as random effects: This means that emo, session, and the 2-way interaction can differ between subjects. \n\nIntercept = treatment(avr_treat) / session (1) / emotion (neutral).  \navr_treat is the mean of IVET and VRET.  \n\nThe effect for the intercept = **`r myround(tm$estimate[tm$term==\"(Intercept)\"], 2)`**. This is the mean amp for the intercept that contains the average across treatments in session 1 to neutral pictures.  \n\nThe effect of the interaction is added to this together with lower-order terms to get the marginal mean. An interaction parameter is how much it differs from the lower order terms and the *t* test is for the null hypothesis that the difference between these parameters is 0. When testing higher effects, the lower effects are removed. That is, the higher effects test for something over and above the lower effects. Accordingly, the estimated marginal means are the intercept + lower effects + estimate for higher effect. \n\nWe want to see whether the groups showed higher amps to spiders than neutral pictures in session 1.  \n`r pickme = \"Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \nIndeed, mean amps are relatively positive to spiders.  \n\nDid the groups differ in how they responded to spiders versus neutral pictures in session 1? No.  \n`r pickme = \"treat:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \n\nDid the effect of spiders differ between sessions: No difference! \n  `r pickme = \"sess:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \n\nCritically, did this effect vary with treatment? No difference!  \n  `r pickme = \"treat:sess:Emospider\"`\n**`r (pickme)`**  \n  In the model table with condition labels, this is number \n**`r effectlbls$num[effectlbls$original==pickme]`**.  \n\n`r effectlbls$condition[effectlbls$original==pickme]`.  \n- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  \n- p value: `r formatC(tm$p.value[tm$term==pickme], format=\"e\")`  \n\n### estimated means\n```{r}\ndata %>%\n  modelr::data_grid(treat, Emo, sess) %>%\n  mutate(marginal_mean = predict(get(model_name), ., re.form = NA),\n         treat = ifelse(treat == -.5, \"IVET\", \"VRET\"),\n         sess = ifelse(sess == 0, \"1\", \"2\")) %>%\n  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%\n  kable(digits = 2) %>%\n  kable_styling()\n```\n\n### Bayes {.tabset}\nonly spider and neutral\n\n#### gaussian model\n```{r}\ndetect_treat <- detect_only_treat_recode %>% \n  select(Emo, EPN, LPP, fp, sess, treat) %>% \n  filter(Emo %in% c('spider', 'neutral')) %>% \n  mutate(fp = as.factor(fp),\n         Emo = factor(Emo, levels = c('neutral','spider'))) %>% \n  na.omit()\n# Regression Model.\nLPP.treat.model <- brm(LPP ~ 1 + treat*sess*Emo + (1 + sess*Emo | fp), \n                       family = gaussian(),\n                       data = detect_treat,\n                       prior = c(prior(normal(0, 4), class = Intercept),\n                                 prior(normal(0, 4), class = b)),\n                       chains = 4,\n                       file = \"results/models/LPP.treat.model\", \n                       # file to save/reuse model\n                       cores = 4, \n                       iter = 3000,\n                       warmup = 1000,\n                       init_r = 0.5,\n                       save_pars = save_pars(all = TRUE))\n# Model Summary.\nsummary(LPP.treat.model)\n```\n\n### Bayes factor {.tabset}\nonly spider and neutral\n\n#### computations\n```{r}\nnull.treat.model <- brm(LPP ~ 1 + (1 + sess*Emo | fp),\n                        family = gaussian(),\n                        data = detect_treat,\n                        prior = prior(normal(0, 4), class = Intercept),\n                        chains = 4,\n                        file = \"results/models/LPP.treat.null\", \n                        # Specify file to save/reuse model\n                        cores = 4, \n                        iter = 3000,\n                        warmup = 1000,\n                        init_r = 0.5,\n                        save_pars = save_pars(all = TRUE))\nsess_emo.treat.model <- brm(LPP ~ 1 + sess*Emo + (1 + sess*Emo | fp),\n                            family = gaussian(),\n                            data = detect_treat,\n                            prior = c(prior(normal(0, 4), class = Intercept),\n                                      prior(normal(0, 4), class = b)),\n                            chains = 4,\n                            file = \"results/models/LPP.treat.sess_emo\", \n                            cores = 4, \n                            iter = 3000,\n                            warmup = 1000,\n                            save_pars = save_pars(all = TRUE))\nemo.treat.model <- brm(LPP ~ 1 + Emo + (1 + sess*Emo | fp),\n                       family = gaussian(),\n                       data = detect_treat,\n                       prior = c(prior(normal(0, 4), class = Intercept),\n                                 prior(normal(0, 4), class = b)),\n                       chains = 4,\n                       file = \"results/models/LPP.treat.emo\", \n                       cores = 4, \n                       iter = 3000,\n                       warmup = 1000,\n                       save_pars = save_pars(all = TRUE))\n```\n\nCompute bayes factor approximations (via bridge sampling)\n```{r}\n# Bayes factor comparisons are in favor of alternative hypothesis.\nfull.treat.bayes <- bayes_factor(LPP.treat.model, null.treat.model)\nsess_emo.treat.bayes <- bayes_factor(sess_emo.treat.model, null.treat.model)\nemo.treat.bayes <- bayes_factor(emo.treat.model, null.treat.model)\n\nfull.treat.bayes\nsess_emo.treat.bayes\nemo.treat.bayes\n```\n\n#### compare with null\n```{r}\ntibble(model = c(\"TreatxSessxEmo\", \"SessxEmo\", \"Emo\"),\n       Compared_To_Null = format(c(full.treat.bayes$bf, \n                                   sess_emo.treat.bayes$bf, \n                                   emo.treat.bayes$bf), scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### compare with Treat x Sess x Emo\n```{r}\ntibble(model = c(\"TreatxSessxEmo\", \"SessxEmo\", \"Emo\"),\n       Compared_To_Treat.Sess.Emo = \n         format(c(full.treat.bayes$bf/full.treat.bayes$bf, \n                  sess_emo.treat.bayes$bf/full.treat.bayes$bf, \n                  emo.treat.bayes$bf/full.treat.bayes$bf),\n                                           scientific = TRUE),\n       BF01 = \n         format(c(full.treat.bayes$bf/full.treat.bayes$bf, \n                  full.treat.bayes$bf/sess_emo.treat.bayes$bf, \n                  full.treat.bayes$bf/emo.treat.bayes$bf),\n                                           scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### compare with Sess x Emo\n```{r}\ntibble(model = c(\"TreatxSessxEmo\", \"SessxEmo\", \"Emo\"),\n       Compared_To_Sess.Emo = format(c(full.treat.bayes$bf/sess_emo.treat.bayes$bf, \n                                       sess_emo.treat.bayes$bf/sess_emo.treat.bayes$bf,\n                                       emo.treat.bayes$bf/sess_emo.treat.bayes$bf),\n                                     scientific = TRUE),\n       BF01 = format(c(sess_emo.treat.bayes$bf/full.treat.bayes$bf, \n                       sess_emo.treat.bayes$bf/sess_emo.treat.bayes$bf,\n                       sess_emo.treat.bayes$bf/emo.treat.bayes$bf),\n                                     scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### compare with Emo\n```{r}\ntibble(model = c(\"TreatxSessxEmo\", \"SessxEmo\", \"Emo\"),\n       Compared_To_Emo = format(c(full.treat.bayes$bf/emo.treat.bayes$bf, \n                                  sess_emo.treat.bayes$bf/emo.treat.bayes$bf, \n                                  emo.treat.bayes$bf/emo.treat.bayes$bf),\n                                scientific = TRUE),\n       BF01 = format(c(emo.treat.bayes$bf/full.treat.bayes$bf, \n                       emo.treat.bayes$bf/sess_emo.treat.bayes$bf, \n                       emo.treat.bayes$bf/emo.treat.bayes$bf),\n                                scientific = TRUE)) %>% \n  kable() %>%\n  kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"), \n                full_width = F, position = 'left')\n```\n\n#### check assumptions {.tabset}\nLinear regression has these assumptions:  \n\n1. Linear association\n2. Normality of residuals\n3. No heteroskedasticity\n4. No multicollinearity\n\n##### linearity\n```{r}\n# Check linearity\nna.omit(detect_treat) %>%\n  add_residual_draws(LPP.treat.model, ndraws = 1) %>%\n  ggplot(aes(x = .row, y = .residual)) +\n  stat_pointinterval()\n```\n\n##### normality\n```{r}\n# Check normality\nna.omit(detect_treat) %>%\n  add_residual_draws(LPP.treat.model, ndraws = 1) %>%\n  median_qi() %>%\n  ggplot(aes(sample = .residual)) +\n  geom_qq() +\n  geom_qq_line()\n```\n\n##### multicollinearity\n```{r}\n# Check vif and tolerance\ncheck_collinearity(LPP.treat.model)\n```"},"formats":{"revealjs":{"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":{"html_document":{"code_folding":"hide","df_print":"paged","highlight":"tango","theme":"united","toc":"yes","toc_float":{"collapsed":"yes","smooth_scroll":"yes"}}},"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","output-file":"VR_spider_LMM.html"},"language":{},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.0.36","auto-stretch":true,"title":"VR spiders analyses","author":"Stefan Wiens, Dani Cosme, Stephen Pierzchajlo","date":"`r Sys.Date()`"}}}}