---
title: "VR spiders analyses"
author: "Stefan Wiens, Dani Cosme, Stephen Pierzchajlo"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    df_print: paged
    highlight: tango
    theme: united
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: yes
---

```{r setup, include=FALSE}
#'echo = False' hides *all* code chunks below when knitted 
#'warning = F' hides *all* warnings messages below when knitted 
#'message = F' hides *all* messages below when knitted 

knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE,
                      fig.path = "figures/extra/",
                      fig.width=11, fig.height=5)
options(scipen = 999)
options(repos = list(CRAN="http://cran.rstudio.com/"))
```

```{r prepare R, echo = FALSE, include = FALSE}
# clear memory and set random seed
rm(list = ls()) # clear memory
graphics.off()  # clear all plots
cat("\014")     # clear console (same as Ctrl-L in console)

# set seed
set.seed(123)
```

# load packages
```{r}
packages <- c('tidyverse',     # data handling
              'lmerTest', 
              'modelr',
              'sjPlot',
              'kableExtra',
              'broom.mixed',
              'gridExtra',
              'brms',
              'bayesplot',
              'rstanarm',
              'performance',
              'tidybayes',
              'brant')    
# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages], repos = c(CRAN = "https://cran.rstudio.com"))
}
# Packages loading
invisible(lapply(packages, library, character.only = TRUE))

packv <- NULL
for (i in 1:length(packages)) {
  packv = rbind(packv, c(packages[i], as.character(packageVersion(packages[i]))))
}
colnames(packv) <- c("Package", "Version") 
packv %>% 
  as_tibble %>% 
  arrange(Package) %>% 
  kable(align = "l") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

# define aesthetics
```{r}
palette <- c("#ED5C4D", "#57B5ED", "#FBBE4B") # control vs each
palette2 <- c("#ED5C4D", "#5a4491") # control vs combined

plot_aes <- theme_minimal() +
  theme(legend.position = "top",
        text = element_text(size = 20), #, family = "Helvetica"), does not work in Win
        axis.text = element_text(color = "black"),
        axis.line = element_line(colour = "black"),
        axis.ticks.y = element_blank())
```

# functions
```{r}
source('src/LMM_functions.R')
source('src/myround.R')

# 95% confidence intervals
ci95LL <- function(data){return(t.test(data, 
                                      conf.level = 0.95, 
                                      alternative = "two.sided")$conf.int[1])}
ci95UL <- function(data){return(t.test(data, 
                                      conf.level = 0.95, 
                                      alternative = "two.sided")$conf.int[2])}
```

# set up directories
```{r}
# directory with input EEG log files
dir_log <- 'data/log'
# directory with input EEG mean amp files
dir_meanamps <- 'data/mean_amps'
```

# check file integrity {.tabset}
The experimental groups were **VRET** (virtual reality exposure treatment) and **IVET** (in vivo exposure treatment). Subject numbering started from 1 for the experimental group (without any knowledge of treatment). Thus, in the experimental group, each subject (fp in Swedish) has their unique number. However, subject numbering in the control group also started from 1. Thus, the same ID number (e.g., 1) in the experimental and control group refers to different people. The script handles this by adding 100 to the ID number of the control group. Thus, there is a unique code for each subject.  

Below, session 1 refers to pre-treatment and session 2 to post-treatment.

## experimental group
```{r read in experimental group (2 sessions)}
# according to subject notes
# vret codes for treatment: 1= vret, 0 = ivet
file <- 'data/VR_spider_EEG-EG_final.tsv'
listEGnotes <- read.csv(file, sep = '\t', header = T)
listEGnotes$sess1 <- 1
listEGnotes$sess1[listEGnotes$pre=='nope'] <- 0
listEGnotes$sess2 <- 1
listEGnotes$sess2[listEGnotes$post=='nope'] <- 0

# EG according to EEG log files
fps <- list.files(file.path(dir_log,'experimental'), pattern = 'fp')
listEGlog <- data.frame()
for (f in fps){ # f = fps[6]
  fp <- substring(f, first = 3)
  sess <- as.integer(substring(fp, first = regexpr('_',fp)[1]+1))
  fp <- as.integer(substring(fp, first = 1, last = regexpr('_',fp)[1]-1))
  listEGlog <- rbind(listEGlog, cbind(fp,sess))
}
rm(f,fp,fps,sess,file)

# EG according to EEG mean amps
fps <- list.files(file.path(dir_meanamps), pattern = 'fp')
listamps <- data.frame()
for (f in fps){ # f = fps[6]
  fp <- substring(f, first = 3, last = 11)
  sess <- as.integer(substring(fp, first = regexpr('_ses', fp)[1]+4))
  fp <- as.integer(substring(fp, first = 1, last = 3))
  listamps <- rbind(listamps, cbind(fp,sess))
}
listEGamps <- listamps %>% filter(fp < 100)
rm(f,fp,fps,sess)

# check subject match between EEG amps and log
# session 1
if (setequal(listEGamps$fp[listEGamps$sess==1], listEGlog$fp[listEGlog$sess==1])!=T){
  print('EG: Mismatch between EEG amps and log files: Session 1')
  print('Unique in EEG amps')
  print(setdiff(listEGamps$fp[listEGamps$sess==1], listEGlog$fp[listEGlog$sess==1]))
  print('Unique in EEG log')
  print(setdiff(listEGlog$fp[listEGlog$sess==1], listEGamps$fp[listEGamps$sess==1]))
  stop('EG: mismatch between EEG amps and log files: Session 1')
}
# session 2
if (setequal(listEGamps$fp[listEGamps$sess==2], listEGlog$fp[listEGlog$sess==2])!=T){
  print('EG: Mismatch between EEG amps and log files: Session 2')
  print('Unique in EEG amps')
  print(setdiff(listEGampsfp[listEGamps$sess==2], listEGlog$fp[listEGlog$sess==2]))
  print('Unique in EEG log')
  print(setdiff(listEGlog$fp[listEGlog$sess==2], listEGamps$fp[listEGamps$sess==2]))
  stop('EG: Mismatch between EEG amps and log files: Session 2')
}

# check subject match between notes and EEG log
# session 1
if (setequal(listEGnotes$fp[listEGnotes$sess1==1], listEGlog$fp[listEGlog$sess==1])!=T){
  print('EG: Mismatch between notes and EEG log files: Session 1')
  print('Unique in notes')
  print(setdiff(listEGnotes$fp[listEGnotes$sess1==1], listEGlog$fp[listEGlog$sess==1]))
  print('Unique in EEG log')
  print(setdiff(listEGlog$fp[listEGlog$sess==1], listEGnotes$fp[listEGnotes$sess1==1]))
  stop('EG: Mismatch between notes and EEG log files: Session 1')
}
# session 2
if (setequal(listEGnotes$fp[listEGnotes$sess2==1], listEGlog$fp[listEGlog$sess==2])!=T){
  print('EG: Mismatch between notes and EEG log files: Session 2')
  print('Unique in notes')
  print(setdiff(listEGnotes$fp[listEGnotes$sess2==1], listEGlog$fp[listEGlog$sess==2]))
  print('Unique in EEG log')
  print(setdiff(listEGlog$fp[listEGlog$sess==2], listEGnotes$fp[listEGnotes$sess2==1]))
  stop('EG: Mismatch between notes and EEG log files: Session 2')
}
# make notes list the gold standard----
rm(listEGlog, listEGamps)
```

## control group
```{r read and check subjects in control group (only 1 session)}
# The same ID number (e.g., 1) in the experimental and control group refers to different people. The script handles this by adding 100 to the ID number of the control group. Thus, there is a unique code for each subject.

# according to subject notes
file <- 'data/VR_spider_EEG-CG_final.tsv'
listCGnotes <- read.csv(file, sep = '\t', header = T)
listCGnotes$fp <- listCGnotes$fp + 100 # add 100 to create a unique code

# CG according to EEG log files
fps <- list.files(file.path(dir_log,'control'), pattern = 'fp')
listCGlog <-  data.frame()
for (f in fps){ # f = fps[6]
  fp <- as.integer(substring(f, first = 3))
  listCGlog <- rbind(listCGlog, cbind(fp))
}
listCGlog$fp <- listCGlog$fp + 100 # add 100 to create a unique code

# CG according to EEG mean amps
# (data already read in for EG above)
listCGamps <- listamps %>% 
  filter(fp >= 100) %>% 
  select(-sess)

# check subject match between EEG amps and log
if (setequal(listCGamps$fp, listCGlog$fp)!=T){
  print('CG: Mismatch between EEG amps and log files')
  print('Unique in EEG amps')
  print(setdiff(listCGamps$fp, listCGlog$fp))
  print('Unique in EEG log')
  print(setdiff(listCGlog$fp,listCGamps$fp))
  stop('CG: Mismatch between EEG amps and log files')
}

# check subject match between notes and EEG log
if (setequal(listCGnotes$fp, listCGlog$fp)!=T){
  print('CG: Mismatch between notes and EEG log files')
  print('Unique in notes')
  print(setdiff(listCGnotes$fp, listCGlog$fp))
  print('Unique in EEG log')
  print(setdiff(listCGlog$fp, listCGnotes$fp))
  stop('Mismatch between notes and EEG log files: Control group')
}

# make notes list the gold standard----
rm(listCGlog, listCGamps)
```

# demographics
Demographics are in the data files only for the control group.  

Mean (SD) of age = `r myround(mean(listCGnotes$age),1)` (`r myround(sd(listCGnotes$age),2)`).  

```{r}
listCGnotes %>% 
  count(gender) %>% 
  mutate(gender = case_when(gender == 'f' ~ 'female',
                            gender == 'm' ~ 'male')) %>% 

  kable(align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```
Handedness:
```{r}
listCGnotes %>% 
  count(handedness) %>% 
  mutate(handedness = case_when(handedness == 'l' ~ 'left',
                                handedness == 'r' ~ 'right')) %>% 
  kable(align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

# detection task: questionnaire {.tabset}
After the detection task (with EEG), subjects filled in a questionnaire.  

Questions:  
Q1) Task focus: 'How much did you focus on the fixation cross? 1=never, 9=always  
Q2) Flash visible: 'How easy to see the flash?' 1=difficult, 9=easy  
Q3) Spiders distract: 'How distracted were you by spiders?' 1=little, 9=lots  
Q4) Nonspiders distract: 'How distracted were you by nonspiders?' 1=little, 9=lots  
Q5) Task easy: 'How easy was the task?' 1=difficult, 9=easy  
```{r read questionnaire data about detection task}
# experimental
file <- 'data/detection_que_experimental.tsv'
tmpque <- read.csv(file, skip = 0, sep = '\t', header = T)
# sess 1
tmp <- sort(intersect(listEGnotes$fp[listEGnotes$sess1==1],tmpque$fp[tmpque$sess==1]))
note1 <- paste0('EG Session 1: n = ', length(setdiff(listEGnotes$fp[listEGnotes$sess1==1], tmp)))
QueDetect <- tmpque[tmpque$fp %in% tmp & tmpque$sess == 1,]
# sess 2
tmp <- sort(intersect(listEGnotes$fp[listEGnotes$sess2==1],tmpque$fp[tmpque$sess==2]))
note2 <- paste0('EG Session 2: n = ', length(setdiff(listEGnotes$fp[listEGnotes$sess2==1], tmp)))
QueDetect <- rbind(QueDetect, tmpque[tmpque$fp %in% tmp & tmpque$sess == 2,])
QueDetect$treat <- 'IVET'
tmp <- listEGnotes$fp[listEGnotes$vret==1]
QueDetect$treat[QueDetect$fp %in% tmp] = 'VRET'

# control
file <- 'data/detection_que_control.tsv'
tmpque <- read.csv(file, skip = 0, sep = '\t', header = T) 
tmpque$fp <- tmpque$fp + 100 # add 100 to get unique ID codes
tmp = sort(intersect(listCGnotes$fp, tmpque$fp))
note3 = paste0('CG: n = ', length(setdiff(listCGnotes$fp, tmp)))
tmpque = tmpque[tmpque$fp %in% tmp,]
tmpque$treat = 'Control'
QueDetect = rbind(QueDetect, tmpque)
rownames(QueDetect) = NULL
QueDetect$sess = QueDetect$sess - 1 # recode to session 0 and 1
QueDetect$treat = factor(QueDetect$treat, levels=c('Control', 'IVET', 'VRET'))

dataque <- QueDetect %>%
    pivot_longer(cols = c(q1, q2, q3, q4, q5), names_to = 'que', values_to = 'dv') %>% 
    mutate(fp = as.character(fp))

# check that answers range between 1 and 9
dataque %>% 
  summarise(min_dv = min(dv),
            max_dv = max(dv), 
            .groups = 'drop') %>% 
  as.numeric() %>% 
  identical(c(1,9)) %>% 
  isFALSE() %>% 
  {if(.)(stop("Error: Answers min and max are not 1 and 9, respectively!"))}
```

```{r, export que tsv}
write_tsv(dataque, file.path('results/dataque.tsv'))
```

## sample size
Data are almost complete except that four subjects (not from one particular group) have missing questionnaire data. These subjects are from these groups:  

* `r note1`
* `r note2`
* `r note3`

The variables `Pre` and `Post` show the number of participants in each. The variable `Both` shows how many of these subjects participated in both sessions. These are not additional subjects. If one wants to know the number of participants only in `Pre`, compute `Pre` minus `Both`.
```{r}
tmptable <- dataque %>% 
  group_by(fp) %>% 
  slice(1) %>% 
  select(fp, treat) %>% 
  group_by(treat) %>% 
  summarise(N = n(), .groups = 'drop') %>% 
  rename("Treatment" = treat)
tmptable <- dataque %>%
  select(fp, sess, treat) %>%
  unique() %>%
  group_by(sess, treat) %>%
  mutate(sess = ifelse(sess==0, 'Pre', 'Post'),
         sess = factor(sess, levels = c('Pre', 'Post'))) %>% 
  summarise(n = n(), .groups = 'drop') %>% # grouping is dropped 
  pivot_wider(names_from = sess, values_from = n) %>%
  mutate_if(is.numeric, ~ ifelse(is.na(.), "--", .)) %>% 
  cbind(tmptable, .) %>% 
  select(-treat)
tmps1I <- dataque %>%
  filter(treat == 'IVET',
         sess == 0) %>%
  distinct(., fp) %>% 
  pull()
tmps1V <- dataque %>%
  filter(treat == 'VRET',
         sess == 0) %>%
  distinct(., fp) %>% 
  pull()
tmps2I <- dataque %>%
  filter(treat == 'IVET',
         sess == 1) %>%
  distinct(., fp) %>% 
  pull()
tmps2V <- dataque %>%
  filter(treat == 'VRET',
         sess == 1) %>%
  distinct(., fp) %>% 
  pull()
tmptable$'Both' = c('--', length(intersect(tmps1I, tmps2I)), length(intersect(tmps1V, tmps2V)))
tmptable %>%
  kable(align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
rm(tmptable, tmps1I, tmps1V, tmps2I, tmps2V)
```

## descriptives
The table shows means (*SD* in parentheses).  
```{r Questionnaire Detect data}
dataque %>%
  mutate(sess = ifelse(sess==0, 'pre', 'post'),
         sess = factor(sess, levels = c('pre', 'post'))) %>% 
  group_by(sess, treat, que) %>%
  summarise(m_sd = sprintf("%.2f (%.2f)", mean(dv, na.rm = TRUE),
            sd(dv, na.rm = TRUE)), .groups = 'drop') %>%
  # grouping is dropped
  pivot_wider(names_from = que, values_from = m_sd) %>%
  rename("Treatment" = treat,
         "Session" = sess,
         "Task focus" = q1,
         "Flash visible" = q2,
         "Spiders distract" = q3,
         "Nonspiders distract" = q4,
         "Task easy" = q5) %>%
  arrange(Treatment, Session) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

## session 1 across treatments {.tabset}
* standard regression model (no repeated measures)
* use session 1 from all three groups
* combine treatment groups
* no plots because the comparison involves two means (treatment vs. control). The *B* in the table shows the mean difference.    

### Q1
Task focus: 'How much did you focus on the fixation cross? 1=never, 9=always  

Note that the intercept shows the mean score for Controls in Session 1.  

Result: The (combined) treatment group tended to be less focused on the cross. Makes sense because in Q3, they rated to be more distracted by spiders.  
```{r}
mylabels = c('treatment (Control)',
             'treatment (VRET/IVET)')
model_name = "quedetect_q1_acrosstreatment"
model_formula = formula("dv ~ 1 + treat")
# fp is not included because each subject contributes one data point
data <- dataque %>%
  filter(sess == 0) %>%
  filter(que == 'q1') %>%
  mutate(treat = ifelse(treat == 'Control', 'Control', 'VRET/IVET'),   
         treat = factor(treat, levels = c("Control", "VRET/IVET")))
assign(get("model_name"), lm(model_formula, data = data))
table_model(get(model_name),
           dv_labels = "Task focus",
           pred_labels = mylabels)
```

### Q2
Flash visible: 'How easy to see the flash?' 1=difficult, 9=easy  
```{r}
model_name = "quedetect_q2_acrosstreatment"
model_formula = formula("dv ~ 1 + treat")
data <- dataque %>%
  filter(sess == 0) %>%
  filter(que == 'q2') %>%
  mutate(treat = ifelse(treat == 'Control', 'Control', 'VRET/IVET'),   
         treat = factor(treat, levels = c("Control", "VRET/IVET")))
assign(get("model_name"), lm(model_formula, data = data))
table_model(get(model_name),
           dv_labels = "Flash visible",
           pred_labels = mylabels)
```

### Q3
Spiders distract: 'How distracted were you by spiders?' 1=little, 9=lots  

Result: The treatment group rated to be much more distracted by spiders.  
```{r}
model_name = "quedetect_q3_acrosstreatment"
model_formula = formula("dv ~ 1 + treat")
data <- dataque %>%
  filter(sess == 0) %>%
  filter(que == 'q3') %>%
  mutate(treat = ifelse(treat == 'Control', 'Control', 'VRET/IVET'),   
         treat = factor(treat, levels = c("Control", "VRET/IVET")))
assign(get("model_name"), lm(model_formula, data = data))
table_model(get(model_name),
           dv_labels = "Spiders distract",
           pred_labels = mylabels)
```

### Q4
Nonspiders distract: 'How distracted were you by nonspiders?' 1=little, 9=lots  
```{r}
model_name = "quedetect_q4_acrosstreatment"
model_formula = formula("dv ~ 1 + treat")
data <- dataque %>%
  filter(sess == 0) %>%
  filter(que == 'q4') %>%
  mutate(treat = ifelse(treat == 'Control', 'Control', 'VRET/IVET'),   
         treat = factor(treat, levels = c("Control", "VRET/IVET")))
assign(get("model_name"), lm(model_formula, data = data))
table_model(get(model_name),
           dv_labels = "Nonspiders distract",
           pred_labels = mylabels)
```

### Q3 vs Q4
Measure distraction by spiders versus nonspiders. That is, compute Q3 minus Q4 for each subject. Positive values mean that the subject reported being more distracted by spiders than nonspiders.  

Result: Compared to controls, the treatment groups reported more distraction by spiders (vs. nonspiders) in session 1.  

```{r}
model_name = "quedetect_q34_acrosstreatment"
model_formula = formula("dv ~ 1 + treat")
data <- QueDetect %>%
  filter(sess == 0) %>%
  mutate(dv = q3 - q4) %>%
  select(fp, sess, treat, dv) %>%
  mutate(treat = ifelse(treat == 'Control', 'Control', 'VRET/IVET'),   
         treat = factor(treat, levels = c("Control", "VRET/IVET")))
assign(get("model_name"), lm(model_formula, data = data))
table_model(get(model_name),
           dv_labels = "Distract spiders minus nonspiders",
           pred_labels = mylabels)
```

### Q5
Task easy: 'How easy was the task?' 1=difficult, 9=easy  
```{r}
model_name = "quedetect_q5_acrosstreatment"
model_formula = formula("dv ~ 1 + treat")
data <- dataque %>%
  filter(sess == 0) %>%
  filter(que == 'q5') %>%
  mutate(treat = ifelse(treat == 'Control', 'Control', 'VRET/IVET'),   
         treat = factor(treat, levels = c("Control", "VRET/IVET")))
assign(get("model_name"), lm(model_formula, data = data))
table_model(get(model_name),
           dv_labels = "Task easy",
           pred_labels = mylabels)
```

## treatment comparison {.tabset}
* MLM model
* session 1 and session 2 (session 1 as reference)
* include only treatment groups
* IVET = -.5, VRET = .5

### Q1 {.tabset}
Task focus: 'How much did you focus on the fixation cross? 1=never, 9=always  

#### model
```{r}
mylabels = c('treatment (VRET/IVET) / session (1)',
             'treatment (VRET vs IVET) /  session (1)', 
             'treatment (VRET/IVET) / session (2)', 
             'treatment (VRET vs IVET) / session (2)')
model_name = "quedetect_q1_treatment"
model_formula = formula("dv ~ 1 + treat*sess + (1 | fp)")
data <- dataque %>%
  filter(!treat == 'Control') %>%
  filter(que == 'q1') %>%
  mutate(treat =  ifelse(as.character(treat) == "IVET", -.5, .5))
#recode treatment as -.5 and .5
assign(get("model_name"), lmerTest::lmer(model_formula,
                                         control = lmerControl(optimizer = "bobyqa",  
                                                               optCtrl = list(maxfun = 1e5)),
                                         data = data))
table_model(get(model_name),
            dv_labels = "Task focus",
            pred_labels = mylabels)
```

#### plot
```{r, fig.width=11, fig.height=5}
ggeffects::ggpredict(get(model_name), c("treat", "sess")) %>%
  data.frame() %>%
  mutate(group = ifelse(group == 0, 'pre', 'post'),
         group = factor(group, levels = c('pre', 'post')),
         x = ifelse(x == -.5, "IVET", "VRET")) %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  scale_color_manual(values = palette[2:3], name = "treatment") +
  labs(y = "predicted rating\n", x = "\nsession") +
  plot_aes
```

### Q2 {.tabset}
Flash visible: 'How easy to see the flash?' 1=difficult, 9=easy  

Result: The interaction suggests that IVET rated the flash as more visible during session 1 than 2, whereas VRET rated the opposite. This effect does not seem meaningful.  

#### model
```{r}
model_name = "quedetect_q2_treatment"
model_formula = formula("dv ~ 1 + treat*sess + (1 | fp)")
data <- dataque %>%
  filter(!treat == 'Control') %>%
  filter(que == 'q2') %>%
  mutate(treat =  ifelse(as.character(treat) == "IVET", -.5, .5))
#recode treatment as -.5 and .5
assign(get("model_name"), lmerTest::lmer(model_formula,
                                         control = lmerControl(optimizer = "bobyqa",  
                                                               optCtrl = list(maxfun = 1e5)),
                                         data = data))
table_model(get(model_name),
            dv_labels = "Flash visible",
            pred_labels = mylabels)
```

#### plot
```{r, fig.width=11, fig.height=5}
ggeffects::ggpredict(get(model_name), c("treat", "sess")) %>%
  data.frame() %>%
  mutate(group = ifelse(group == 0, 'pre', 'post'),
         group = factor(group, levels = c('pre', 'post')),
         x = ifelse(x == -.5, "IVET", "VRET")) %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  scale_color_manual(values = palette[2:3], name = "treatment") +
  labs(y = "predicted rating\n", x = "\nsession") +
  plot_aes
```

### Q3 {.tabset}
Spiders distract: 'How distracted were you by spiders?' 1=little, 9=lots  

Result: The treatment groups rated less distraction by spiders in session 2 than 1.  
See also the Q3 vs Q4 that uses the nonspiders as controls.

#### model
```{r}
model_name = "quedetect_q3_treatment"
model_formula = formula("dv ~ 1 + treat*sess + (1 | fp)")
data <- dataque %>%
  filter(!treat == 'Control') %>%
  filter(que == 'q3') %>%
  mutate(treat =  ifelse(as.character(treat) == "IVET", -.5, .5))
#recode treatment as -.5 and .5
assign(get("model_name"), lmerTest::lmer(model_formula,
                                         control = lmerControl(optimizer = "bobyqa",  
                                                               optCtrl = list(maxfun = 1e5)),
                                         data = data))
table_model(get(model_name),
            dv_labels = "Spider distract",
            pred_labels = mylabels)
```

#### plot
```{r, fig.width=11, fig.height=5}
ggeffects::ggpredict(get(model_name), c("treat", "sess")) %>%
  data.frame() %>%
  mutate(group = ifelse(group == 0, 'pre', 'post'),
         group = factor(group, levels = c('pre', 'post')),
         x = ifelse(x == -.5, "IVET", "VRET")) %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  scale_color_manual(values = palette[2:3], name = "treatment") +
  labs(y = "predicted rating\n", x = "\nsession") +
  plot_aes
```

### Q4 {.tabset}
Nonspiders distract: 'How distracted were you by nonspiders?' 1=little, 9=lots  

#### model
```{r}
model_name = "quedetect_q4_treatment"
model_formula = formula("dv ~ 1 + treat*sess + (1 | fp)")
data <- dataque %>%
  filter(!treat == 'Control') %>%
  filter(que == 'q4') %>%
  mutate(treat =  ifelse(as.character(treat) == "IVET", -.5, .5))
#recode treatment as -.5 and .5
assign(get("model_name"), lmerTest::lmer(model_formula,
                                         control = lmerControl(optimizer = "bobyqa",  
                                                               optCtrl = list(maxfun = 1e5)),
                                         data = data))
table_model(get(model_name),
            dv_labels = "Nonspiders distract",
            pred_labels = mylabels)
```

#### plot
```{r, fig.width=11, fig.height=5}
ggeffects::ggpredict(get(model_name), c("treat", "sess")) %>%
  data.frame() %>%
  mutate(group = ifelse(group == 0, 'pre', 'post'),
         group = factor(group, levels = c('pre', 'post')),
         x = ifelse(x == -.5, "IVET", "VRET")) %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  scale_color_manual(values = palette[2:3], name = "treatment") +
  labs(y = "predicted rating\n", x = "\nsession") +
  plot_aes
```

### Q3 vs Q4 {.tabset}
Measure distraction by spiders versus nonspiders. That is, compute Q3 minus Q4 for each subject.  
Positive values mean that the subject reported being more distracted by spiders than nonspiders.  

Result: The treatment groups rated less distraction by spiders (vs. nonspiders) in session 2 than 1.  

#### model
```{r}
model_name = "quedetect_q34_treatment"
model_formula = formula("dv ~ 1 + treat*sess + (1 | fp)")
data <- QueDetect %>%
  filter(!treat == 'Control') %>%
  mutate(dv = q3 - q4) %>%
  select(fp, sess, treat, dv) %>%
  mutate(treat =  as.numeric(ifelse(as.character(treat) == "IVET", -.5, .5)))
#recode treatment as -.5 and .5
assign(get("model_name"), lmerTest::lmer(model_formula,
                                         control = lmerControl(optimizer = "bobyqa",  
                                                               optCtrl = list(maxfun = 1e5)),
                                         data = data))
table_model(get(model_name),
            dv_labels = "Distract spiders minus nonspiders",
            pred_labels = mylabels)
```

#### plot
```{r, fig.width=11, fig.height=5}
ggeffects::ggpredict(get(model_name), c("treat", "sess")) %>%
  data.frame() %>%
  mutate(group = ifelse(group == 0, 'pre', 'post'),
         group = factor(group, levels = c('pre', 'post')),
         x = ifelse(x == -.5, "IVET", "VRET")) %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  scale_color_manual(values = palette[2:3], name = "treatment") +
  labs(y = "predicted rating\n", x = "\nsession") +
  plot_aes
```

### Q5 {.tabset}
Task easy: 'How easy was the task?' 1=difficult, 9=easy  

Result: The treatment groups rated the task as easier during session 2 than 1.  

#### model
```{r}
model_name = "quedetect_q5_treatment"
model_formula = formula("dv ~ 1 + treat*sess + (1 | fp)")
data <- dataque %>%
  filter(!treat == 'Control') %>%
  filter(que == 'q5') %>%
  mutate(treat =  ifelse(as.character(treat) == "IVET", -.5, .5))
#recode treatment as -.5 and .5
assign(get("model_name"), lmerTest::lmer(model_formula,
                                         control = lmerControl(optimizer = "bobyqa",  
                                                               optCtrl = list(maxfun = 1e5)),
                                         data = data))
table_model(get(model_name),
            dv_labels = "Task easy",
            pred_labels = mylabels)
```

#### plot
```{r, fig.width=11, fig.height=5}
ggeffects::ggpredict(get(model_name), c("treat", "sess")) %>%
  data.frame() %>%
  mutate(group = ifelse(group == 0, 'pre', 'post'),
         group = factor(group, levels = c('pre', 'post')),
         x = ifelse(x == -.5, "IVET", "VRET")) %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  scale_color_manual(values = palette[2:3], name = "treatment") +
  labs(y = "predicted rating\n", x = "\nsession") +
  plot_aes
rm(list=ls(pattern='quedetect'))
```


# sample size
```{r}
Nall = sum(c(nrow(listCGnotes),listEGnotes$sess1,listEGnotes$sess2))
```

The total number of recordings is **`r Nall`**.  A recording comprises data from two tasks of a single subject in a single session.  

* Detection task (with EEG): Subjects detected flashing of the central fixation cross.  
* Rating task: Subjects rated each picture on arousal and pleasantness. (Note that pleasantness is recoded below to unpleasantness.)  

The table shows the number of subjects in the three groups.  

The variable *Both* shows how many subjects participated in both sessions. So, these are not additional subjects.  
```{r}
tmptable <- listEGnotes %>%
  select(vret, sess1, sess2) %>%
  mutate(sess12 = ifelse(sess1==1 & sess2==1, 1, 0)) %>%
  group_by(vret, sess1, sess2, sess12) %>%
  summarise(n = n(), .groups = 'drop') # grouping is dropped 
tmpd = data.frame(Treatment = c('Control','IVET','VRET'),
                  N = c(nrow(listCGnotes), 
                        length(listEGnotes$fp[listEGnotes$vret==0]),
                        length(listEGnotes$fp[listEGnotes$vret==1])),
                  S1 = c(nrow(listCGnotes), 
                         tmptable$n[2]+tmptable$n[3], 
                         tmptable$n[5]+tmptable$n[6]),
                  S2 = c('--', 
                         tmptable$n[1]+tmptable$n[3], 
                         tmptable$n[4]+tmptable$n[6]),
                  Both = c('--', tmptable$n[3], tmptable$n[6]))
tmpd %>%
  rename("Pre" = `S1`,
         "Post" = `S2`) %>%
  kable(align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
rm(tmptable, tmpd)
```

# read rating/EEG data {.tabset}
Read in the data from the detection task (with EEG) and the rating data from the rating task.

## experimental group
```{r read behavioral and mean EEG data per trial in experimental group}
# experimental group
fps <- c(listEGnotes$fp[listEGnotes$sess1==1], 
        listEGnotes$fp[listEGnotes$sess2==1])
ses <- as.integer(c(listEGnotes$sess1[listEGnotes$sess1==1], 
                   listEGnotes$sess2[listEGnotes$sess2==1]*2))
vr <- as.integer(c(listEGnotes$vret[listEGnotes$sess1==1],
                  listEGnotes$vret[listEGnotes$sess2==1]))
RawDetect<- data.frame()
RawRate <- data.frame()
for (f in 1:length(fps)){ # f = 3
  
  # read in detection behavioral data----
  file <- file.path(dir_log,'experimental',sprintf('fp%s_%s/DATA_SpVR_%s_%s.txt',
                                                  fps[f],ses[f],fps[f], ses[f]))
  if (file.exists(file)){
    tmp <- read.csv(file, skip = 10, sep = '\t', header = F)[,1:13]
    # header = T did not work because of an extra tab at the end of each row
    colnames(tmp) <-  c('Trial',	'Code',	'Targ',	'Gap',	'Emo',	'Pind',	'Pcode',
                       'PicOn',	'ProbeOn',	'NumResp',	'RespOn',	'Logcode',	'PPTcode')
    if (nrow(tmp) != 200){
      print(file)
      stop('Not 200 trials per session!')
    }
  }
  
  # read in detection EEG data----
  # Trial	fp	ses	cond	EPN	LPP	bad
  file <- file.path(dir_meanamps,sprintf('fp%03.0f_ses%02.0f.tsv',
                                          fps[f],ses[f]))
  if (file.exists(file)){
    tmp2 <- read.csv(file, sep = '\t', header = T)
    
    if (identical(rep(fps[f],length(tmp2$fp)), as.integer(tmp2$fp)) == F){
      print(file)
      stop('Subject id does not match!')
    }
    if (identical(rep(ses[f],length(tmp2$fp)), as.integer(tmp2$ses)) == F){
      print(file)
      stop('Session number does not match!')
    }
    
    # Some subjects had a trial missing in EEG
    # apparently, no code was sent to the EEG
    # fix these data
    # Note: earlier file versions had trialonset as a variable
    #tmp2$diff[2:length(tmp2$trialonset)] = diff(tmp2$trialonset, lag = 1)
    # I used the timing difference to find which trial was missing
    if (fps[f] == 13 & ses[f] == 1){
      # trial 172 is missing; skip this trial
      tmp2$Trial[172:199] <- 173:200
      tmp2 <- rbind(tmp2, c(172,13,1,'pos/notarget',NA,NA,NA,NA,NA,NA,NA,NA,1))
      tmp2 <- tmp2[order(as.numeric(tmp2$Trial)),]
    }
    if (fps[f] == 15 & ses[f] == 2){
      # trial 140 is missing; skip this trial
      tmp2$Trial[140:199] <- 141:200
      tmp2 <- rbind(tmp2, c(140,15,1,'pos/notarget',NA,NA,NA,NA,NA,NA,NA,NA,1))
      tmp2 <- tmp2[order(as.numeric(tmp2$Trial)),]
    }
    if (fps[f] == 71 & ses[f] == 1){
      # trial 30 is missing; skip this trial
      tmp2$Trial[30:199] <- 31:200
      tmp2 <- rbind(tmp2, c(30,71,1,'neg/notarget',NA,NA,NA,NA,NA,NA,NA,NA,1))
      tmp2 <- tmp2[order(as.numeric(tmp2$Trial)),]
    }
    
    # Emo: 1=spi, 2=unpleasant, 3=neutral, 4=pleasant
    tmp2$Emo <- NA
    tmp2$Emo[grepl('spi', tmp2$cond)] <- 1
    tmp2$Emo[grepl('neg', tmp2$cond)] <- 2
    tmp2$Emo[grepl('neu', tmp2$cond)] <- 3
    tmp2$Emo[grepl('pos', tmp2$cond)] <- 4
    
    tmp2$Targ <- 0
    tmp2$Targ[grepl('/target', tmp2$cond)] <- 1
    
    if (nrow(tmp2) != 200){
      print(file)
      stop('Not 200 trials per session!')
    }
    if (identical(tmp$Emo, as.integer(tmp2$Emo)) == F){
      print(file)
      stop('Emotion codes do not match!')
    }
    if (identical(tmp$Targ, as.integer(tmp2$Targ)) == F){
      print(file)
      stop('Target trials do not match!')
    }
    
    # copy mean amps
    tmp$EPN <- as.numeric(tmp2$EPN_average)
    tmp$LPP <- as.numeric(tmp2$LPP_average)
    tmp$bad <- as.numeric(tmp2$bad)
    
    tmp$fp <- fps[f]
    tmp$sess <- ses[f]-1 # code session as 0 and 1
    tmp$treat <- ifelse(vr[f] == 1, 'VRET', 'IVET')
    
    RawDetect <- rbind(RawDetect, tmp)
    rm(tmp, tmp2)
  }
  
  # read in rating data----
  file <- file.path(dir_log,'experimental',sprintf('fp%s_%s/DATA_SpVRrate_%s_%s.txt',
                                                  fps[f],ses[f],fps[f],ses[f]))
  if (file.exists(file)){
    tmp <- read.csv(file, skip = 5, sep = '\t', header = T)[-c(1:4),]
    # delete practice rows
    if (nrow(tmp) != 40){
      print(file)
      stop('Not 40 trials per session!')
    }
    tmp$fp <- fps[f]
    tmp$sess <- ses[f]-1
    tmp$treat <- ifelse(vr[f] == 1, 'VRET', 'IVET')
    RawRate <- rbind(RawRate, tmp)
  }
}
rm(fps,tmp,file,f,ses,vr)
```

## control group
```{r read behavioral and mean EEG data per trial in control group}
# control group
fps <- listCGnotes$fp
for (f in 1:length(fps)){ # f = 1
  
  # read in detection data----
  file <- file.path(dir_log,'control',sprintf('fp%s/DATA_SpVR_%s_1.txt',fps[f]-100,fps[f]-100))
  # for log, fp number starts from 1
  if (file.exists(file)){
    tmp <- read.csv(file, skip = 10, sep = '\t', header = F)[,1:13]
    # header = T did not work because of an extra tab at the end of each row
    colnames(tmp) <-  c('Trial',	'Code',	'Targ',	'Gap',	'Emo',	'Pind',	'Pcode',
                       'PicOn',	'ProbeOn',	'NumResp',	'RespOn',	'Logcode',	'PPTcode')
    if (nrow(tmp) != 200){
      print(file)
      stop('Not 200 trials per session!')
    }
  }
  
  # read in detection EEG data----
  file <- file.path(dir_meanamps,sprintf('fp%03.0f_ses01.tsv',
                                          fps[f])) # fp numbers already starts from 100

  if (file.exists(file)){
    tmp2 <- read.csv(file, sep = '\t', header = T, )
    
    if (identical(as.integer(rep(fps[f],length(tmp2$fp))), tmp2$fp) == F){
      print(file)
      stop('Subject id does not match!')
    }
    
    # Emo: 1=spi, 2=unpleasant, 3=neutral, 4=pleasant
    tmp2$Emo <- NA
    tmp2$Emo[grepl('spi', tmp2$cond)] <- 1
    tmp2$Emo[grepl('neg', tmp2$cond)] <- 2
    tmp2$Emo[grepl('neu', tmp2$cond)] <- 3
    tmp2$Emo[grepl('pos', tmp2$cond)] <- 4
    
    tmp2$Targ <- 0
    tmp2$Targ[grepl('/target', tmp2$cond)] <- 1
    
    if (nrow(tmp2) != 200){
      print(file)
      stop('Not 200 trials per session!')
    }
    if (identical(tmp$Emo, as.integer(tmp2$Emo)) == F){
      print(file)
      stop('Emotion codes do not match!')
    }
    if (identical(tmp$Targ, as.integer(tmp2$Targ)) == F){
      print(file)
      stop('Target trials do not match!')
    }
    
    # copy mean amps
    tmp$EPN <- as.numeric(tmp2$EPN_average)
    tmp$LPP <- as.numeric(tmp2$LPP_average)
    tmp$bad <- as.numeric(tmp2$bad)
    
    tmp$fp <- fps[f]
    tmp$sess <- 0 # code session as 0 and 1
    tmp$treat <- 'Control'
    
    RawDetect <- rbind(RawDetect, tmp)
    rm(tmp, tmp2)
  }
  
  # read in rating data----
  file <- file.path(dir_log,'control',sprintf('fp%s/DATA_SpVRrate_%s_1.txt',fps[f]-100,fps[f]-100))
  # for rating, fp number starts from 1
  if (file.exists(file)){
    tmp <- read.csv(file, skip = 5, sep = '\t', header = T)[-c(1:4),]
    # delete practice rows
    if (nrow(tmp) != 40){
      print(file)
      stop('Not 40 trials per session!')
    }
    tmp$fp <- fps[f]
    tmp$sess <- 0 # code session as 0 and 1
    tmp$treat <- 'Control'
    RawRate <- rbind(RawRate, tmp)
  }
}
rm(fps,tmp,file,f)
```

## recode variables
* Subject ID (fp) as character (for an unknown reason, fp as factor messes up predicted())
* Control group as reference category
* Emotion categories: neutral, spider, negative, positive (in this order)
```{r recode variables in rawdata}
RawDetect <- RawDetect %>%
  mutate(fp = as.character(fp),
         treat = factor(treat, levels = c("Control", "IVET", "VRET")), 
         # relevel so control is the reference
         Emo = recode(Emo, "1" = "spider", "2" = "negative", "3" = "neutral", "4" = "positive"), 
         # recode emotion categories
         Emo = factor(Emo, levels = c("neutral", "spider", "negative", "positive"))) 
# relevel so that neutral is the reference
RawRate <- RawRate %>%
  mutate(fp = as.character(fp),
         treat = factor(treat, levels = c("Control", "IVET", "VRET")), 
         # relevel so control is the reference
         Emo = recode(Emo, "1" = "spider", "2" = "negative", "3" = "neutral", "4" = "positive"), 
         # recode emotion categories
         Emo = factor(Emo, levels = c("neutral", "spider", "negative", "positive")))
```

```{r, export raw csv}
write_tsv(RawDetect, file.path('results/datadetect.tsv'))
write_tsv(RawRate, file.path('results/datarate.tsv'))
```

# detection task performance {.tabset}
Process the performance data (false alarms, hit rate, reaction time to hits) from 
the detection task.  

## false alarms
In the plot, subject refers to the data from a subject in a single session (*N* = `r Nall`). Most subjects made very few false alarms with a couple of exceptions. However, 
these subjects were in the control group. So, ignore false alarms and focus on hits.
```{r compute false alarms for detect data}
# false alarm
tmp <- RawDetect %>% 
  mutate(fals = ifelse(Targ==0 & NumResp>0, 1, 0)) %>%
  group_by(fp, sess) %>%
  summarise(sumfals = sum(fals), .groups = 'drop') %>% 
  pull(sumfals) %>% 
  mean()
RawDetect %>% 
  mutate(fals = ifelse(Targ==0 & NumResp>0, 1, 0)) %>%
  group_by(fp, sess) %>%
  summarise(sumfals = sum(fals), .groups = 'drop') %>% 
  ggplot(aes(sumfals)) +
     geom_density() +
     theme_bw() +
     labs(title = paste0('Number of false alarms (mean = ', myround(tmp,1),')'), 
          x = 'Number of false alarms per subject (possible max = 160)') +
    geom_vline(xintercept = tmp, linetype = 'longdash')
rm(tmp)
```

## hit rate {.tabset}
Hits are trials in which the flashing of the fixation cross was detected and reaction time (RT) > 200 ms.  

### plot
In the plot, subject refers to the data from a subject in a single session (*N* = 160).  
Hit rate varied across subjects.    
```{r compute hit rate for detect data}
# hits
RawDetect <- RawDetect %>% 
  mutate(hit = ifelse(Targ == 1 & NumResp > 0 & RespOn - ProbeOn > 200, 1, 0))
tmp <- RawDetect %>% 
  filter(Targ == 1) %>% 
  group_by(fp, sess) %>%
  summarise(mhit = mean(hit)*100, .groups = 'drop') %>% 
  pull(mhit) %>% 
  mean()
RawDetect %>% 
  filter(Targ == 1) %>% 
  group_by(fp, sess) %>%
  summarise(mhit = mean(hit)*100, .groups = 'drop') %>% 
  ggplot(aes(mhit)) +
     geom_density() +
     theme_bw() +
     labs(title = paste0('Hit rate (mean = ', myround(tmp,1),')'), 
          x = 'Hit rate (%) per subject') +
     geom_vline(xintercept = tmp, linetype = 'longdash')
rm(tmp)
```

### session 1 across treatments {.tabset}
* use session 1 from all three groups
* combine treatment groups
* compute mean hit rate
* nonspiders (i.e., positive, neutral, negative) are combined
* compare spiders versus nonspiders 
* intercept is control/nonspiders

Result: In Session 1, the combined treatment groups (vs controls) tended to have lower hit rates for spiders (vs nonspiders).  

#### model
```{r}
mylabels <- c('treatment (Control) / emotion (nonspiders)',
             'treatment (VRET/IVET) /  emotion (nonspiders)', 
             'treatment (Control) / emotion (spiders)', 
             'treatment (VRET/IVET) / emotion (spiders)')
model_name <- "perfdetect_acrosstreatment"
model_formula <- formula("mhit ~ 1 + treat*Emo + (1 | fp)")
data <- RawDetect %>%
  filter(sess == 0 & Targ == 1) %>%
  mutate(Emo = ifelse(Emo == 'spider', 'spider', 'nonspider'),   
         Emo = factor(Emo, levels = c("nonspider", "spider"))) %>%
  group_by(fp, Emo) %>%
  summarise(mhit = mean(hit)*100, .groups = 'drop') %>%
  mutate(treat = ifelse(as.numeric(as.character(fp)) > 100,'Control', 'VRET/IVET'),   
         treat = factor(treat, levels = c("Control", "VRET/IVET")))
assign(get("model_name"), lmerTest::lmer(model_formula,
                                         control = lmerControl(optimizer = "bobyqa",  
                                                               optCtrl = list(maxfun = 1e5)),
                                         data = data))
table_model(get(model_name),
            dv_labels = "Mean Hit rate (%)",
            pred_labels = mylabels)
```

#### plot
```{r}
ggeffects::ggpredict(get(model_name), c("treat", "Emo")) %>%
  data.frame() %>%
  mutate(group = factor(group, levels = c("nonspider", "spider"))) %>%
  ggplot(aes(group, predicted, color = x)) +
  #geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat, group = fp), alpha = .3, size = .2) +
  # plotting individual lines is not meaningful because slopes are fixed in model
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  scale_color_manual(values = palette2, name = "treatment") +
  labs(y = "predicted hit rate\n", x = "\nemotion") +
  plot_aes
```

### treatment comparison {.tabset}
* session 1 and session 2 (session 1 as reference)
* include only treatment groups
* IVET = -.5, VRET = .5
* compute mean hit rate
* nonspiders (i.e., positive, neutral, negative) are combined
* compare spiders versus nonspiders 
* intercept is session 1/nonspiders

Results do not suggest that the treatment groups differed. However, across treatment groups, there were two effects:  
  
* Performance was lower to spiders than nonspiders in Session 1.
* The performance difference between spiders vs nonspiders decreased from Session 1 to Session 2.  

#### model
```{r}
mylabels <- c('treatment (VRET/IVET) / session (1) / emotion (nonspider)',
             'treatment (VRET vs IVET) /  session (1) / emotion (nonspider)', 
             'treatment (VRET/IVET) / session (2) / emotion (nonspider)', 
             'treatment (VRET/IVET) / session (1) / emotion (spider)',
             'treatment (VRET vs IVET) / session (2) / emotion (nonspider)',
             'treatment (VRET vs IVET) /  session (1) / emotion (spider)', 
             'treatment (VRET/IVET) /  session (2) / emotion (spider)', 
             'treatment (VRET vs IVET) /  session (2) / emotion (spider)')
model_name <- "perfdetect_treatment"
model_formula <- formula("mhit ~ 1 + treat*sess*Emo + (1 | fp)")
data <- RawDetect %>%
  filter(!treat == 'Control' & Targ == 1) %>%
  mutate(Emo = ifelse(Emo == 'spider', 'spider', 'nonspider'),   
         Emo = factor(Emo, levels = c("nonspider", "spider")),
         treat =  ifelse(as.character(treat) == "IVET", -.5, .5)) %>%
  #recode treatment as -.5 and .5
  group_by(treat, fp, sess, Emo) %>%
  summarise(mhit = mean(hit)*100, .groups = 'drop') 
assign(get("model_name"), lmerTest::lmer(model_formula,
                                         control = lmerControl(optimizer = "bobyqa",  
                                                               optCtrl = list(maxfun = 1e5)),
                                         data = data))
table_model(get(model_name),
            dv_labels = "Mean Hit rate",
            pred_labels = mylabels)
```

#### plot
```{r}
ggeffects::ggpredict(get(model_name), c("treat", "sess", "Emo")) %>%
  data.frame() %>%
  mutate(group = ifelse(group == 0, 'pre', 'post'),
         group = factor(group, levels = c('pre', 'post')),
         x = ifelse(x == -.5, "IVET", "VRET")) %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  facet_grid(~facet) +
  scale_color_manual(values = palette[2:3], name = "treatment") +
  labs(y = "predicted hit rate\n", x = "\nsession") +
  plot_aes
```

## hits RT (ms) {.tabset}
### session 1 across treatments {.tabset}
* use session 1 from all three groups
* combine treatment groups
* compute mean hit RT (ms)
* nonspiders (i.e., positive, neutral, negative) are combined
* compare spiders versus nonspiders 
* intercept is control/nonspiders

Results do not suggest differences in Session 1.  

#### model
```{r}
mylabels <- c('treatment (Control) / emotion (nonspiders)',
             'treatment (VRET/IVET) /  emotion (nonspiders)', 
             'treatment (Control) / emotion (spiders)', 
             'treatment (VRET/IVET) / emotion (spiders)')
model_name <- "perfdetectRT_acrosstreatment"
model_formula <- formula("mhitRT ~ 1 + treat*Emo + (1 | fp)")
data <- RawDetect %>%
  filter(sess == 0,
         hit == 1) %>%
  mutate(hitRT = RespOn - ProbeOn,
         Emo = ifelse(Emo == 'spider', 'spider', 'nonspider'),   
         Emo = factor(Emo, levels = c("nonspider", "spider"))) %>%
  group_by(fp, Emo) %>%
  summarise(mhitRT = mean(hitRT), .groups = 'drop') %>%
  mutate(treat = ifelse(as.numeric(fp) < 100,'Control', 'VRET/IVET'),   
         treat = factor(treat, levels = c("Control", "VRET/IVET")))
assign(get("model_name"), lmerTest::lmer(model_formula,
                                         control = lmerControl(optimizer = "bobyqa",  
                                                               optCtrl = list(maxfun = 1e5)),
                                         data = data))
table_model(get(model_name),
            dv_labels = "Mean Hit RT (ms)",
            pred_labels = mylabels)
```

#### plot
```{r}
ggeffects::ggpredict(get(model_name), c("treat", "Emo")) %>%
  data.frame() %>%
  mutate(group = factor(group, levels = c("nonspider", "spider"))) %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  scale_color_manual(values = palette2, name = "treatment") +
  labs(y = "predicted hit RT (ms)\n", x = "\nemotion") +
  plot_aes
```

### treatment comparison {.tabset}
* session 1 and session 2 (session 1 as reference)
* include only treatment groups
* IVET = -.5, VRET = .5
* compute mean hit RT (ms)
* nonspiders (i.e., positive, neutral, negative) are combined
* compare spiders versus nonspiders 
* intercept is session 1/nonspiders

Results suggest no differences.  

#### model
```{r}
mylabels <- c('treatment (VRET/IVET) / session (1) / emotion (nonspider)',
             'treatment (VRET vs IVET) /  session (1) / emotion (nonspider)', 
             'treatment (VRET/IVET) / session (2) / emotion (nonspider)', 
             'treatment (VRET/IVET) / session (1) / emotion (spider)',
             'treatment (VRET vs IVET) / session (2) / emotion (nonspider)',
             'treatment (VRET vs IVET) /  session (1) / emotion (spider)', 
             'treatment (VRET/IVET) /  session (2) / emotion (spider)', 
             'treatment (VRET vs IVET) /  session (2) / emotion (spider)')
model_name <- "perfdetectRT_treatment"
model_formula <- formula("mhitRT ~ 1 + treat*sess*Emo + (1 | fp)")
data <- RawDetect %>%
  filter(!treat == 'Control',
         hit == 1) %>%
  mutate(hitRT = RespOn - ProbeOn,
         Emo = ifelse(Emo == 'spider', 'spider', 'nonspider'),   
         Emo = factor(Emo, levels = c("nonspider", "spider")),
         treat =  ifelse(as.character(treat) == "IVET", -.5, .5)) %>%
  #recode treatment as -.5 and .5
  group_by(treat, fp, sess, Emo) %>%
  summarise(mhitRT = mean(hitRT), .groups = 'drop') 
assign(get("model_name"), lmerTest::lmer(model_formula,
                                         control = lmerControl(optimizer = "bobyqa",  
                                                               optCtrl = list(maxfun = 1e5)),
                                         data = data))
table_model(get(model_name),
            dv_labels = "Mean Hit RT (ms)",
            pred_labels = mylabels)
```

#### plot
```{r}
ggeffects::ggpredict(get(model_name), c("treat", "sess", "Emo")) %>%
  data.frame() %>%
  mutate(group = ifelse(group == 0, 'pre', 'post'),
         group = factor(group, levels = c('pre', 'post')),
         x = ifelse(x == -.5, "IVET", "VRET")) %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  facet_grid(~facet) +
  scale_color_manual(values = palette[2:3], name = "treatment") +
  labs(y = "predicted hit RT (ms)\n", x = "\nsession") +
  plot_aes
```

# prepare rating/EEG subsets {.tabset}

## emotion rating
Self-reported ratings of arousal and pleasantness during the rating task.
```{r}
# check min=1 and max=9
RawRate %>% 
  summarise(min_aro = min(Aro),
            max_aro = max(Aro),
            min_uple = min(Ple),
            max_uple = max(Ple), .groups = 'drop') %>% 
  as.numeric() %>% 
  identical(c(1,9,1,9)) %>% 
  isFALSE() %>% 
  {if(.)(stop("Error: Rating min and max are not 1 and 9, respectively!"))}

rate <- RawRate

# arousal and pleasantness separately
# ====================================
# subset baseline data
rate_baseline <- rate %>%
  filter(sess == 0) %>%
  pivot_longer(cols = c(Ple, Aro), names_to = 'rating_type', values_to = 'rating') %>%
  mutate(rating_type = factor(rating_type, levels = c("Aro", "Ple")))

# combine treatments
# (IVET and VRET have different fp, ie subject ids)
rate_baseline_acrosstreatment <- rate_baseline %>%
  mutate(treat = ifelse(treat == "Control", "Control", "IVET/VRET"), 
         treat = factor(treat, levels = c("Control", "IVET/VRET")))

# pivot_longer rating types and filter out control
rate_only_treat <- rate %>%
  filter(!treat == "Control") %>%
  pivot_longer(cols = c(Ple, Aro), names_to = 'rating_type', values_to = 'rating') 

# recode treatment
rate_only_treat_recode <- rate_only_treat %>%
  mutate(treat =  ifelse(as.character(treat) == "IVET", -.5, .5))
         #recode treatment as -.5 and .5

# subtract the average across neutral pictures from each trial
neutral_rate <- rate %>%
  filter(Emo == "neutral") %>%
  group_by(fp, sess) %>%
  summarise(neutral_avg_Aro = mean(Aro, na.rm = TRUE),
            neutral_avg_Ple = mean(Ple, na.rm = TRUE),
            .groups = 'drop') # grouping is dropped

rate_diffneutral <- rate %>%
  filter(!Emo == "neutral") %>%
  left_join(., neutral_rate, by = c("fp", "sess")) %>%
  mutate(Aro_diff  = Aro - neutral_avg_Aro,
         Ple_diff = Ple - neutral_avg_Ple,
         Emo = factor(Emo, levels = c("spider", "negative", "positive")),
         treat = factor(treat))

```

## detection task (EEG){.tabset}
* remove bad trials from the EEG data
* remove outliers
* remove target trials from the EEG data (20% target trials)
* remove false alarms

### all trials
Number of trials = `r nrow(RawDetect)`. 
```{r}
RawDetect %>% 
  pivot_longer(cols = c(EPN,LPP), names_to = 'ERP_type', values_to = 'amp' ) %>% 
  ggplot() +
  geom_violin(aes(x = ERP_type, y = amp)) +
  theme_bw() +
  labs(title = paste0('Mean amplitude (V) per trial (N = ', nrow(RawDetect),')'), 
       x = 'ERP interval')
```

### remove bad trials
Below, the bad trials were removed. These were marked during the initial data preparation.  

Number of trials = `r nrow(RawDetect %>% filter(bad == 0))`. Percentage of remaining trials = `r myround(nrow(RawDetect %>% filter(bad == 0)) / nrow(RawDetect) *100,1)`.  

The figure suggests that some outliers remained. The figure suggests that +/-25 V is a reasonable cut off for these outliers.  
```{r}
RawDetect %>% 
  filter(bad == 0) %>% # remove bad EEG trials
  pivot_longer(cols = c(EPN,LPP), names_to = 'ERP_type', values_to = 'amp' ) %>% 
  ggplot() +
  geom_violin(aes(x = ERP_type, y = amp)) +
  geom_hline(aes(yintercept = 25), linetype = 'longdash') +
  geom_hline(aes(yintercept = -25), linetype = 'longdash') +
  theme_bw() +
  labs(title = paste0('Mean amplitude (V) per trial (N = ', nrow(RawDetect %>% filter(bad == 0)),')'), 
       x = 'ERP interval')
# remove outliers
tmp <- nrow(RawDetect %>% filter(bad == 0))
RawDetect <- RawDetect %>% 
  mutate(bad = ifelse(abs(EPN) > 25 | abs(LPP) > 25 | is.na(EPN) | is.na(LPP), 1, bad))
tmp2 <- nrow(RawDetect %>% filter(bad == 0))
```

### remove outliers
The outliers were identified with the previous violin plot. 
Number of trials that were excluded: `r tmp-tmp2`.  
Number of remaining trials = `r nrow(RawDetect %>% filter(bad == 0))`. Percentage of remaining trials = `r myround(nrow(RawDetect %>% filter(bad == 0)) / nrow(RawDetect)*100,1)`.

```{r}
rm(tmp, tmp2)
RawDetect %>% 
  filter(bad == 0) %>% # remove bad trials and outliers
  pivot_longer(cols = c(EPN,LPP), names_to = 'ERP_type', values_to = 'amp' ) %>% 
  ggplot() +
  geom_violin(aes(x = ERP_type, y = amp)) +
  geom_hline(aes(yintercept = 25), linetype = 'longdash') +
  geom_hline(aes(yintercept = -25), linetype = 'longdash') +
  theme_bw() +
  labs(title = paste0('Mean amplitude (V) per trial (N = ', nrow(RawDetect %>% filter(bad == 0)),')'), 
       x = 'ERP interval')
```

### check distribution
Check how bad trials are distributed between spider and nonspiders. The expected percentages for bad spider trials is 25% (1 of 4 picture categories).

```{r}
RawDetect %>% 
  mutate(Treatment = ifelse(treat == 'Control', 'Control', 'IVET/VRET'),
         spider = ifelse(Emo == 'spider', 'spider', 'nonspider')) %>% 
  group_by(Treatment, spider) %>% 
  summarize(bad = sum(bad), .groups = 'drop') %>% 
  pivot_wider(names_from = 'spider', values_from = 'bad') %>% 
  mutate(bad_percent = spider/(spider+nonspider)*100) %>% 
  kable(align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

### N trials
Percentage of good EEG trials per recording.
```{r}
RawDetect %>% 
  group_by(treat, sess, fp) %>% 
  summarize(good = (1-sum(bad)/n())*100,.groups = 'drop') %>% 
  pull(good) %>% 
  summary()
```

### N trials by group
Percentage of good EEG trials per participant and group.
```{r}
RawDetect %>% 
  group_by(treat, sess, fp) %>% 
  summarize(good = (1-sum(bad)/n())*100,.groups = 'drop') %>% 
  mutate(sess = ifelse(sess == 0, 'pre', 'post')) %>% 
  unite(Condition, treat, sess, sep = " ") %>% 
  mutate(Condition = ifelse(Condition == 'Control pre', 'Control', Condition)) %>% 
  mutate(Condition = factor(Condition, levels=unique(as.character(Condition)))) %>% 
  group_by(Condition) %>% 
  summarize(N = n(),
            Mean = myround(mean(good),2),
            SD = myround(sd(good),2),
            .groups = 'drop') %>% 
  kable(align = "c") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

### N trials per block {.tabset}

#### plot

```{r}
RawDetect %>% 
  filter(bad == 0) %>% # remove bad trials and outliers
  mutate(block = case_when(
          Trial < 51 ~ 1,
          Trial < 101 ~ 2,
          Trial < 151 ~ 3,
          Trial < 201 ~ 4)) %>%  
  group_by(treat, sess, fp, Emo, block) %>% 
  summarize(ntrial = n(), .groups = 'drop') %>% 
  mutate(sess = ifelse(sess == 0, 'pre', 'post')) %>% 
  unite(Condition, treat, sess, sep = " ") %>% 
  mutate(Condition = ifelse(Condition == 'Control pre', 'Control', Condition)) %>% 
  group_by(Condition, Emo, block) %>% 
  summarise(N = paste0('(n=',n(),')'),
            Mean = mean(ntrial),
            .groups = 'drop') %>% 
  unite(Condition, Condition, N, sep = " ") %>% 
  ggplot(aes(x=block, y=Mean, by=Condition, color=Emo)) + 
  geom_line() +
  theme_bw() + # get rid of background
  facet_grid(~Condition) + 
  ylim(c(11, 13)) +
  labs(title = "Mean N valid EEG trials",
       y = "N trials")
```
#### analysis {.tabset}

focus on spider and neutral pictures

group average is baseline (because of sum coding)

note: the models did not converge for a complex random-effects structure

results do not suggest any interaction effects with block

##### summary 
```{r}
df_n <- RawDetect %>% 
  filter(bad == 0) %>% # remove bad trials and outliers
  filter(Emo %in% c("spider", "neutral")) %>% 
  mutate(block = case_when(
          Trial < 51 ~ 0,
          Trial < 101 ~ 1,
          Trial < 151 ~ 2,
          Trial < 201 ~ 3)) %>%  
  group_by(treat, sess, fp, Emo, block) %>% 
  summarize(ngood = n(), .groups = 'drop') %>% 
  mutate(sess = ifelse(sess == 0, 'pre', 'post')) %>% 
  unite(Condition, treat, sess, sep = " ") %>% 
  mutate(Condition = ifelse(Condition == 'Control pre', 'Control', Condition))

tmp <- RawDetect %>% 
  filter(bad == 1) %>% # keep bad trials
  filter(Emo %in% c("spider", "neutral")) %>% 
  mutate(block = case_when(
          Trial < 51 ~ 0,
          Trial < 101 ~ 1,
          Trial < 151 ~ 2,
          Trial < 201 ~ 3)) %>%  
  group_by(treat, sess, fp, Emo, block) %>% 
  summarize(nbad = n(), .groups = 'drop') %>% 
  mutate(sess = ifelse(sess == 0, 'pre', 'post')) %>% 
  unite(Condition, treat, sess, sep = " ") %>% 
  mutate(Condition = ifelse(Condition == 'Control pre', 'Control', Condition))

df_n <- left_join(df_n, tmp) %>% 
  mutate(nbad = ifelse(is.na(nbad), 0, nbad),
         Condition = as.factor(Condition))
rm(tmp)

contrasts(df_n$Condition) <- contr.treatment(5)

n_mod <- glmer(cbind(ngood, nbad) ~ -1 + block * Emo * Condition + (1 | fp),
               data = df_n,
               family = binomial, 
               control = glmerControl(optimizer = "bobyqa"))
summary(n_mod)
```

##### table
```{r}
tidy(n_mod, conf.int = TRUE) %>% 
  select(-group) %>% 
  kable() %>%
  kable_styling()
```

```{r, export Detect without outliers csv}
write_tsv(RawDetect, file.path('results/datadetect_clean.tsv'))
```

### prepare files
```{r}
detect <- RawDetect %>%
  filter(bad == 0) #%>% # remove bad EEG trials and outliers
 # # target trials
 # filter(Targ == 0) %>%
 # # false alarms
 # mutate(fals = ifelse(Targ==0 & NumResp>0, 1, 0)) %>%
 # filter(fals == 0) %>%
 # select(-fals)

# subset baseline data
detect_baseline <- detect %>%
  filter(sess == 0)

# combine treatments
# (IVET and VRET have different fp, ie subject ids)
detect_baseline_acrosstreatment <- detect_baseline %>%
  mutate(treat = ifelse(treat == "Control", "Control", "IVET/VRET"), 
         treat = factor(treat, levels = c("Control", "IVET/VRET")))

# filter out control
detect_only_treat <- detect %>%
  filter(!treat == "Control") %>%
  mutate(treat = factor(treat))

# recode treatment as -.5 and .5
detect_only_treat_recode <- detect_only_treat %>%
  mutate(treat =  ifelse(as.character(treat) == "IVET", -.5, .5)) #recode rating_type as -.5 and .5

# subtract the average across neutral pictures from each trial and re-reference
neutral_ERP <- detect %>%
  filter(Emo == "neutral") %>%
  group_by(fp, sess) %>%
  summarise(neutral_avg_LPP = mean(LPP, na.rm = TRUE),
            neutral_avg_EPN = mean(EPN, na.rm = TRUE),
            .groups = 'drop') # grouping is dropped

detect_diffneutral <- detect %>%
  filter(!Emo == "neutral") %>%
  left_join(., neutral_ERP, by = c("fp", "sess")) %>%
  mutate(LPP_diff = LPP - neutral_avg_LPP,
         EPN_diff = EPN - neutral_avg_EPN,
         Emo = factor(Emo, levels = c("spider", "negative", "positive")),
         treat = factor(treat))

detect_diffneutralEG <- detect_diffneutral %>%
  filter(!treat == "Control") %>%
  mutate(treat =  ifelse(as.character(treat) == "IVET", -.5, .5))
```

# descriptives with figures {.tabset}

## emotion ratings {.tabset}
### means
The table shows means (*SD* in parentheses).  
```{r}
rate %>%
  pivot_longer(cols = c(Ple, Aro), names_to = 'rating_type', values_to = 'rating') %>%
  group_by(fp, sess, treat, Emo, rating_type) %>%
  summarise(mean = mean(rating, na.rm = TRUE), .groups = 'drop') %>% 
  # grouping is dropped 
  mutate(rating_type = ifelse(rating_type == "Aro", "arousal", "pleasantness")) %>%
  ungroup() %>%
  mutate(sess = ifelse(sess == 0, "pre", "post"),
         sess = factor(sess, levels = c('pre', 'post'))) %>%
  unite(emo_rating, rating_type, Emo, sep = " ") %>%
  group_by(sess, treat, emo_rating) %>%
  summarise(N = n(),
            m_sd = sprintf("%.2f (%.2f)", mean(mean, na.rm = TRUE), 
                           sd(mean, na.rm = TRUE)), .groups = 'drop') %>%
  # grouping is dropped
  pivot_wider(names_from = emo_rating, values_from = m_sd) %>%
  rename("Treatment" = treat,
         "Session" = sess) %>%
  arrange(Treatment) %>%
  kable() %>%
  kable_styling()
```

### change scores
Compute difference scores relative to neutral pictures. For example, spider = spider - neutral.
```{r}
rate_diffneutral %>%
  pivot_longer(cols = c(Aro_diff, Ple_diff), names_to = 'rating_type', values_to = 'rating') %>% 
  group_by(fp, sess, treat, Emo, rating_type) %>%
  summarise(rating = mean(rating, na.rm = TRUE), .groups = 'drop') %>% 
  # grouping is dropped 
  mutate(sess = ifelse(sess == 0, "pre", "post"),
         sess = factor(sess, levels = c('pre', 'post'))) %>% 
  group_by(sess, treat, Emo, rating_type) %>%
  summarise(N = n(),
            Mean = mean(rating),
            LL = ci95LL(rating),
            UL = ci95UL(rating),
           .groups = 'drop') %>% 
  relocate(rating_type) %>% 
  arrange(rating_type, Emo, treat, sess) %>%
  rename("Rating" = rating_type,
         "Treatment" = treat,
         "Session" = sess, 
         "Category" = Emo) %>%
  kable() %>%
  kable_styling()
```

### plot
Plot change scores for spiders
```{r}
fig_rating <- rate_diffneutral %>%
  filter(Emo == "spider") %>% 
  pivot_longer(cols = c(Aro_diff, Ple_diff), names_to = 'rating_type', values_to = 'rating') %>% 
  group_by(fp, sess, treat, Emo, rating_type) %>%
  summarise(rating = mean(rating, na.rm = TRUE), .groups = 'drop') %>% 
  # grouping is dropped 
  mutate(sess = ifelse(sess == 0, "pre", "post"),
         sess = factor(sess, levels = c('pre', 'post')),
         rating_type = 
           ifelse(rating_type == "Aro_diff", "Arousal", "Pleasantness")) %>% 
  group_by(sess, treat, rating_type) %>%
  summarise(N = paste0('(n=',n(),')'),
            Mean = mean(rating),
            LL = ci95LL(rating),
            UL = ci95UL(rating),
           .groups = 'drop') %>% 
  relocate(rating_type) %>% 
  arrange(rating_type, treat, sess) %>%
  unite(Condition, treat, sess, sep = "-") %>% 
  mutate(Condition = ifelse(Condition == 'Control-pre', 'Control', Condition)) %>% 
  unite(Condition, Condition, N, sep = "\n") %>% 
  mutate(Condition = factor(Condition, levels=unique(as.character(Condition)))) %>% 
  ggplot(aes(x=Condition, y=Mean)) + 
  geom_bar(stat="identity"
          ,fill="gray"
          ,color="black" # add black border to each bar
          ,position=position_dodge()) + # separate bars
  theme_bw() + # get rid of background
  geom_errorbar(position=position_dodge(.9), width=.25, 
                aes(ymin=LL, ymax=UL)) +
  facet_wrap(~rating_type, nrow = 1) +
  labs(title = "Picture ratings") +
  # theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(x = "Group by session") +
  labs(y = "Rating difference (spiders-neutral)") 
fig_rating
ggsave('results/figures/fig_rating.png')
```


## mean amplitudes (EEG) {.tabset}
### means
The table shows means (*SD* in parentheses).  
```{r}
detect %>%
  pivot_longer(cols = c(EPN, LPP), names_to = 'erp_type', values_to = 'value') %>%
  group_by(fp, sess, treat, Emo, erp_type) %>%
  summarise(mean = mean(value, na.rm = TRUE), .groups = 'drop') %>% 
  # grouping is dropped
  mutate(sess = ifelse(sess == 0, "pre", "post"),
         sess = factor(sess, levels = c('pre', 'post'))) %>%
  unite(emo_rating, erp_type, Emo, sep = " ") %>%
  group_by(sess, treat, emo_rating) %>%
  summarise(N = n(),
            m_sd = sprintf("%.2f (%.2f)", 
                           mean(mean, na.rm = TRUE), 
                           sd(mean, na.rm = TRUE)), 
                           .groups = 'drop') %>% 
  # grouping is dropped
  pivot_wider(names_from = emo_rating, values_from = m_sd) %>%
  rename("Treatment" = treat,
         "Session" = sess) %>%
  arrange(Treatment) %>%
  kable() %>%
  kable_styling()
```

### change scores
Compute difference scores relative to neutral pictures. For example, spider = spider - neutral. Thus, the dependent variables capture EPN and LPP.  
```{r}
detect_diffneutral %>%
  group_by(fp, sess, treat, Emo) %>%
  summarise(EPN = mean(EPN_diff, na.rm = TRUE),
            LPP = mean(LPP_diff, na.rm = TRUE), .groups = 'drop') %>% # grouping is dropped 
  mutate(sess = ifelse(sess == 0, "pre", "post"),
         sess = factor(sess, levels = c('pre', 'post'))) %>% 
  group_by(sess, treat, Emo) %>%
  summarise(N = n(),
            EPN_Mean = mean(EPN),
            EPN_LL = ci95LL(EPN),
            EPN_UL = ci95UL(EPN),
            LPP_Mean = mean(LPP),
            LPP_LL = ci95LL(LPP),
            LPP_UL = ci95UL(LPP),
            .groups = 'drop') %>% 
  arrange(Emo, sess, treat) %>%
  rename("Treatment" = treat,
         "Session" = sess, 
         "Category" = Emo) %>%
  kable() %>%
  kable_styling()
```

### plot
Plot change scores for spiders
```{r}
tmpdata <- detect_diffneutral %>%
  filter(Emo == 'spider') %>% 
  pivot_longer(cols = c(EPN_diff, LPP_diff), names_to = 'erp_type', 
               values_to = 'value') %>%
  mutate(erp_type = ifelse(erp_type == 'EPN_diff','EPN','LPP')) %>% 
  group_by(fp, sess, treat, erp_type) %>%
  summarise(value = mean(value, na.rm = TRUE), .groups = 'drop') %>% 
  # grouping is dropped
  mutate(sess = ifelse(sess == 0, "pre", "post"),
         sess = factor(sess, levels = c('pre', 'post'))) %>% 
  group_by(sess, treat, erp_type) %>%
  summarise(N = paste0('(n=',n(),')'),
            Mean = mean(value),
            LL = ci95LL(value),
            UL = ci95UL(value),
            .groups = 'drop') %>% 
  arrange(treat, sess) %>% 
  unite(Condition, treat, sess, sep = " ") %>% 
  mutate(Condition = ifelse(Condition == 'Control pre', 'Control', Condition)) %>% 
  unite(Condition, Condition, N, sep = "\n") %>% 
  mutate(Condition = factor(Condition, levels=unique(as.character(Condition))))
fig_epn <- tmpdata %>% 
  filter(erp_type == 'EPN') %>% 
  ggplot(aes(x=Condition, y=Mean)) + 
  geom_bar(stat="identity"
          ,fill="gray"
          ,color="black" # add black border to each bar
          ,position=position_dodge()) + # separate bars
  theme_bw() + # get rid of background
  geom_errorbar(position=position_dodge(.9), width=.25, 
                aes(ymin=LL, ymax=UL)) +
  labs(title = "EPN to spiders (vs neutral)") +
    theme(plot.title = element_text(hjust = 0.5),
          text = element_text(size = 20),
          axis.text.x = element_text(size = 14)) +
  labs(x = "Group by session") +
  labs(y = "Mean amplitude (V)")
fig_epn
ggsave('results/figures/fig_meanamps_EPN.png', plot = fig_epn)
fig_lpp <- tmpdata %>% 
  filter(erp_type == 'LPP') %>% 
  ggplot(aes(x=Condition, y=Mean)) + 
  geom_bar(stat="identity"
          ,fill="gray"
          ,color="black" # add black border to each bar
          ,position=position_dodge()) + # separate bars
  theme_bw() + # get rid of background
  geom_errorbar(position=position_dodge(.9), width=.25, 
                aes(ymin=LL, ymax=UL)) +
  labs(title = "LPP to spiders (vs neutral)") +
    theme(plot.title = element_text(hjust = 0.5),
          text = element_text(size = 20),
          axis.text.x = element_text(size = 14)) +
  labs(x = "Group by session") +
  labs(y = "Mean amplitude (V)")
fig_lpp
ggsave('results/figures/fig_meanamps_LPP.png', plot = fig_lpp)
#fig_amp <- grid.arrange(fig_epn, fig_lpp, ncol = 2)
```

### save EPN and LPP
```{r}
detect %>%
  group_by(fp, sess, treat, Emo) %>%
  summarise(EPN = mean(EPN, na.rm = TRUE),
            LPP = mean(LPP, na.rm = TRUE), .groups = 'drop') %>% # grouping is dropped 
  write_tsv(file.path('results/datameanamps.tsv'))
```


# arousal ratings
Self-reported ratings of arousal during the rating task.

## session 1 three groups{.tabset}
* use session 1 from all three groups  
* examine if IVET and VRET differ from controls in spider (vs neutral) ratings in session 1
* compare IVET and VRET separately to the control group
* does not test whether the treatments differ from each other
* use neutral pictures as reference emotion
* save the model to save time  

```{r arousal ratings}
model_name <- "session_pre_all_groups_rating_arousal"
model_formula <- formula("rating ~ 1 + treat*Emo + (1 + Emo | fp)")
data <- rate_baseline %>% 
  filter(rating_type == "Aro")
if (file.exists(sprintf("results/models/model_%s.RDS", model_name))) {
  assign(get("model_name"), readRDS(sprintf("results/models/model_%s.RDS", model_name)))
} else {
  assign(get("model_name"), lmerTest::lmer(model_formula,
                                           control = lmerControl(optimizer = "bobyqa",
                                                                 optCtrl = list(maxfun = 1e5)),
                                           data = data))
  saveRDS(eval(parse(text = model_name)), sprintf("results/models/model_%s.RDS", model_name))
}
```

### plots {.tabset}
#### all categories
```{r}
fits <- data %>%
  modelr::data_grid(treat, Emo, fp) %>%
  mutate(predicted_re = predict(get(model_name), .),
         fp_treat = sprintf("%s_%s", fp, treat)) %>%
  filter(fp_treat %in% sprintf("%s_%s", data$fp, data$treat))
ggeffects::ggpredict(get(model_name), c("treat", "Emo")) %>%
  data.frame() %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(data = fits, aes(x = Emo, y = predicted_re, color = treat,
                             group = interaction(fp, treat)), alpha = .3, size = .2) +
  geom_line(aes(group = x), position = position_dodge(width = .15), size = 1) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .15), size = .5) +
  scale_color_manual(values = palette, name = "treatment") +
  labs(y = "Predicted arousal\n", x = "\nemotion") +
  plot_aes 
ggsave('results/figures/fig_rating_arousal_pre.png', plot = last_plot())
```

### summarize model
```{r}
summary(get(model_name))
tidied_model <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```

### model table {.tabset}
#### table of labels
```{r}
effectlbls <- data.frame(
  num = as.character(seq(1:12)), 
  original = tidied_model$term[1:12],
  standard = c("intercept (control, neutral)", 
               "treatment (IVET)", 
               "treatment (VRET)", 
               "emotion (spider)", 
               "emotion (negative)", 
               "emotion (positive)",
               "treatment (IVET) x emotion (spider)",
               "treatment (VRET) x emotion (spider)",
               "treatment (IVET) x emotion (negative)", 
               "treatment (VRET) x emotion (negative)",
               "treatment (IVET) x emotion (positive)", 
               "treatment (VRET) x emotion (positive)"),
  condition =  c("treatment (control) / emotion (neutral)", 
                 "treatment (IVET) / emotion (neutral)", 
                 "treatment (VRET) / emotion (neutral)", 
                 "treatment (control) / emotion (spider)", 
                 "treatment (control) / emotion (negative)", 
                 "treatment (control) / emotion (positive)",
                 "treatment (IVET) / emotion (spider)", 
                 "treatment (VRET) / emotion (spider)",
                 "treatment (IVET) / emotion (negative)", 
                 "treatment (VRET) / emotion (negative)",
                 "treatment (IVET) / emotion (positive)", 
                 "treatment (VRET) / emotion (positive)"),
  stringsAsFactors = F)
effectlbls %>%
  kable() %>%
  kable_styling()
```

#### standard labels
```{r}
table_model(get(model_name), 
            dv_labels = "session 1",
            pred_labels = paste(effectlbls[,1], effectlbls[,3]))
```

#### condition labels
```{r}
table_model(get(model_name), 
            dv_labels = "session 1",
            pred_labels = paste(effectlbls[,1], effectlbls[,4]))
```

### interpretation
```{r}
tm <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```
The goal is to examine whether IVET and VRET differ from controls in spider (vs neutral) ratings in the first session (but not in any other picture category). The analysis compares IVET and VRET separately to the control group and does not test whether the treatments differ from each other.

The formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  
Up to Emo as random effects: This means that the emo effect can differ between subjects. 

Intercept = treatment(control) / emotion(neutral).  

The effect for the intercept = **`r myround(tm$estimate[tm$term=="(Intercept)"],2)`**. This is the mean rating for the intercept that contains treatment(control) and emotion(neutral) and is thus the marginal mean for the control group for neutral pictures.  

The effect of the interaction is added to this together with lower-order terms to get the marginal mean. An interaction parameter is how much it differs from the lower order terms and the t-test is for the null hypothesis that the difference between these parameters is 0. When testing higher effects, the lower effects are removed. That is, the higher effects test for something over and above the lower effects. Accordingly, the estimated marginal means are the intercept + lower effects + estimate for higher effect. 

We want to see whether IVET and VRET differ from controls in their spider ratings. Because the intercept contains treatment(control) and emotion(neutral), we are interested in these tests:   
  
  **For IVET**:  
  `r pickme = "treatIVET:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format = "e")`  
This is the interaction of treatment(IVET vs control) x emotion (spider vs neutral) across ratings.  

**For VRET (same test as for IVET)**:  
  `r pickme = "treatVRET:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
This is the interaction of treatment(VRET vs control) x emotion (spider vs neutral) across ratings.  

### estimated means {.tabset}
```{r}
mmeans1 <- data %>%
  modelr::data_grid(treat, Emo) %>%
  mutate(marginal_mean = predict(get(model_name), ., re.form = NA)) %>%
  pivot_wider(names_from = Emo, values_from = marginal_mean)
mmeans1 %>%
  kable(digits = 2) %>%
  kable_styling()
```

## session 1 across treatments {.tabset}
* use session 1 from all three groups
* combine treatment groups
* use neutral pictures as reference emotion
* save the model to save time

```{r}
model_name <- "session_pre_across_treat_rating_arousal"
model_formula <- formula("rating ~ 1 + treat*Emo + (1 + Emo | fp)")
data <- rate_baseline_acrosstreatment %>% 
  filter(rating_type == "Aro")
if (file.exists(sprintf("results/models/model_%s.RDS", model_name))) {
  assign(get("model_name"), readRDS(sprintf("results/models/model_%s.RDS", model_name)))
} else {
  assign(get("model_name"), lmerTest::lmer(model_formula,
                                           control = lmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e5)),
                                           data = data))
  saveRDS(eval(parse(text = model_name)), sprintf("results/models/model_%s.RDS", model_name))
}
```

### plots {.tabset}
```{r}
fits <- data %>%
  modelr::data_grid(treat, Emo, fp) %>%
  mutate(predicted_re = predict(get(model_name), .),
         fp_treat = sprintf("%s_%s", fp, treat)) %>%
  filter(fp_treat %in% sprintf("%s_%s", data$fp, data$treat))
ggeffects::ggpredict(get(model_name), c("treat", "Emo")) %>%
  data.frame() %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(data = fits, aes(x = Emo, y = predicted_re, color = treat,
                             group = interaction(fp, treat)), alpha = .3, size = .2) +
  geom_line(aes(group = x), position = position_dodge(width = .15), size = 1) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .15), size = .5) +
  scale_color_manual(values = palette2, name = "treatment") +
  labs(y = "predicted arousal\n", x = "\nemotion") +
  plot_aes
```
### summarize model
```{r}
summary(get(model_name))
tidied_model <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```

### model table {.tabset}
#### table of labels
```{r}
effectlbls <- data.frame(
  num = as.character(seq(1:8)), 
  original = tidied_model$term[1:8],
  standard = c("intercept (control, neutral)", 
               "treatment (IVET/VRET)", 
               "emotion (spider)", 
               "emotion (negative)", 
               "emotion (positive)",
               "treatment (IVET/VRET) x emotion (spider)",
               "treatment (IVET/VRET) x emotion (negative)", 
               "treatment (IVET/VRET) x emotion (positive)"), 
  condition =  c("treatment (control) / emotion (neutral)", 
                 "treatment (IVET/VRET) / emotion (neutral)", 
                 "treatment (control) / emotion (spider)", 
                 "treatment (control) / emotion (negative)", 
                 "treatment (control) / emotion (positive)",
                 "treatment (IVET/VRET) / emotion (spider)", 
                 "treatment (IVET/VRET) / emotion (negative)", 
                 "treatment (IVET/VRET) / emotion (positive)"),
  stringsAsFactors = F)
effectlbls %>%
  kable() %>%
  kable_styling()
```

#### standard labels
```{r}
table_model(get(model_name), 
            dv_labels = "session 1",
            pred_labels = paste(effectlbls[,1], effectlbls[,3]))
```

#### condition labels
```{r}
table_model(get(model_name), 
            dv_labels = "session 1",
            pred_labels = paste(effectlbls[,1], effectlbls[,4]))
```

### interpretation
```{r}
tm <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```
The goal is to examine whether the combined treatment groups (IVET and VRET) differ from controls in spider (vs neutral) ratings in the first session (but not in any other picture category). The analysis compares the combined IVET and VRET to the control group and does not test whether the treatments differ from each other.

The formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  
Up to Emo as random effects: This means that the emo effect can differ between subjects. 

Intercept = treatment(control) / emotion(neutral).  

The effect for the intercept = **`r myround(tm$estimate[tm$term=="(Intercept)"], 2)`**. This is the mean rating for the intercept that contains treatment(control) and emotion(neutral) and is thus the marginal mean for the control group for neutral pictures.  

The effect of the interaction is added to this together with lower-order terms to get the marginal mean. An interaction parameter is how much it differs from the lower order terms and the t-test is for the null hypothesis that the difference between these parameters is 0. When testing higher effects, the lower effects are removed. That is, the higher effects test for something over and above the lower effects. Accordingly, the estimated marginal means are the intercept + lower effects + estimate for higher effect. 

We want to see whether the combined treatment groups (IVET and VRET) differ from controls in their spider ratings. Because the intercept contains treatment(control) and emotion(neutral), we are interested in these tests:   
  
  `r pickme = "treatIVET/VRET:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
This is the interaction of treatment(IVET/VRET vs control) x emotion (spider vs neutral) across ratings.  

### estimated means {.tabset}
```{r}
data %>%
  modelr::data_grid(treat, Emo) %>%
  mutate(marginal_mean = predict(get(model_name), ., re.form = NA)) %>%
  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%
  kable(digits = 2) %>%
  kable_styling()
```

### Bayes {.tabset}
#### ordinal model
```{r}
ratings_arousal_sess1 <- rate_baseline_acrosstreatment %>%
  filter(rating_type == "Aro") %>% 
  filter(Emo %in% c('spider', 'neutral')) %>%
  mutate(fp = as.factor(fp))
# Ordinal Regression Model.
ratings_arousal.sess1.model <- brm(rating ~ 1 + treat*Emo + (1 + Emo | fp),
                             family = cumulative("probit"),
                             data = na.omit(ratings_arousal_sess1),
                             prior = c(prior(normal(0, 4), class = Intercept),
                                       prior(normal(0, 4), class = b)),
                             chains = 4,
                             file = "results/models/ratings_arousal.sess1.model", 
                             # file to save/reuse model
                             cores = 4,
                             iter = 3000,
                             warmup = 1000,
                             init_r = 0.5,
                             save_pars = save_pars(all = TRUE))
# Model Summary.
summary(ratings_arousal.sess1.model)
```

### Bayes factor {.tabset}
only spider and neutral

#### computations
```{r}
null_arousal.sess1.model <- brm(rating ~ 1 + (1 + Emo | fp),
                          family = cumulative("probit"),
                          data = ratings_arousal_sess1,
                          prior = prior(normal(0, 4), class = Intercept),
                          chains = 4,
                          file = "results/models/rating_arousal.sess1.null", 
                          # Specify file to save/reuse model
                          cores = 4, 
                          iter = 3000,
                          warmup = 1000,
                          init_r = 0.5,
                          save_pars = save_pars(all = TRUE))
emo_arousal.sess1.model <- brm(rating ~ 1 + Emo + (1 + Emo | fp),
                         family = cumulative("probit"),
                         data = ratings_arousal_sess1,
                         prior = c(prior(normal(0, 4), class = Intercept),
                                   prior(normal(0, 4), class = b)),
                         chains = 4,
                         file = "results/models/rating_arousal.sess1.emo", 
                         # Specify file to save/reuse model
                         cores = 4, 
                         iter = 3000,
                         warmup = 1000,
                         init_r = 0.5,
                         save_pars = save_pars(all = TRUE))
treat_arousal.sess1.model <- brm(rating ~ 1 + treat + (1 + Emo | fp),
                           family = cumulative("probit"),
                           data = ratings_arousal_sess1,
                           prior = c(prior(normal(0, 4), class = Intercept),
                                     prior(normal(0, 4), class = b)),
                           chains = 4,
                           file = "results/models/rating_arousal.sess1.treat", 
                           # Specify file to save/reuse model
                           cores = 4, 
                           iter = 3000,
                           warmup = 1000,
                           init_r = 0.5,
                           save_pars = save_pars(all = TRUE))
```

Compute bayes factor approximations (via bridge sampling)
```{r}
# Bayes factor comparisons are in favor of alternative hypothesis.
full_arousal.sess1.bayes <- bayes_factor(ratings_arousal.sess1.model, null_arousal.sess1.model)
treat_arousal.sess1.bayes <- bayes_factor(treat_arousal.sess1.model, null_arousal.sess1.model)
emo_arousal.sess1.bayes <- bayes_factor(emo_arousal.sess1.model, null_arousal.sess1.model)

full_arousal.sess1.bayes
treat_arousal.sess1.bayes
emo_arousal.sess1.bayes
```

#### compare with null
```{r}
tibble(model = c("TreatxEmo", "Treat", "Emo"),
       Compared_To_Null = format(c(full_arousal.sess1.bayes$bf, 
                                   treat_arousal.sess1.bayes$bf, 
                                   emo_arousal.sess1.bayes$bf), scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### compare with Emo
```{r}
tibble(model = c("TreatxEmo", "Treat", "Emo"),
       Compared_To_Emo =  
         format(c(full_arousal.sess1.bayes$bf/emo_arousal.sess1.bayes$bf, 
         treat_arousal.sess1.bayes$bf/emo_arousal.sess1.bayes$bf,
         emo_arousal.sess1.bayes$bf/emo_arousal.sess1.bayes$bf), 
                                scientific = TRUE),
       BF01 = 
         format(c(emo_arousal.sess1.bayes$bf/full_arousal.sess1.bayes$bf, 
         emo_arousal.sess1.bayes$bf/treat_arousal.sess1.bayes$bf,
         emo_arousal.sess1.bayes$bf/emo_arousal.sess1.bayes$bf), 
                                scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### check assumptions
An ordinal regression has four assumptions:  

1. The dependent variables are ordered.
2. One or more of the independent variables are either continuous, categorical, or ordinal.
3. No multi-collinearity.
4. Proportional odds.

Check vif and tolerance (multicollinearity)
```{r}
check_collinearity(ratings_arousal.sess1.model)
```

## treatment comparison {.tabset}
* session 1 and session 2 (session 1 as reference)
* include only treatment groups
* IVET = -.5, VRET = .5
* use neutral pictures as reference emotion
```{r}
model_name <- "only_treat_rating_arousal"
model_formula <- formula("rating ~ 1 + treat*sess*Emo + (1 + sess*Emo | fp)")
data <- rate_only_treat_recode %>% 
  filter(rating_type == "Aro")
if (file.exists(sprintf("results/models/model_%s.RDS", model_name))) {
  assign(get("model_name"), readRDS(sprintf("results/models/model_%s.RDS", model_name)))
} else {
  assign(get("model_name"), lmerTest::lmer(model_formula,
                                           control = lmerControl(optimizer = "nloptwrap",
                                                                 optCtrl = list(maxfun = 1e7),
                                                                 calc.derivs = FALSE),
                                           data = data))
  saveRDS(eval(parse(text = model_name)), sprintf("results/models/model_%s.RDS", model_name))
}
```

### plots {.tabset}
#### all categories
```{r}
fits <- data %>%
  modelr::data_grid(treat, sess, Emo, fp) %>%
  mutate(predicted_re = predict(get(model_name), .),
         fp_treat = sprintf("%s_%s", fp, treat)) %>%
  filter(fp_treat %in% sprintf("%s_%s", data$fp, data$treat)) %>%
  mutate(sess = ifelse(sess == 0, 'pre', 'post'),
         sess = factor(sess, levels = c('pre', 'post')),
         treat = ifelse(treat == -.5, "IVET", "VRET"))
ggeffects::ggpredict(get(model_name), c("treat", "sess", "Emo")) %>%
  data.frame() %>%
  mutate(group = ifelse(group == 0, 'pre', 'post'),
         group = factor(group, levels = c('pre', 'post')),
         x = ifelse(x == -.5, "IVET", "VRET"),
         Emo = facet) %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat,
                             group = interaction(fp, treat, Emo)), alpha = .3, size = .2) +
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  facet_grid(~Emo) +
  scale_color_manual(values = palette[2:3], name = "treatment") +
  labs(y = "predicted arousal\n", x = "\nsession") +
  plot_aes
```

#### spider and neutral ratings
```{r}
fits <- data %>%
  modelr::data_grid(treat, sess, Emo, fp) %>%
  mutate(predicted_re = predict(get(model_name), .),
         fp_treat = sprintf("%s_%s", fp, treat)) %>%
  filter(fp_treat %in% sprintf("%s_%s", data$fp, data$treat)) %>%
  filter(Emo %in% c("neutral", "spider")) %>%
  mutate(sess = ifelse(sess == 0, 'pre', 'post'),
         sess = factor(sess, levels = c('pre', 'post')),
         treat = ifelse(treat == -.5, "IVET", "VRET"))
ggeffects::ggpredict(get(model_name), c("treat", "sess", "Emo")) %>%
  data.frame() %>%
  filter(facet %in% c("neutral", "spider")) %>%
  mutate(group = ifelse(group == 0, 'pre', 'post'),
         group = factor(group, levels = c('pre', 'post')),
         x = ifelse(x == -.5, "IVET", "VRET"),
         Emo = facet) %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat,
                             group = interaction(fp, treat, Emo)), alpha = .3, size = .2) +
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  facet_grid(~Emo) +
  scale_color_manual(values = palette[2:3], name = "treatment") +
  labs(y = "Predicted arousal\n", x = "\nsession") +
  plot_aes
ggsave('results/figures/fig_rating_arousal_treat.png', plot = last_plot())
```

### summarize model
```{r}
summary(get(model_name))
tidied_model <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```

### model table {.tabset}
#### table of labels
```{r}
effectlbls <- data.frame(
  num = as.character(seq(1:16)), 
  original = tidied_model$term[1:16],
  standard = c("intercept (avr_treat, session (1), neutral)",
               "treatment (VRET vs IVET)",
               "session (2)",
               "emotion (spider)",
               "emotion (negative)",
               "emotion (positive)",
               "treatment (VRET vs IVET) x session",
               "treatment (VRET vs IVET) x emotion (spider)",
               "treatment (VRET vs IVET) x emotion (negative)",
               "treatment (VRET vs IVET) x emotion (positive)",
               "session x emotion (spider)",
               "session x emotion (negative)",
               "session x emotion (positive)",
               "treatment (VRET vs IVET) x session x emotion (spider)",
               "treatment (VRET vs IVET) x session x emotion (negative)",
               "treatment (VRET vs IVET) x session x emotion (positive)"),
  condition = c("treatment (avr_treat) / session (1) / emotion (neutral)",
                "treatment (VRET vs IVET) / sess (1) / emotion (neutral)",
                "treatment (avr_treat) / sess (2) / emotion (neutral)",
                "treatment (avr_treat) / sess (1) / emotion (spider)",
                "treatment (avr_treat) / sess (1) / emotion (negative)",
                "treatment (avr_treat) / sess (1) / emotion (positive)",
                "treatment (VRET vs IVET) / sess (2) / emotion (neutral)",
                "treatment (VRET vs IVET) / sess (1) / emotion (spider)",
                "treatment (VRET vs IVET) / sess (1) / emotion (negative)",
                "treatment (VRET vs IVET) / sess (1) / emotion (positive)",
                "treatment (avr_treat) / sess (2) / emotion (spider)",
                "treatment (avr_treat) / sess (2) / emotion (negative)",
                "treatment (avr_treat) / sess (2) / emotion (positive)",
                "treatment (VRET vs IVET) / sess (2) / emotion (spider)",
                "treatment (VRET vs IVET) / sess (2) / emotion (negative)",
                "treatment (VRET vs IVET) / sess (2) / emotion (positive)"),
  stringsAsFactors = F)
effectlbls %>%
  kable() %>%
  kable_styling()
```

#### standard labels
```{r}
table_model(get(model_name), 
            dv_labels = "only treat model",
            pred_labels = paste(effectlbls[,1], effectlbls[,3]))
```

#### condition labels
```{r}
table_model(get(model_name), 
            dv_labels = "only treat model",
            pred_labels = paste(effectlbls[,1], effectlbls[,4]))
```

### interpretation
```{r}
tm <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```
The goal is to examine whether IVET and VRET differ from each other in spider (vs neutral) ratings in the first session and between the first and second session (but not in any other picture category). 

The formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  
Emo by sess as random effects: This means that emo, session, and the emo by session can differ between subjects. 

Intercept = treatment(avr_treat) / session (1) / emotion (neutral).  
avr_treat is the mean of IVET and VRET.  

The effect for the intercept = **`r myround(tm$estimate[tm$term=="(Intercept)"], 2)`**. This is the mean rating for the intercept that contains the average across treatments in session 1 to neutral pictures.  

The effect of the interaction is added to this together with lower-order terms to get the marginal mean. An interaction parameter is how much it differs from the lower order terms and the t-test is for the null hypothesis that the difference between these parameters is 0. When testing higher effects, the lower effects are removed. That is, the higher effects test for something over and above the lower effects. Accordingly, the estimated marginal means are the intercept + lower effects + estimate for higher effect. 

We want to see whether the groups rated spiders differently from neutral pictures in session 1.  
`r pickme = "Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
Indeed, spiders are rated more emotional.  
(Note that the session 1 analysis with three groups tested each treatment compared to the control group.)  

Did the groups differ in how they rated spiders from neutral pictures in session 1? The next analysis suggests: No.  
`r pickme = "treat:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
(Note that the session 1 analysis with three groups tested each treatment compared to the control group.)  

Next, we examine whether the effect of spiders differed between sessions. 
`r pickme = "sess:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
Indeed, spiders (vs neutral) are rated less emotional in session 2 than session 1.  

Critically, did this effect vary with treatment?  
  `r pickme = "treat:sess:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
No, it does not look like that the treatment groups differed.  

All the other tests concern pictures other than spiders. 

### estimated means {.tabset}
```{r}
data %>%
  modelr::data_grid(treat, Emo, sess) %>%
  mutate(marginal_mean = predict(get(model_name), ., re.form = NA),
         treat = ifelse(treat == -.5, "IVET", "VRET"),
         sess = ifelse(sess == 0, 'pre', 'post'),
         sess = factor(sess, levels = c('pre', 'post'))) %>%
  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%
  kable(digits = 2) %>%
  kable_styling()
```

### Bayes {.tabset}
#### ordinal model
```{r}
ratings_arousal_treat <- rate_only_treat_recode %>% 
  filter(rating_type == "Aro") %>% 
  filter(Emo %in% c('spider', 'neutral')) %>% 
  mutate(fp = as.factor(fp))
# Ordinal Regression Model.
ratings_arousal.treat.model <- brm(rating ~ 1 + treat*sess*Emo + (1 + sess*Emo | fp), 
                             family = cumulative("probit"),
                             data = na.omit(ratings_arousal_treat),
                             prior = c(prior(normal(0, 4), class = Intercept),
                                       prior(normal(0, 4), class = b)),
                             chains = 4,
                             file = "results/models/ratings_arousal.treat.model", 
                             # file to save/reuse model
                             cores = 4, 
                             iter = 3000,
                             warmup = 1000,
                             init_r = 0.5,
                             save_pars = save_pars(all = TRUE))
# Model Summary.
summary(ratings_arousal.treat.model)
```

### Bayes factor {.tabset}
only spider and neutral

#### computations
```{r}
null_arousal.treat.model <- brm(rating ~ 1 + (1 + sess*Emo | fp),
                          family = cumulative("probit"),
                          data = ratings_arousal_treat,
                          prior = prior(normal(0, 4), class = Intercept),
                          chains = 4,
                          file = "results/models/rating_arousal.treat.null", 
                          # Specify file to save/reuse model
                          cores = 4, 
                          iter = 3000,
                          warmup = 1000,
                          init_r = 0.5,
                          save_pars = save_pars(all = TRUE))
sess_emo.treat_arousal.model <- brm(rating ~ 1 + sess*Emo + (1 + sess*Emo | fp),
                              family = cumulative("probit"),
                              data = ratings_arousal_treat,
                              prior = c(prior(normal(0, 4), class = Intercept),
                                        prior(normal(0, 4), class = b)),
                              chains = 4,
                              file = "results/models/rating_arousal.treat.sess_emo", 
                              cores = 4, 
                              iter = 3000,
                              warmup = 1000,
                              save_pars = save_pars(all = TRUE))
emo.treat_arousal.model <- brm(rating ~ 1 + Emo + (1 + sess*Emo | fp),
                         family = cumulative("probit"),
                         data = ratings_arousal_treat,
                         prior = c(prior(normal(0, 4), class = Intercept),
                                   prior(normal(0, 4), class = b)),
                         chains = 4,
                         file = "results/models/rating_arousal.treat.emo", 
                         cores = 4, 
                         iter = 3000,
                         warmup = 1000,
                         save_pars = save_pars(all = TRUE))
```

Compute bayes factor approximations (via bridge sampling)
```{r}
# Bayes factor comparisons are in favor of alternative hypothesis.
full.treat_arousal.bayes <- bayes_factor(ratings_arousal.treat.model, null_arousal.treat.model)
sess_emo.treat_arousal.bayes <- bayes_factor(sess_emo.treat_arousal.model, null_arousal.treat.model)
emo.treat_arousal.bayes <- bayes_factor(emo.treat_arousal.model, null_arousal.treat.model)

full.treat_arousal.bayes
sess_emo.treat_arousal.bayes
emo.treat_arousal.bayes
```

#### compare with null
```{r}
tibble(model = c("TreatxSessxEmo", "SessxEmo", "Emo"),
       Compared_To_Null = format(c(full.treat_arousal.bayes$bf, 
                                   sess_emo.treat_arousal.bayes$bf, 
                                   emo.treat_arousal.bayes$bf), scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### compare with Sess x Emo
```{r}
tibble(model = c("TreatxSessxEmo", "SessxEmo", "Emo"),
       Compared_To_SessxEmo =     
         format(c(full.treat_arousal.bayes$bf/sess_emo.treat_arousal.bayes$bf,
                  sess_emo.treat_arousal.bayes$bf/sess_emo.treat_arousal.bayes$bf,
                  emo.treat_arousal.bayes$bf/sess_emo.treat_arousal.bayes$bf),
                                               scientific = TRUE),
         BF01 =   format(c(sess_emo.treat_arousal.bayes$bf/full.treat_arousal.bayes$bf,
                  sess_emo.treat_arousal.bayes$bf/sess_emo.treat_arousal.bayes$bf,
                  sess_emo.treat_arousal.bayes$bf/emo.treat_arousal.bayes$bf))) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### compare with Treat x Sess x Emo
```{r}
tibble(model = c("TreatxSessxEmo", "SessxEmo", "Emo"),
       Compared_To_TreatxSessxEmo =   
         format(c(full.treat_arousal.bayes$bf/full.treat_arousal.bayes$bf,
                  sess_emo.treat_arousal.bayes$bf/full.treat_arousal.bayes$bf, 
                  emo.treat_arousal.bayes$bf/full.treat_arousal.bayes$bf),
                                               scientific = TRUE),
       BF01 =   format(c(full.treat_arousal.bayes$bf/full.treat_arousal.bayes$bf,
                  full.treat_arousal.bayes$bf/sess_emo.treat_arousal.bayes$bf, 
                  full.treat_arousal.bayes$bf/emo.treat_arousal.bayes$bf))) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### check assumptions
An ordinal regression has four assumptions:  

1. The dependent variables are ordered.
2. One or more of the independent variables are either continuous, categorical, or ordinal.
3. No multi-collinearity.
4. Proportional odds.

Check vif and tolerance (multicollinearity)
```{r}
check_collinearity(ratings_arousal.treat.model)
```

# valence ratings
Self-reported ratings of valence during the rating task.

## session 1 three groups{.tabset}
* use session 1 from all three groups  
* examine if IVET and VRET differ from controls in spider (vs neutral) ratings in session 1
* compare IVET and VRET separately to the control group
* does not test whether the treatments differ from each other
* use neutral pictures as reference emotion
* save the model to save time  

```{r valence ratings}
model_name <- "session_pre_all_groups_rating_valence"
model_formula <- formula("rating ~ 1 + treat*Emo + (1 + Emo | fp)")
data <- rate_baseline %>% 
  filter(rating_type == "Ple")
if (file.exists(sprintf("results/models/model_%s.RDS", model_name))) {
  assign(get("model_name"), readRDS(sprintf("results/models/model_%s.RDS", model_name)))
} else {
  assign(get("model_name"), lmerTest::lmer(model_formula,
                                           control = lmerControl(optimizer = "bobyqa",
                                                                 optCtrl = list(maxfun = 1e5)),
                                           data = data))
  saveRDS(eval(parse(text = model_name)), sprintf("results/models/model_%s.RDS", model_name))
}
```

### plots {.tabset}
```{r}
fits <- data %>%
  modelr::data_grid(treat, Emo, fp) %>%
  mutate(predicted_re = predict(get(model_name), .),
         fp_treat = sprintf("%s_%s", fp, treat)) %>%
  filter(fp_treat %in% sprintf("%s_%s", data$fp, data$treat))
ggeffects::ggpredict(get(model_name), c("treat", "Emo")) %>%
  data.frame() %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(data = fits, aes(x = Emo, y = predicted_re, color = treat,
                             group = interaction(fp, treat)), alpha = .3, size = .2) +
  geom_line(aes(group = x), position = position_dodge(width = .15), size = 1) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .15), size = .5) +
  scale_color_manual(values = palette, name = "treatment") +
  labs(y = "Predicted valence\n", x = "\nemotion") +
  plot_aes
ggsave('results/figures/fig_rating_valence_pre.png', plot = last_plot())
```

### summarize model
```{r}
summary(get(model_name))
tidied_model <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```

### model table {.tabset}
#### table of labels
```{r}
effectlbls <- data.frame(
  num = as.character(seq(1:12)), 
  original = tidied_model$term[1:12],
  standard = c("intercept (control, neutral)", 
               "treatment (IVET)", 
               "treatment (VRET)", 
               "emotion (spider)", 
               "emotion (negative)", 
               "emotion (positive)",
               "treatment (IVET) x emotion (spider)",
               "treatment (VRET) x emotion (spider)",
               "treatment (IVET) x emotion (negative)", 
               "treatment (VRET) x emotion (negative)",
               "treatment (IVET) x emotion (positive)", 
               "treatment (VRET) x emotion (positive)"),
  condition =  c("treatment (control) / emotion (neutral)", 
                 "treatment (IVET) / emotion (neutral)", 
                 "treatment (VRET) / emotion (neutral)", 
                 "treatment (control) / emotion (spider)", 
                 "treatment (control) / emotion (negative)", 
                 "treatment (control) / emotion (positive)",
                 "treatment (IVET) / emotion (spider)", 
                 "treatment (VRET) / emotion (spider)",
                 "treatment (IVET) / emotion (negative)", 
                 "treatment (VRET) / emotion (negative)",
                 "treatment (IVET) / emotion (positive)", 
                 "treatment (VRET) / emotion (positive)"),
  stringsAsFactors = F)
effectlbls %>%
  kable() %>%
  kable_styling()
```

#### standard labels
```{r}
table_model(get(model_name), 
            dv_labels = "session 1",
            pred_labels = paste(effectlbls[,1], effectlbls[,3]))
```

#### condition labels
```{r}
table_model(get(model_name), 
            dv_labels = "session 1",
            pred_labels = paste(effectlbls[,1], effectlbls[,4]))
```

### interpretation
```{r}
tm <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```
The goal is to examine whether IVET and VRET differ from controls in spider (vs neutral) ratings in the first session (but not in any other picture category). The analysis compares IVET and VRET separately to the control group and does not test whether the treatments differ from each other.

The formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  
Up to Emo as random effects: This means that the emo effect can differ between subjects. 

Intercept = treatment(control) / emotion(neutral).  

The effect for the intercept = **`r myround(tm$estimate[tm$term=="(Intercept)"],2)`**. This is the mean rating for the intercept that contains treatment(control) and emotion(neutral) and is thus the marginal mean for the control group for neutral pictures.  

The effect of the interaction is added to this together with lower-order terms to get the marginal mean. An interaction parameter is how much it differs from the lower order terms and the t-test is for the null hypothesis that the difference between these parameters is 0. When testing higher effects, the lower effects are removed. That is, the higher effects test for something over and above the lower effects. Accordingly, the estimated marginal means are the intercept + lower effects + estimate for higher effect. 

We want to see whether IVET and VRET differ from controls in their spider ratings. Because the intercept contains treatment(control) and emotion(neutral), we are interested in these tests:   
  
  **For IVET**:  
  `r pickme = "treatIVET:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format = "e")`  
This is the interaction of treatment(IVET vs control) x emotion (spider vs neutral) across ratings.  

**For VRET (same test as for IVET)**:  
  `r pickme = "treatVRET:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
This is the interaction of treatment(VRET vs control) x emotion (spider vs neutral) across ratings.  

### estimated means {.tabset}
```{r}
mmeans1 <- data %>%
  modelr::data_grid(treat, Emo) %>%
  mutate(marginal_mean = predict(get(model_name), ., re.form = NA)) %>%
  pivot_wider(names_from = Emo, values_from = marginal_mean)
mmeans1 %>%
  kable(digits = 2) %>%
  kable_styling()
```

## session 1 across treatments {.tabset}
* use session 1 from all three groups
* combine treatment groups
* use neutral pictures as reference emotion
* save the model to save time
```{r}
model_name <- "session_pre_across_treat_rating_valence"
model_formula <- formula("rating ~ 1 + treat*Emo + (1 + Emo | fp)")
data <- rate_baseline_acrosstreatment %>% 
  filter(rating_type == "Ple")
if (file.exists(sprintf("results/models/model_%s.RDS", model_name))) {
  assign(get("model_name"), readRDS(sprintf("results/models/model_%s.RDS", model_name)))
} else {
  assign(get("model_name"), lmerTest::lmer(model_formula,
                                           control = lmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 1e5)),
                                           data = data))
  saveRDS(eval(parse(text = model_name)), sprintf("results/models/model_%s.RDS", model_name))
}
```

### plots {.tabset}
```{r}
fits <- data %>%
  modelr::data_grid(treat, Emo, fp) %>%
  mutate(predicted_re = predict(get(model_name), .),
         fp_treat = sprintf("%s_%s", fp, treat)) %>%
  filter(fp_treat %in% sprintf("%s_%s", data$fp, data$treat))
ggeffects::ggpredict(get(model_name), c("treat", "Emo")) %>%
  data.frame() %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(data = fits, aes(x = Emo, y = predicted_re, color = treat,
                             group = interaction(fp, treat)), alpha = .3, size = .2) +
  geom_line(aes(group = x), position = position_dodge(width = .15), size = 1) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .15), size = .5) +
  scale_color_manual(values = palette2, name = "treatment") +
  labs(y = "predicted valence\n", x = "\nemotion") +
  plot_aes
```
### summarize model
```{r}
summary(get(model_name))
tidied_model <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```

### model table {.tabset}
#### table of labels
```{r}
effectlbls <- data.frame(
  num = as.character(seq(1:8)), 
  original = tidied_model$term[1:8],
  standard = c("intercept (control, neutral)", 
               "treatment (IVET/VRET)", 
               "emotion (spider)", 
               "emotion (negative)", 
               "emotion (positive)",
               "treatment (IVET/VRET) x emotion (spider)",
               "treatment (IVET/VRET) x emotion (negative)", 
               "treatment (IVET/VRET) x emotion (positive)"), 
  condition =  c("treatment (control) / emotion (neutral)", 
                 "treatment (IVET/VRET) / emotion (neutral)", 
                 "treatment (control) / emotion (spider)", 
                 "treatment (control) / emotion (negative)", 
                 "treatment (control) / emotion (positive)",
                 "treatment (IVET/VRET) / emotion (spider)", 
                 "treatment (IVET/VRET) / emotion (negative)", 
                 "treatment (IVET/VRET) / emotion (positive)"),
  stringsAsFactors = F)
effectlbls %>%
  kable() %>%
  kable_styling()
```

#### standard labels
```{r}
table_model(get(model_name), 
            dv_labels = "session 1",
            pred_labels = paste(effectlbls[,1], effectlbls[,3]))
```

#### condition labels
```{r}
table_model(get(model_name), 
            dv_labels = "session 1",
            pred_labels = paste(effectlbls[,1], effectlbls[,4]))
```

### interpretation
```{r}
tm <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```
The goal is to examine whether the combined treatment groups (IVET and VRET) differ from controls in spider (vs neutral) ratings in the first session (but not in any other picture category). The analysis compares the combined IVET and VRET to the control group and does not test whether the treatments differ from each other.

The formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  
Up to Emo as random effects: This means that the emo effect can differ between subjects. 

Intercept = treatment(control) / emotion(neutral).  

The effect for the intercept = **`r myround(tm$estimate[tm$term=="(Intercept)"], 2)`**. This is the mean rating for the intercept that contains treatment(control) and emotion(neutral) and is thus the marginal mean for the control group for neutral pictures.  

The effect of the interaction is added to this together with lower-order terms to get the marginal mean. An interaction parameter is how much it differs from the lower order terms and the t-test is for the null hypothesis that the difference between these parameters is 0. When testing higher effects, the lower effects are removed. That is, the higher effects test for something over and above the lower effects. Accordingly, the estimated marginal means are the intercept + lower effects + estimate for higher effect. 

We want to see whether the combined treatment groups (IVET and VRET) differ from controls in their spider ratings. Because the intercept contains treatment(control) and emotion(neutral), we are interested in these tests:   
  
  `r pickme = "treatIVET/VRET:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
This is the interaction of treatment(IVET/VRET vs control) x emotion (spider vs neutral) across ratings.  

### estimated means {.tabset}
```{r}
data %>%
  modelr::data_grid(treat, Emo) %>%
  mutate(marginal_mean = predict(get(model_name), ., re.form = NA)) %>%
  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%
  kable(digits = 2) %>%
  kable_styling()
```

### Bayes {.tabset}
#### ordinal model
```{r}
ratings_valence_sess1 <- rate_baseline_acrosstreatment %>%
  filter(rating_type == "Ple") %>% 
  filter(Emo %in% c('spider', 'neutral')) %>%
  mutate(fp = as.factor(fp))
# Ordinal Regression Model.
ratings_valence.sess1.model <- brm(rating ~ 1 + treat*Emo + (1 + Emo | fp),
                             family = cumulative("probit"),
                             data = na.omit(ratings_valence_sess1),
                             prior = c(prior(normal(0, 4), class = Intercept),
                                       prior(normal(0, 4), class = b)),
                             chains = 4,
                             file = "results/models/ratings_valence.sess1.model", 
                             # file to save/reuse model
                             cores = 4,
                             iter = 3000,
                             warmup = 1000,
                             init_r = 0.5,
                             save_pars = save_pars(all = TRUE))
# Model Summary.
summary(ratings_valence.sess1.model)
```

### Bayes factor {.tabset}
only spider and neutral

#### computations
```{r}
null_valence.sess1.model <- brm(rating ~ 1 + (1 + Emo | fp),
                          family = cumulative("probit"),
                          data = ratings_valence_sess1,
                          prior = prior(normal(0, 4), class = Intercept),
                          chains = 4,
                          file = "results/models/rating_valence.sess1.null", 
                          # Specify file to save/reuse model
                          cores = 4, 
                          iter = 3000,
                          warmup = 1000,
                          init_r = 0.5,
                          save_pars = save_pars(all = TRUE))
emo_valence.sess1.model <- brm(rating ~ 1 + Emo + (1 + Emo | fp),
                         family = cumulative("probit"),
                         data = ratings_valence_sess1,
                         prior = c(prior(normal(0, 4), class = Intercept),
                                   prior(normal(0, 4), class = b)),
                         chains = 4,
                         file = "results/models/rating_valence.sess1.emo", 
                         # Specify file to save/reuse model
                         cores = 4, 
                         iter = 3000,
                         warmup = 1000,
                         init_r = 0.5,
                         save_pars = save_pars(all = TRUE))
treat_valence.sess1.model <- brm(rating ~ 1 + treat + (1 + Emo | fp),
                           family = cumulative("probit"),
                           data = ratings_valence_sess1,
                           prior = c(prior(normal(0, 4), class = Intercept),
                                     prior(normal(0, 4), class = b)),
                           chains = 4,
                           file = "results/models/rating_valence.sess1.treat", 
                           # Specify file to save/reuse model
                           cores = 4, 
                           iter = 3000,
                           warmup = 1000,
                           init_r = 0.5,
                           save_pars = save_pars(all = TRUE))
```

Compute bayes factor approximations (via bridge sampling)
```{r}
# Bayes factor comparisons are in favor of alternative hypothesis.
full_valence.sess1.bayes <- bayes_factor(ratings_valence.sess1.model, null_valence.sess1.model)
treat_valence.sess1.bayes <- bayes_factor(treat_valence.sess1.model, null_valence.sess1.model)
emo_valence.sess1.bayes <- bayes_factor(emo_valence.sess1.model, null_valence.sess1.model)

full_valence.sess1.bayes
treat_valence.sess1.bayes
emo_valence.sess1.bayes
```

#### compare with null
```{r}
tibble(model = c("TreatxEmo", "Treat", "Emo"),
       Compared_To_Null = format(c(full_valence.sess1.bayes$bf, 
                                   treat_valence.sess1.bayes$bf, 
                                   emo_valence.sess1.bayes$bf), scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### compare with Emo
```{r}
tibble(model = c("TreatxEmo", "Treat", "Emo"),
       Compared_To_Emo =
         format(c(full_valence.sess1.bayes$bf/emo_valence.sess1.bayes$bf, 
                  treat_valence.sess1.bayes$bf/emo_valence.sess1.bayes$bf,
                  emo_valence.sess1.bayes$bf/emo_valence.sess1.bayes$bf), 
                                scientific = TRUE),  
         BF01 = 
         format(c(emo_valence.sess1.bayes$bf/full_valence.sess1.bayes$bf, 
         emo_valence.sess1.bayes$bf/treat_valence.sess1.bayes$bf,
         emo_valence.sess1.bayes$bf/emo_valence.sess1.bayes$bf), 
                                scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```


#### check assumptions
An ordinal regression has four assumptions:  

1. The dependent variables are ordered.
2. One or more of the independent variables are either continuous, categorical, or ordinal.
3. No multi-collinearity.
4. Proportional odds.

Check vif and tolerance (multicollinearity)
```{r}
check_collinearity(ratings_valence.sess1.model)
```

## treatment comparison {.tabset}
* session 1 and session 2 (session 1 as reference)
* include only treatment groups
* IVET = -.5, VRET = .5
* use neutral pictures as reference emotion
```{r}
model_name <- "only_treat_rating_valence"
model_formula <- formula("rating ~ 1 + treat*sess*Emo + (1 + sess*Emo | fp)")
data <- rate_only_treat_recode %>% 
  filter(rating_type == "Ple")
if (file.exists(sprintf("results/models/model_%s.RDS", model_name))) {
  assign(get("model_name"), readRDS(sprintf("results/models/model_%s.RDS", model_name)))
} else {
  assign(get("model_name"), lmerTest::lmer(model_formula,
                                           control = lmerControl(optimizer = "nloptwrap",
                                                                 optCtrl = list(maxfun = 1e7),
                                                                 calc.derivs = FALSE),
                                           data = data))
  saveRDS(eval(parse(text = model_name)), sprintf("results/models/model_%s.RDS", model_name))
}
```

### plots {.tabset}
#### all categories
```{r}
fits <- data %>%
  modelr::data_grid(treat, sess, Emo, fp) %>%
  mutate(predicted_re = predict(get(model_name), .),
         fp_treat = sprintf("%s_%s", fp, treat)) %>%
  filter(fp_treat %in% sprintf("%s_%s", data$fp, data$treat)) %>%
  mutate(sess = ifelse(sess == 0, 'pre', 'post'),
         sess = factor(sess, levels = c('pre', 'post')),
         treat = ifelse(treat == -.5, "IVET", "VRET"))
ggeffects::ggpredict(get(model_name), c("treat", "sess", "Emo")) %>%
  data.frame() %>%
  mutate(group = ifelse(group == 0, 'pre', 'post'),
         group = factor(group, levels = c('pre', 'post')),
         x = ifelse(x == -.5, "IVET", "VRET"),
         Emo = facet) %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat,
                             group = interaction(fp, treat, Emo)), alpha = .3, size = .2) +
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  facet_grid(~Emo) +
  scale_color_manual(values = palette[2:3], name = "treatment") +
  labs(y = "predicted valence\n", x = "\nsession") +
  plot_aes
```

#### spider and neutral ratings
```{r}
fits <- data %>%
  modelr::data_grid(treat, sess, Emo, fp) %>%
  mutate(predicted_re = predict(get(model_name), .),
         fp_treat = sprintf("%s_%s", fp, treat)) %>%
  filter(fp_treat %in% sprintf("%s_%s", data$fp, data$treat)) %>%
  filter(Emo %in% c("neutral", "spider")) %>%
  mutate(sess = ifelse(sess == 0, 'pre', 'post'),
         sess = factor(sess, levels = c('pre', 'post')),
         treat = ifelse(treat == -.5, "IVET", "VRET"))
ggeffects::ggpredict(get(model_name), c("treat", "sess", "Emo")) %>%
  data.frame() %>%
  filter(facet %in% c("neutral", "spider")) %>%
  mutate(group = ifelse(group == 0, 'pre', 'post'),
         group = factor(group, levels = c('pre', 'post')),
         x = ifelse(x == -.5, "IVET", "VRET"),
         Emo = facet) %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat,
                             group = interaction(fp, treat, Emo)), alpha = .3, size = .2) +
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  facet_grid(~Emo) +
  scale_color_manual(values = palette[2:3], name = "treatment") +
  labs(y = "Predicted valence\n", x = "\nsession") +
  plot_aes
ggsave('results/figures/fig_rating_valence_treat.png', plot = last_plot())
```

### summarize model
```{r}
summary(get(model_name))
tidied_model <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```

### model table {.tabset}
#### table of labels
```{r}
effectlbls <- data.frame(
  num = as.character(seq(1:16)), 
  original = tidied_model$term[1:16],
  standard = c("intercept (avr_treat, session (1), neutral)",
               "treatment (VRET vs IVET)",
               "session (2)",
               "emotion (spider)",
               "emotion (negative)",
               "emotion (positive)",
               "treatment (VRET vs IVET) x session",
               "treatment (VRET vs IVET) x emotion (spider)",
               "treatment (VRET vs IVET) x emotion (negative)",
               "treatment (VRET vs IVET) x emotion (positive)",
               "session x emotion (spider)",
               "session x emotion (negative)",
               "session x emotion (positive)",
               "treatment (VRET vs IVET) x session x emotion (spider)",
               "treatment (VRET vs IVET) x session x emotion (negative)",
               "treatment (VRET vs IVET) x session x emotion (positive)"),
  condition = c("treatment (avr_treat) / session (1) / emotion (neutral)",
                "treatment (VRET vs IVET) / sess (1) / emotion (neutral)",
                "treatment (avr_treat) / sess (2) / emotion (neutral)",
                "treatment (avr_treat) / sess (1) / emotion (spider)",
                "treatment (avr_treat) / sess (1) / emotion (negative)",
                "treatment (avr_treat) / sess (1) / emotion (positive)",
                "treatment (VRET vs IVET) / sess (2) / emotion (neutral)",
                "treatment (VRET vs IVET) / sess (1) / emotion (spider)",
                "treatment (VRET vs IVET) / sess (1) / emotion (negative)",
                "treatment (VRET vs IVET) / sess (1) / emotion (positive)",
                "treatment (avr_treat) / sess (2) / emotion (spider)",
                "treatment (avr_treat) / sess (2) / emotion (negative)",
                "treatment (avr_treat) / sess (2) / emotion (positive)",
                "treatment (VRET vs IVET) / sess (2) / emotion (spider)",
                "treatment (VRET vs IVET) / sess (2) / emotion (negative)",
                "treatment (VRET vs IVET) / sess (2) / emotion (positive)"),
  stringsAsFactors = F)
effectlbls %>%
  kable() %>%
  kable_styling()
```

#### standard labels
```{r}
table_model(get(model_name), 
            dv_labels = "only treat model",
            pred_labels = paste(effectlbls[,1], effectlbls[,3]))
```

#### condition labels
```{r}
table_model(get(model_name), 
            dv_labels = "only treat model",
            pred_labels = paste(effectlbls[,1], effectlbls[,4]))
```

### interpretation
```{r}
tm <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```
The goal is to examine whether IVET and VRET differ from each other in spider (vs neutral) ratings in the first session and between the first and second session (but not in any other picture category). 

The formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  
Emo by sess as random effects: This means that emo, session, and the emo by session can differ between subjects. 

Intercept = treatment(avr_treat) / session (1) / emotion (neutral).  
avr_treat is the mean of IVET and VRET.  

The effect for the intercept = **`r myround(tm$estimate[tm$term=="(Intercept)"], 2)`**. This is the mean rating for the intercept that contains the average across treatments in session 1 to neutral pictures.  

The effect of the interaction is added to this together with lower-order terms to get the marginal mean. An interaction parameter is how much it differs from the lower order terms and the t-test is for the null hypothesis that the difference between these parameters is 0. When testing higher effects, the lower effects are removed. That is, the higher effects test for something over and above the lower effects. Accordingly, the estimated marginal means are the intercept + lower effects + estimate for higher effect. 

We want to see whether the groups rated spiders differently from neutral pictures in session 1.  
`r pickme = "Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
Indeed, spiders are rated more emotional.  
(Note that the session 1 analysis with three groups tested each treatment compared to the control group.)  

Did the groups differ in how they rated spiders from neutral pictures in session 1? The next analysis suggests: No.  
`r pickme = "treat:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
(Note that the session 1 analysis with three groups tested each treatment compared to the control group.)  

Next, we examine whether the effect of spiders differed between sessions. 
`r pickme = "sess:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
Indeed, spiders (vs neutral) are rated less emotional in session 2 than session 1.  

Critically, did this effect vary with treatment?  
  `r pickme = "treat:sess:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
No, it does not look like that the treatment groups differed.  

All the other tests concern pictures other than spiders. 

### estimated means {.tabset}
```{r}
data %>%
  modelr::data_grid(treat, Emo, sess) %>%
  mutate(marginal_mean = predict(get(model_name), ., re.form = NA),
         treat = ifelse(treat == -.5, "IVET", "VRET"),
         sess = ifelse(sess == 0, 'pre', 'post'),
         sess = factor(sess, levels = c('pre', 'post'))) %>%
  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%
  kable(digits = 2) %>%
  kable_styling()
```

### Bayes {.tabset}
#### ordinal model
```{r}
ratings_valence_treat <- rate_only_treat_recode %>% 
  filter(rating_type == "Ple") %>% 
  filter(Emo %in% c('spider', 'neutral')) %>% 
  mutate(fp = as.factor(fp))
# Ordinal Regression Model.
ratings_valence.treat.model <- brm(rating ~ 1 + treat*sess*Emo + (1 + sess*Emo | fp), 
                             family = cumulative("probit"),
                             data = na.omit(ratings_valence_treat),
                             prior = c(prior(normal(0, 4), class = Intercept),
                                       prior(normal(0, 4), class = b)),
                             chains = 4,
                             file = "results/models/ratings_valence.treat.model", 
                             # file to save/reuse model
                             cores = 4, 
                             iter = 3000,
                             warmup = 1000,
                             init_r = 0.5,
                             save_pars = save_pars(all = TRUE))
# Model Summary.
summary(ratings_valence.treat.model)
```


### Bayes factor {.tabset}
only spider and neutral

#### computations
```{r}
null_valence.treat.model <- brm(rating ~ 1 + (1 + sess*Emo | fp),
                          family = cumulative("probit"),
                          data = ratings_valence_treat,
                          prior = prior(normal(0, 4), class = Intercept),
                          chains = 4,
                          file = "results/models/rating_valence.treat.null", 
                          # Specify file to save/reuse model
                          cores = 4, 
                          iter = 3000,
                          warmup = 1000,
                          init_r = 0.5,
                          save_pars = save_pars(all = TRUE))
sess_emo.treat_valence.model <- brm(rating ~ 1 + sess*Emo + (1 + sess*Emo | fp),
                              family = cumulative("probit"),
                              data = ratings_valence_treat,
                              prior = c(prior(normal(0, 4), class = Intercept),
                                        prior(normal(0, 4), class = b)),
                              chains = 4,
                              file = "results/models/rating_valence.treat.sess_emo", 
                              cores = 4, 
                              iter = 3000,
                              warmup = 1000,
                              save_pars = save_pars(all = TRUE))
emo.treat_valence.model <- brm(rating ~ 1 + Emo + (1 + sess*Emo | fp),
                         family = cumulative("probit"),
                         data = ratings_valence_treat,
                         prior = c(prior(normal(0, 4), class = Intercept),
                                   prior(normal(0, 4), class = b)),
                         chains = 4,
                         file = "results/models/rating_valence.treat.emo", 
                         cores = 4, 
                         iter = 3000,
                         warmup = 1000,
                         save_pars = save_pars(all = TRUE))
```

Compute bayes factor approximations (via bridge sampling)
```{r}
# Bayes factor comparisons are in favor of alternative hypothesis.
full.treat_valence.bayes <- bayes_factor(ratings_valence.treat.model, null_valence.treat.model)
sess_emo.treat_valence.bayes <- bayes_factor(sess_emo.treat_valence.model, null_valence.treat.model)
emo.treat_valence.bayes <- bayes_factor(emo.treat_valence.model, null_valence.treat.model)

full.treat_valence.bayes
sess_emo.treat_valence.bayes
emo.treat_valence.bayes
```

#### compare with null
```{r}
tibble(model = c("TreatxSessxEmo", "SessxEmo", "Emo"),
       Compared_To_Null = format(c(full.treat_valence.bayes$bf, 
                                   sess_emo.treat_valence.bayes$bf, 
                                   emo.treat_valence.bayes$bf), scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### compare with Sess x Emo
```{r}
tibble(model = c("TreatxSessxEmo", "SessxEmo", "Emo"),
       Compared_To_SessxEmo =     
         format(c(full.treat_valence.bayes$bf/sess_emo.treat_valence.bayes$bf,
                  sess_emo.treat_valence.bayes$bf/sess_emo.treat_valence.bayes$bf,
                  emo.treat_valence.bayes$bf/sess_emo.treat_valence.bayes$bf),
                                               scientific = TRUE),
         BF01 =   format(c(sess_emo.treat_valence.bayes$bf/full.treat_valence.bayes$bf,
                  sess_emo.treat_valence.bayes$bf/sess_emo.treat_valence.bayes$bf,
                  sess_emo.treat_valence.bayes$bf/emo.treat_valence.bayes$bf),
                                              scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### compare with Treat x Sess x Emo
```{r}
tibble(model = c("TreatxSessxEmo", "SessxEmo", "Emo"),
       Compared_To_TreatxSessxEmo =   
         format(c(full.treat_valence.bayes$bf/full.treat_valence.bayes$bf,
                  sess_emo.treat_valence.bayes$bf/full.treat_valence.bayes$bf, 
                  emo.treat_valence.bayes$bf/full.treat_valence.bayes$bf),
                                               scientific = TRUE),
       BF01 =   format(c(full.treat_valence.bayes$bf/full.treat_valence.bayes$bf,
                  full.treat_valence.bayes$bf/sess_emo.treat_valence.bayes$bf, 
                  full.treat_valence.bayes$bf/emo.treat_valence.bayes$bf),
                                               scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### check assumptions
An ordinal regression has four assumptions:  

1. The dependent variables are ordered.
2. One or more of the independent variables are either continuous, categorical, or ordinal.
3. No multi-collinearity.
4. Proportional odds.

Check vif and tolerance (multicollinearity)
```{r}
check_collinearity(ratings_valence.treat.model)
```

# EEG: EPN-relevant amplitude
EEG data during the detection task  

## session 1 three groups {.tabset}
* use session 1 from all three groups  
* examine whether IVET and VRET differ from controls to spiders (vs neutral) in session 1
* compare IVET and VRET separately to the control group
* do not test whether the treatments differ from each other
* use neutral pictures as reference emotion
* save the model to save time  
```{r}
model_name <- "session_pre_all_groups_EPN"
model_formula <- formula("EPN ~ 1 + treat*Emo + (1 + Emo | fp)")
data <- detect_baseline
if (file.exists(sprintf("results/models/model_%s.RDS", model_name))) {
  assign(get("model_name"), readRDS(sprintf("results/models/model_%s.RDS", model_name)))
} else {
  assign(get("model_name"), lmerTest::lmer(model_formula,
                                           control = lmerControl(optimizer = "nloptwrap",
                                                                 optCtrl = list(maxfun = 1e7),
                                                                 calc.derivs = FALSE), 
                                           data = data))
  saveRDS(eval(parse(text = model_name)), sprintf("results/models/model_%s.RDS", model_name))
}
# with nloptwrap: Model failed to converge with 1 negative eigenvalue: -1.5e+03
# Nelder_Mead: Model failed to converge with 1 negative eigenvalue: -2.3e+02
# results looked similar
```

### plot {.tabset}
```{r}
fits <- data %>%
  modelr::data_grid(treat, Emo, fp) %>%
  mutate(predicted_re = predict(get(model_name), .),
         fp_treat = sprintf("%s_%s", fp, treat)) %>%
  filter(fp_treat %in% sprintf("%s_%s", data$fp, data$treat))
ggeffects::ggpredict(get(model_name), c("treat", "Emo")) %>%
  data.frame() %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(data = fits, aes(x = Emo, y = predicted_re, color = treat,
                             group = interaction(fp, treat)), alpha = .3, size = .2) +
  geom_line(aes(group = x), position = position_dodge(width = .15), size = 1) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .15), size = .5) +
  scale_color_manual(values = palette, name = "treatment") +
  labs(y = "Predicted amp (V)\n", x = "\nemotion") +
  plot_aes
ggsave('results/figures/fig_meanamps_EPN_pre.png', plot = last_plot())
```


### summarize model
```{r}
summary(get(model_name))
tidied_model <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```

### model table {.tabset}
#### table of labels
```{r}
effectlbls <- data.frame(
  num = as.character(seq(1:12)), 
  original = tidied_model$term[1:12],
  standard = c("intercept (control, neutral)", 
               "treatment (IVET)", 
               "treatment (VRET)", 
               "emotion (spider)", 
               "emotion (negative)", 
               "emotion (positive)",
               "treatment (IVET) x emotion (spider)",
               "treatment (VRET) x emotion (spider)",
               "treatment (IVET) x emotion (negative)", 
               "treatment (VRET) x emotion (negative)",
               "treatment (IVET) x emotion (positive)", 
               "treatment (VRET) x emotion (positive)"),
  condition = c("treatment (control) / emotion (neutral)", 
                "treatment (IVET) / emotion (neutral)", 
                "treatment (VRET) / emotion (neutral)", 
                "treatment (control) / emotion (spider)", 
                "treatment (control) / emotion (negative)", 
                "treatment (control) / emotion (positive)",
                "treatment (IVET) / emotion (spider)", 
                "treatment (VRET) / emotion (spider)",
                "treatment (IVET) / emotion (negative)", 
                "treatment (VRET) / emotion (negative)",
                "treatment (IVET) / emotion (positive)", 
                "treatment (VRET) / emotion (positive)"),
  stringsAsFactors = F)
effectlbls %>%
  kable() %>%
  kable_styling()
```

#### standard labels
```{r}
table_model(get(model_name), 
            dv_labels = "session 1",
            pred_labels = paste(effectlbls[,1], effectlbls[,3]))
```

#### condition labels
```{r}
table_model(get(model_name), 
            dv_labels = "session 1",
            pred_labels = paste(effectlbls[,1], effectlbls[,4]))
```

### interpretation
```{r}
tm <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```
The goal is to examine whether IVET and VRET differ from controls in spider (vs neutral) mean amplitude in the first session (but not in any other picture category). The analysis compares IVET and VRET separately to the control group and does not test whether the treatments differ from each other.

The formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  
Emo as random effect.  

Intercept = treatment(control) / emotion(neutral).  

The effect for the intercept = **`r myround(tm$estimate[tm$term=="(Intercept)"], 2)`**. This is the mean amplitude for the intercept that contains treatment(control) and emotion(neutral) and is thus the marginal mean for the control group for neutral pictures.  

The first effect shows that there is an effect of spider (vs neutral). It shows that for the control group, spiders have lower amps than neutral pictures. This relative negativity supports an EPN. But, this effect is not of particular interest because it is only for the control group.  

`r pickme = "Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  

The main interest is to see whether IVET and VRET differ from controls in their amps to spiders. Particularly, the difference between spiders and neutral pictures should be more negative for each treatment group compared to controls. Because the intercept contains treatment(control) and emotion(neutral), we are interested in these tests:   
  
  **For IVET**:  
  `r pickme = "treatIVET:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
This is the interaction of treatment(IVET vs control) x emotion (spider vs neutral).  

**For VRET (same test as for IVET)**:  
  `r pickme = "treatVRET:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
This is the interaction of treatment(VRET vs control) x emotion (spider vs neutral).  

### estimated means
```{r}
data %>%
  modelr::data_grid(treat, Emo) %>%
  mutate(marginal_mean = predict(get(model_name), ., re.form = NA),) %>%
  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%
  kable(digits = 2) %>%
  kable_styling()
```

## session 1 across treatments {.tabset}
* use session 1 from all three groups
* combine treatment groups
* use neutral pictures as reference emotion
* save the model to save time
```{r}
model_name <- "session_pre_across_treat_EPN"
model_formula <- formula("EPN ~ 1 + treat*Emo + (1 + Emo | fp)")
data <- detect_baseline_acrosstreatment
if (file.exists(sprintf("results/models/model_%s.RDS", model_name))) {
  assign(get("model_name"), readRDS(sprintf("results/models/model_%s.RDS", model_name)))
} else {
  assign(get("model_name"), lmerTest::lmer(model_formula,
                                           control = lmerControl(optimizer = "nloptwrap",
                                                                 optCtrl = list(maxfun = 1e7),
                                                                 calc.derivs = FALSE), 
                                           data = data))
  saveRDS(eval(parse(text = model_name)), sprintf("results/models/model_%s.RDS", model_name))
}
```

### plot {.tabset}
```{r}
fits <- data %>%
  modelr::data_grid(treat, Emo, fp) %>%
  mutate(predicted_re = predict(get(model_name), .),
         fp_treat = sprintf("%s_%s", fp, treat)) %>%
  filter(fp_treat %in% sprintf("%s_%s", data$fp, data$treat))
ggeffects::ggpredict(get(model_name), c("treat", "Emo")) %>%
  data.frame() %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(data = fits, aes(x = Emo, y = predicted_re, color = treat,
                             group = interaction(fp, treat)), alpha = .3, size = .2) +
  geom_line(aes(group = x), position = position_dodge(width = .1), size = 1) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1), size = .5) +
  scale_color_manual(values = palette2, name = "treatment") +
  labs(y = "predicted mean amplitude (V)\n", x = "\nemotion") +
  plot_aes
```

### summarize model
```{r}
summary(get(model_name))
tidied_model <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```

### model table {.tabset}
#### table of labels
```{r}
effectlbls <- data.frame(
  num = as.character(seq(1:8)), 
  original = tidied_model$term[1:8],
  standard = c("intercept (control, neutral)", 
               "treatment (IVET/VRET)", 
               "emotion (spider)", 
               "emotion (negative)", 
               "emotion (positive)",
               "treatment (IVET/VRET) x emotion (spider)",
               "treatment (IVET/VRET) x emotion (negative)", 
               "treatment (IVET/VRET) x emotion (positive)"), 
  condition = c("treatment (control) / emotion (neutral)", 
                "treatment (IVET/VRET) / emotion (neutral)", 
                "treatment (control) / emotion (spider)", 
                "treatment (control) / emotion (negative)", 
                "treatment (control) / emotion (positive)",
                "treatment (IVET/VRET) / emotion (spider)", 
                "treatment (IVET/VRET) / emotion (negative)", 
                "treatment (IVET/VRET) / emotion (positive)"), 
  stringsAsFactors = F)
effectlbls %>%
  kable() %>%
  kable_styling()
```

#### standard labels
```{r}
table_model(get(model_name), 
            dv_labels = "session 1",
            pred_labels = paste(effectlbls[,1], effectlbls[,3]))
```

#### condition labels
```{r}
table_model(get(model_name), 
            dv_labels = "session 1",
            pred_labels = paste(effectlbls[,1], effectlbls[,4]))
```

### interpretation
```{r}
tm <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```
The goal is to examine whether the combined treatment groups (IVET and VRET) differ from controls in spider (vs neutral) mean amplitude in the first session (but not in any other picture category). The analysis compares the combined IVET and VRET to the control group and does not test whether the treatments differ from each other.

The formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  
Emo as random effect.  

Intercept = treatment(control) / emotion(neutral).  

The effect for the intercept = **`r myround(tm$estimate[tm$term=="(Intercept)"], 2)`**. This is the mean amplitude for the intercept that contains treatment(control) and emotion(neutral) and is thus the marginal mean for the control group for neutral pictures.  

The first effect shows that there is an effect of spider (vs neutral). It shows that for the control group, spiders have lower amps than neutral pictures. This relative negativity supports an EPN. But, this effect is not of particular interest because it is only for the control group.  

`r pickme = "Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  

The main interest is to see whether the combined treatment groups (IVET and VRET) differ from controls in their amps to spiders. Particularly, the difference between spiders and neutral pictures should be more negative across treatment groups compared to controls. Because the intercept contains treatment(control) and emotion(neutral), we are interested in this test:   
  
  `r pickme = "treatIVET/VRET:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
This is the interaction of treatment(IVET/VRET vs control) x emotion (spider vs neutral).  

### estimated means
```{r}
data %>%
  modelr::data_grid(treat, Emo) %>%
  mutate(marginal_mean = predict(get(model_name), ., re.form = NA),) %>%
  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%
  kable(digits = 2) %>%
  kable_styling()
```

### Bayes {.tabset}
only spider and neutral

#### gaussian model
```{r}
# Prepare dataframe.
detect_sess1 <- detect_baseline_acrosstreatment %>% 
  select(Emo, EPN, LPP, fp, sess, treat) %>% 
  filter(Emo %in% c('spider', 'neutral')) %>% 
  mutate(fp = as.factor(fp),
         Emo = factor(Emo, levels = c('neutral','spider'))) %>% 
  na.omit()
# Regression Model.
EPN.sess1.model <- brm(EPN ~ 1 + treat*Emo + (1 + Emo | fp), 
                       family = gaussian(),
                       data = detect_sess1,
                       prior = c(prior(normal(0, 4), class = Intercept),
                                 prior(normal(0, 4), class = b)),
                       chains = 4,
                       file = "results/models/EPN.sess1.model", # file to save/reuse model
                       cores = 4, 
                       iter = 3000,
                       warmup = 1000,
                       init_r = 0.5,
                       save_pars = save_pars(all = TRUE))
# Model Summary.
summary(EPN.sess1.model)
```

### Bayes factor {.tabset}
only spider and neutral

#### computations
```{r}
null.sess1.model <- brm(EPN ~ 1 + (1 + Emo | fp),
                        family = gaussian(),
                        data = detect_sess1,
                        prior = prior(normal(0, 4), class = Intercept),
                        chains = 4,
                        file = "results/models/EPN.sess1.null", 
                        # Specify file to save/reuse model
                        cores = 4, 
                        iter = 3000,
                        warmup = 1000,
                        init_r = 0.5,
                        save_pars = save_pars(all = TRUE))
emo.sess1.model <- brm(EPN ~ 1 + Emo + (1 + Emo | fp),
                       family =  gaussian(),
                       data = detect_sess1,
                       prior = c(prior(normal(0, 4), class = Intercept),
                                 prior(normal(0, 4), class = b)),
                       chains = 4,
                       file = "results/models/EPN.sess1.emo", 
                       # Specify file to save/reuse model
                       cores = 4, 
                       iter = 3000,
                       warmup = 1000,
                       init_r = 0.5,
                       save_pars = save_pars(all = TRUE))
treat.sess1.model <- brm(EPN ~ 1 + treat + (1 + Emo | fp),
                         family =  gaussian(),
                         data = detect_sess1,
                         prior = c(prior(normal(0, 4), class = Intercept),
                                   prior(normal(0, 4), class = b)),
                         chains = 4,
                         file = "results/models/EPN.sess1.treat", 
                         # Specify file to save/reuse model
                         cores = 4, 
                         iter = 3000,
                         warmup = 1000,
                         init_r = 0.5,
                         save_pars = save_pars(all = TRUE))
```

Compute bayes factor approximations (via bridge sampling)
```{r}
# Bayes factor comparisons are in favor of alternative hypothesis.
full.sess1.bayes <- bayes_factor(EPN.sess1.model, null.sess1.model)
treat.sess1.bayes <- bayes_factor(treat.sess1.model, null.sess1.model)
emo.sess1.bayes <- bayes_factor(emo.sess1.model, null.sess1.model)

full.sess1.bayes
treat.sess1.bayes
emo.sess1.bayes
```

#### compare with null
```{r}
tibble(model = c("TreatxEmo", "Treat", "Emo"),
       Compared_To_Null = format(c(full.sess1.bayes$bf, 
                                   treat.sess1.bayes$bf, 
                                   emo.sess1.bayes$bf), scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### compare with Emo
```{r}
tibble(model = c("TreatxEmo", "Treat", "Emo"),
       Compared_To_Emo = format(c(full.sess1.bayes$bf/emo.sess1.bayes$bf, 
                                  treat.sess1.bayes$bf/emo.sess1.bayes$bf,
                                  emo.sess1.bayes$bf/emo.sess1.bayes$bf), 
                                scientific = TRUE), 
           BF01 = format(c(emo.sess1.bayes$bf/full.sess1.bayes$bf, 
                           emo.sess1.bayes$bf/treat.sess1.bayes$bf,
                           emo.sess1.bayes$bf/emo.sess1.bayes$bf), 
                                scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### check assumptions {.tabset}
Linear regression has these assumptions:  

1. Linear association
2. Normality of residuals
3. No heteroskedasticity
4. No multicollinearity

##### linearity
```{r}
# Check linearity
na.omit(detect_sess1) %>%
  #add_residual_draws(EPN.sess1.model) %>%
  add_residual_draws(EPN.sess1.model, ndraws = 1) %>%
  ggplot(aes(x = .row, y = .residual)) +
  stat_pointinterval()
```

##### normality
```{r}
# Check normality
na.omit(detect_sess1) %>%
  add_residual_draws(EPN.sess1.model, ndraws = 1) %>%
  median_qi() %>%
  ggplot(aes(sample = .residual)) +
  geom_qq() +
  geom_qq_line()
```

##### multicollinearity
```{r}
# Check vif and tolerance
check_collinearity(EPN.sess1.model)
```

## treatment comparison {.tabset}
* session 1 and session 2 (session 1 as reference)
* include only treatment groups
* IVET = -.5, VRET = .5
* use neutral pictures as reference emotion
```{r}
model_name <- "only_treat_EPN"
model_formula <- formula("EPN ~ 1 + treat*sess*Emo + (1 + sess * Emo | fp)")
data <- detect_only_treat_recode
if (file.exists(sprintf("results/models/model_%s.RDS", model_name))) {
  assign(get("model_name"), readRDS(sprintf("results/models/model_%s.RDS", model_name)))
} else {
  assign(get("model_name"), lmerTest::lmer(model_formula,
                                           control = lmerControl(optimizer = "nloptwrap",
                                                                 optCtrl = list(maxfun = 1e7),
                                                                 calc.derivs = FALSE), 
                                           data = data))
  saveRDS(eval(parse(text = model_name)), sprintf("results/models/model_%s.RDS", model_name))
}
```

### plot {.tabset}
#### all categories
```{r}
fits <- data %>%
  modelr::data_grid(treat, sess, Emo, fp) %>%
  mutate(predicted_re = predict(get(model_name), .),
         fp_treat = sprintf("%s_%s", fp, treat)) %>%
  filter(fp_treat %in% sprintf("%s_%s", data$fp, data$treat)) %>%
  mutate(sess = ifelse(sess == 0, 'pre', 'post'),
         sess = factor(sess, levels = c('pre', 'post')),
         treat = ifelse(treat == -.5, "IVET", "VRET"))
ggeffects::ggpredict(get(model_name), c("treat", "sess", "Emo")) %>%
  data.frame() %>%
  mutate(group = ifelse(group == 0, 'pre', 'post'),
         group = factor(group, levels = c('pre', 'post')),
         x = ifelse(x == -.5, "IVET", "VRET"),
         Emo = facet) %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat,
                             group = interaction(fp, treat, Emo)), alpha = .3, size = .2) +
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  facet_grid(~Emo) +
  scale_color_manual(values = palette[2:3], name = "treatment") +
  labs(y = "predicted mean amplitude (V)\n", x = "\nsession") +
  plot_aes
```

#### spider and neutral
```{r}
fits <- data %>%
  modelr::data_grid(treat, sess, Emo, fp) %>%
  mutate(predicted_re = predict(get(model_name), .),
         fp_treat = sprintf("%s_%s", fp, treat)) %>%
  filter(fp_treat %in% sprintf("%s_%s", data$fp, data$treat)) %>%
  filter(Emo %in% c("neutral", "spider")) %>%
  mutate(sess = ifelse(sess == 0, 'pre', 'post'),
         sess = factor(sess, levels = c('pre', 'post')),
         treat = ifelse(treat == -.5, "IVET", "VRET"))
ggeffects::ggpredict(get(model_name), c("treat", "sess", "Emo")) %>%
  data.frame() %>%
  filter(facet %in% c("neutral", "spider")) %>%
  mutate(group = ifelse(group == 0, 'pre', 'post'),
         group = factor(group, levels = c('pre', 'post')),
         x = ifelse(x == -.5, "IVET", "VRET"),
         Emo = facet) %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat,
                             group = interaction(fp, treat, Emo)), alpha = .3, size = .2) +
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  facet_grid(~Emo) +
  scale_color_manual(values = palette[2:3], name = "treatment") +
  labs(y = "Predicted amp (V)\n", x = "\nsession") +
  plot_aes
ggsave('results/figures/fig_estimated_EPN_treat.png', plot = last_plot())
```

### summarize model
```{r}
summary(get(model_name))
tidied_model <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```

### model table {.tabset}
#### table of labels
```{r}
effectlbls <- data.frame(
  num = as.character(seq(1:16)), 
  original = tidied_model$term[1:16],
  standard = c("intercept (avr_treat, session (1), neutral)",
               "treatment (VRET vs IVET)",
               "session (2)",
               "emotion (spider)",
               "emotion (negative)",
               "emotion (positive)",
               "treatment (VRET vs IVET) x session",
               "treatment (VRET vs IVET) x emotion (spider)",
               "treatment (VRET vs IVET) x emotion (negative)",
               "treatment (VRET vs IVET) x emotion (positive)",
               "session x emotion (spider)",
               "session x emotion (negative)",
               "session x emotion (positive)",
               "treatment (VRET vs IVET) x session x emotion (spider)",
               "treatment (VRET vs IVET) x session x emotion (negative)",
               "treatment (VRET vs IVET) x session x emotion (positive)"),
  condition = c("treatment (avr_treat) / session (1) / emotion (neutral)",
                "treatment (VRET vs IVET) / sess (1) / emotion (neutral)",
                "treatment (avr_treat) / sess (2) / emotion (neutral)",
                "treatment (avr_treat) / sess (1) / emotion (spider)",
                "treatment (avr_treat) / sess (1) / emotion (negative)",
                "treatment (avr_treat) / sess (1) / emotion (positive)",
                "treatment (VRET vs IVET) / sess (2) / emotion (neutral)",
                "treatment (VRET vs IVET) / sess (1) / emotion (spider)",
                "treatment (VRET vs IVET) / sess (1) / emotion (negative)",
                "treatment (VRET vs IVET) / sess (1) / emotion (positive)",
                "treatment (avr_treat) / sess (2) / emotion (spider)",
                "treatment (avr_treat) / sess (2) / emotion (negative)",
                "treatment (avr_treat) / sess (2) / emotion (positive)",
                "treatment (VRET vs IVET) / sess (2) / emotion (spider)",
                "treatment (VRET vs IVET) / sess (2) / emotion (negative)",
                "treatment (VRET vs IVET) / sess (2) / emotion (positive)"),
  stringsAsFactors = F)
effectlbls %>%
  kable() %>%
  kable_styling()
```

#### standard labels
```{r}
table_model(get(model_name), 
            dv_labels = "only treat model",
            pred_labels = paste(effectlbls[,1], effectlbls[,3]))
```

#### condition labels
```{r}
table_model(get(model_name), 
            dv_labels = "only treat model",
            pred_labels = paste(effectlbls[,1], effectlbls[,4]))
```

### interpretation
```{r}
tm <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```
The goal is to examine whether IVET and VRET differ from each other in spider (vs neutral) mean amps in the first session and between the first and second session (but not in any other picture category). 

The formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  
Sess * Emo as random effects: This means that emo, session, and the 2-way interaction can differ between subjects. 

Intercept = treatment(avr_treat) / session (1) / emotion (neutral).  
avr_treat is the mean of IVET and VRET.  

The effect for the intercept = **`r myround(tm$estimate[tm$term=="(Intercept)"], 2)`**. This is the mean amp for the intercept that contains the average across treatments in session 1 to neutral pictures.  

The effect of the interaction is added to this together with lower-order terms to get the marginal mean. An interaction parameter is how much it differs from the lower order terms and the t-test is for the null hypothesis that the difference between these parameters is 0. When testing higher effects, the lower effects are removed. That is, the higher effects test for something over and above the lower effects. Accordingly, the estimated marginal means are the intercept + lower effects + estimate for higher effect. 

We want to see whether the groups showed lower amps to spiders than neutral pictures in session 1.  
`r pickme = "Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
Indeed, mean amps are relatively negative to spiders.  

Did the groups differ in how they responded to spiders versus neutral pictures in session 1? No.  
`r pickme = "treat:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  

Did the effect of spiders differ between sessions: No difference! 
  `r pickme = "sess:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  

Critically, did this effect vary with treatment? No difference!  
  `r pickme = "treat:sess:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  

### estimated means
```{r}
data %>%
  modelr::data_grid(treat, Emo, sess) %>%
  mutate(marginal_mean = predict(get(model_name), ., re.form = NA),
         treat = ifelse(treat == -.5, "IVET", "VRET"),
         sess = ifelse(sess == 0, 'pre', 'post'),
         sess = factor(sess, levels = c('pre', 'post'))) %>%
  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%
  kable(digits = 2) %>%
  kable_styling()
```

### Bayes {.tabset}
only spider and neutral

#### gaussian model
```{r}
detect_treat <- detect_only_treat_recode %>% 
  select(Emo, EPN, LPP, fp, sess, treat) %>% 
  filter(Emo %in% c('spider', 'neutral')) %>% 
  mutate(fp = as.factor(fp),
         Emo = factor(Emo, levels = c('neutral','spider'))) %>% 
  na.omit()
# Regression Model.
EPN.treat.model <- brm(EPN ~ 1 + treat*sess*Emo + (1 + sess*Emo | fp), 
                       family = gaussian(),
                       data = detect_treat,
                       prior = c(prior(normal(0, 4), class = Intercept),
                                 prior(normal(0, 4), class = b)),
                       chains = 4,
                       file = "results/models/EPN.treat.model", # file to save/reuse model
                       cores = 4, 
                       iter = 3000,
                       warmup = 1000,
                       init_r = 0.5,
                       save_pars = save_pars(all = TRUE))
# Model Summary.
summary(EPN.treat.model)
```

### Bayes factor {.tabset}
only spider and neutral

#### computations
```{r}
null.treat.model <- brm(EPN ~ 1 + (1 + sess*Emo | fp),
                        family = gaussian(),
                        data = detect_treat,
                        prior = prior(normal(0, 4), class = Intercept),
                        chains = 4,
                        file = "results/models/EPN.treat.null", 
                        # Specify file to save/reuse model
                        cores = 4, 
                        iter = 3000,
                        warmup = 1000,
                        init_r = 0.5,
                        save_pars = save_pars(all = TRUE))
sess_emo.treat.model <- brm(EPN ~ 1 + sess*Emo + (1 + sess*Emo | fp),
                            family = gaussian(),
                            data = detect_treat,
                            prior = c(prior(normal(0, 4), class = Intercept),
                                      prior(normal(0, 4), class = b)),
                            chains = 4,
                            file = "results/models/EPN.treat.sess_emo", 
                            cores = 4, 
                            iter = 3000,
                            warmup = 1000,
                            save_pars = save_pars(all = TRUE))
emo.treat.model <- brm(EPN ~ 1 + Emo + (1 + sess*Emo | fp),
                       family = gaussian(),
                       data = detect_treat,
                       prior = c(prior(normal(0, 4), class = Intercept),
                                 prior(normal(0, 4), class = b)),
                       chains = 4,
                       file = "results/models/EPN.treat.emo", 
                       cores = 4, 
                       iter = 3000,
                       warmup = 1000,
                       save_pars = save_pars(all = TRUE))
```

Compute bayes factor approximations (via bridge sampling)
```{r}
# Bayes factor comparisons are in favor of alternative hypothesis.
full.treat.bayes <- bayes_factor(EPN.treat.model, null.treat.model)
sess_emo.treat.bayes <- bayes_factor(sess_emo.treat.model, null.treat.model)
emo.treat.bayes <- bayes_factor(emo.treat.model, null.treat.model)

full.treat.bayes
sess_emo.treat.bayes
emo.treat.bayes
```

#### compare with null
```{r}
tibble(model = c("TreatxSessxEmo", "SessxEmo", "Emo"),
       Compared_To_Null = format(c(full.treat.bayes$bf, 
                                   sess_emo.treat.bayes$bf, 
                                   emo.treat.bayes$bf), scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### compare with Treat x Sess x Emo
```{r}
tibble(model = c("TreatxSessxEmo", "SessxEmo", "Emo"),
       Compared_To_Treat.Sess.Emo = 
         format(c(full.treat.bayes$bf/full.treat.bayes$bf, 
                  sess_emo.treat.bayes$bf/full.treat.bayes$bf, 
                  emo.treat.bayes$bf/full.treat.bayes$bf),
                                           scientific = TRUE),
       BF01 = 
         format(c(full.treat.bayes$bf/full.treat.bayes$bf, 
                  full.treat.bayes$bf/sess_emo.treat.bayes$bf, 
                  full.treat.bayes$bf/emo.treat.bayes$bf),
                                           scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### compare with Sess x Emo
```{r}
tibble(model = c("TreatxSessxEmo", "SessxEmo", "Emo"),
       Compared_To_Sess.Emo = format(c(full.treat.bayes$bf/sess_emo.treat.bayes$bf, 
                                       sess_emo.treat.bayes$bf/sess_emo.treat.bayes$bf,
                                       emo.treat.bayes$bf/sess_emo.treat.bayes$bf),
                                     scientific = TRUE),
       BF01 = format(c(sess_emo.treat.bayes$bf/full.treat.bayes$bf, 
                       sess_emo.treat.bayes$bf/sess_emo.treat.bayes$bf,
                       sess_emo.treat.bayes$bf/emo.treat.bayes$bf),
                                     scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### compare with Emo
```{r}
tibble(model = c("TreatxSessxEmo", "SessxEmo", "Emo"),
       Compared_To_Emo = format(c(full.treat.bayes$bf/emo.treat.bayes$bf, 
                                  sess_emo.treat.bayes$bf/emo.treat.bayes$bf, 
                                  emo.treat.bayes$bf/emo.treat.bayes$bf),
                                scientific = TRUE),
       BF01 = format(c(emo.treat.bayes$bf/full.treat.bayes$bf, 
                       emo.treat.bayes$bf/sess_emo.treat.bayes$bf, 
                       emo.treat.bayes$bf/emo.treat.bayes$bf),
                                scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### check assumptions {.tabset}
Linear regression has these assumptions:  

1. Linear association
2. Normality of residuals
3. No heteroskedasticity
4. No multicollinearity

##### linearity
```{r}
# Check linearity
na.omit(detect_treat) %>%
  add_residual_draws(EPN.treat.model, ndraws = 1) %>%  
  ggplot(aes(x = .row, y = .residual)) +
  stat_pointinterval()
```

##### normality
```{r}
# Check normality
na.omit(detect_treat) %>%
  add_residual_draws(EPN.treat.model, ndraws = 1) %>%
  median_qi() %>%
  ggplot(aes(sample = .residual)) +
  geom_qq() +
  geom_qq_line()
```

##### multicollinearity
```{r}
# Check vif and tolerance
check_collinearity(EPN.treat.model)
```

# EEG: LPP-relevant amplitude
EEG data during the detection task  

## session 1 three groups {.tabset}
* use session 1 from all three groups  
* examine whether IVET and VRET differ from controls to spiders (vs neutral) in session 1
* compare IVET and VRET separately to the control group
* do not test whether the treatments differ from each other
* use neutral pictures as reference emotion
* save the model to save time  
```{r}
model_name <- "session_pre_all_groups_LPP"
model_formula <- formula("LPP ~ 1 + treat*Emo + (1 + Emo | fp)")
data <- detect_baseline
if (file.exists(sprintf("results/models/model_%s.RDS", model_name))) {
  assign(get("model_name"), readRDS(sprintf("results/models/model_%s.RDS", model_name)))
} else {
  assign(get("model_name"), lmerTest::lmer(model_formula,
                                           control = lmerControl(optimizer = "Nelder_Mead",
                                                                 optCtrl = list(maxfun = 1e7),
                                                                 calc.derivs = FALSE), 
                                           data = data))
  saveRDS(eval(parse(text = model_name)), sprintf("results/models/model_%s.RDS", model_name))
}
# nloptwrap: Model failed to converge with 1 negative eigenvalue: -8.0e+02
```

### plot {.tabset}
```{r}
fits <- data %>%
  modelr::data_grid(treat, Emo, fp) %>%
  mutate(predicted_re = predict(get(model_name), .),
         fp_treat = sprintf("%s_%s", fp, treat)) %>%
  filter(fp_treat %in% sprintf("%s_%s", data$fp, data$treat))
ggeffects::ggpredict(get(model_name), c("treat", "Emo")) %>%
  data.frame() %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(data = fits, aes(x = Emo, y = predicted_re, color = treat,
                             group = interaction(fp, treat)), alpha = .3, size = .2) +
  geom_line(aes(group = x), position = position_dodge(width = .15), size = 1) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .15), size = .5) +
  scale_color_manual(values = palette, name = "treatment") +
  labs(y = "Predicted amp (V)\n", x = "\nemotion") +
  plot_aes
ggsave('results/figures/fig_meanamps_LPP_pre.png', plot = last_plot())
```

### summarize model
```{r}
summary(get(model_name))
tidied_model <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```

### model table {.tabset}
#### table of labels
```{r}
effectlbls <- data.frame(
  num = as.character(seq(1:12)), 
  original = tidied_model$term[1:12],
  standard = c("intercept (control, neutral)", 
               "treatment (IVET)", 
               "treatment (VRET)", 
               "emotion (spider)", 
               "emotion (negative)", 
               "emotion (positive)",
               "treatment (IVET) x emotion (spider)",
               "treatment (VRET) x emotion (spider)",
               "treatment (IVET) x emotion (negative)", 
               "treatment (VRET) x emotion (negative)",
               "treatment (IVET) x emotion (positive)", 
               "treatment (VRET) x emotion (positive)"),
  condition = c("treatment (control) / emotion (neutral)", 
                "treatment (IVET) / emotion (neutral)", 
                "treatment (VRET) / emotion (neutral)", 
                "treatment (control) / emotion (spider)", 
                "treatment (control) / emotion (negative)", 
                "treatment (control) / emotion (positive)",
                "treatment (IVET) / emotion (spider)", 
                "treatment (VRET) / emotion (spider)",
                "treatment (IVET) / emotion (negative)", 
                "treatment (VRET) / emotion (negative)",
                "treatment (IVET) / emotion (positive)", 
                "treatment (VRET) / emotion (positive)"),
  stringsAsFactors = F)
effectlbls %>%
  kable() %>%
  kable_styling()
```

#### standard labels
```{r}
table_model(get(model_name), 
            dv_labels = "session 1",
            pred_labels = paste(effectlbls[,1], effectlbls[,3]))
```

#### condition labels
```{r}
table_model(get(model_name), 
            dv_labels = "session 1",
            pred_labels = paste(effectlbls[,1], effectlbls[,4]))
```

### interpretation
```{r}
tm <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```
The goal is to examine whether IVET and VRET differ from controls in spider (vs neutral) mean amplitude in the first session (but not in any other picture category). The analysis compares IVET and VRET separately to the control group and does not test whether the treatments differ from each other.

The formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  
Emo as random effect.  

Intercept = treatment(control) / emotion(neutral).  

The effect for the intercept = **`r myround(tm$estimate[tm$term=="(Intercept)"], 2)`**. This is the mean amplitude for the intercept that contains treatment(control) and emotion(neutral) and is thus the marginal mean for the control group for neutral pictures.  

The first effect shows that there is an effect of spider (vs neutral). It shows that for the control group, spiders have higher amps than neutral pictures. This relative positivity supports an LPP. But, this effect is not of particular interest because it is only for the control group.  

`r pickme = "Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  

The main interest is to see whether IVET and VRET differ from controls in their amps to spiders. Particularly, the difference between spiders and neutral pictures should be more positive for each treatment group compared to controls. Because the intercept contains treatment(control) and emotion(neutral), we are interested in these tests:   
  
  **For IVET**:  
  `r pickme = "treatIVET:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
This is the interaction of treatment(IVET vs control) x emotion (spider vs neutral).  

**For VRET (same test as for IVET)**:  
  `r pickme = "treatVRET:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
This is the interaction of treatment(VRET vs control) x emotion (spider vs neutral).  

### estimated means
```{r}
data %>%
  modelr::data_grid(treat, Emo) %>%
  mutate(marginal_mean = predict(get(model_name), ., re.form = NA),) %>%
  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%
  kable(digits = 2) %>%
  kable_styling()
```

## session 1 across treatments {.tabset}
* use session 1 from all three groups
* combine treatment groups
* use neutral pictures as reference emotion
* save the model to save time
```{r}
model_name <- "session_pre_across_treat_LPP"
model_formula <- formula("LPP ~ 1 + treat*Emo + (1 + Emo | fp)")
data <- detect_baseline_acrosstreatment
if (file.exists(sprintf("results/models/model_%s.RDS", model_name))) {
  assign(get("model_name"), readRDS(sprintf("results/models/model_%s.RDS", model_name)))
} else {
  assign(get("model_name"), lmerTest::lmer(model_formula,
                                           control = lmerControl(optimizer = "nloptwrap",
                                                                 optCtrl = list(maxfun = 1e7),
                                                                 calc.derivs = FALSE), 
                                           data = data))
  saveRDS(eval(parse(text = model_name)), sprintf("results/models/model_%s.RDS", model_name))
}
```

### plot {.tabset}
```{r}
fits <- data %>%
  modelr::data_grid(treat, Emo, fp) %>%
  mutate(predicted_re = predict(get(model_name), .),
         fp_treat = sprintf("%s_%s", fp, treat)) %>%
  filter(fp_treat %in% sprintf("%s_%s", data$fp, data$treat))
ggeffects::ggpredict(get(model_name), c("treat", "Emo")) %>%
  data.frame() %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(data = fits, aes(x = Emo, y = predicted_re, color = treat,
                             group = interaction(fp, treat)), alpha = .3, size = .2) +
  geom_line(aes(group = x), position = position_dodge(width = .1), size = 1) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1), size = .5) +
  scale_color_manual(values = palette2, name = "treatment") +
  labs(y = "predicted mean amplitude (V)\n", x = "\nemotion") +
  plot_aes
```

### summarize model
```{r}
summary(get(model_name))
tidied_model <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```

### model table {.tabset}
#### table of labels
```{r}
effectlbls <- data.frame(
  num = as.character(seq(1:8)), 
  original = tidied_model$term[1:8],
  standard = c("intercept (control, neutral)", 
               "treatment (IVET/VRET)", 
               "emotion (spider)", 
               "emotion (negative)", 
               "emotion (positive)",
               "treatment (IVET/VRET) x emotion (spider)",
               "treatment (IVET/VRET) x emotion (negative)", 
               "treatment (IVET/VRET) x emotion (positive)"), 
  condition = c("treatment (control) / emotion (neutral)", 
                "treatment (IVET/VRET) / emotion (neutral)", 
                "treatment (control) / emotion (spider)", 
                "treatment (control) / emotion (negative)", 
                "treatment (control) / emotion (positive)",
                "treatment (IVET/VRET) / emotion (spider)", 
                "treatment (IVET/VRET) / emotion (negative)", 
                "treatment (IVET/VRET) / emotion (positive)"), 
  stringsAsFactors = F)
effectlbls %>%
  kable() %>%
  kable_styling()
```

#### standard labels
```{r}
table_model(get(model_name), 
            dv_labels = "session 1",
            pred_labels = paste(effectlbls[,1], effectlbls[,3]))
```

#### condition labels
```{r}
table_model(get(model_name), 
            dv_labels = "session 1",
            pred_labels = paste(effectlbls[,1], effectlbls[,4]))
```

### interpretation
```{r}
tm <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```
The goal is to examine whether the combined treatment groups (IVET and VRET) differ from controls in spider (vs neutral) mean amplitude in the first session (but not in any other picture category). The analysis compares the combined IVET and VRET to the control group and does not test whether the treatments differ from each other.

The formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  
Emo as random effect.  

Intercept = treatment(control) / emotion(neutral).  

The effect for the intercept = **`r myround(tm$estimate[tm$term=="(Intercept)"], 2)`**. This is the mean amplitude for the intercept that contains treatment(control) and emotion(neutral) and is thus the marginal mean for the control group for neutral pictures.  

The first effect shows that there is an effect of spider (vs neutral). It shows that for the control group, spiders have higher amps than neutral pictures. This relative positivity supports an LPP. But, this effect is not of particular interest because it is only for the control group.  

`r pickme = "Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  

The main interest is to see whether the combined treatment groups (IVET and VRET) differ from controls in their amps to spiders. Particularly, the difference between spiders and neutral pictures should be more positive across treatment groups compared to controls. Because the intercept contains treatment(control) and emotion(neutral), we are interested in this test:   
  
  `r pickme = "treatIVET/VRET:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
This is the interaction of treatment(IVET/VRET vs control) x emotion (spider vs neutral) across ratings.  

### estimated means
```{r}
data %>%
  modelr::data_grid(treat, Emo) %>%
  mutate(marginal_mean = predict(get(model_name), ., re.form = NA),) %>%
  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%
  kable(digits = 2) %>%
  kable_styling()
```

### Bayes {.tabset}
only spider and neutral

#### gaussian model
```{r}
# Prepare dataframe.
detect_sess1 <- detect_baseline_acrosstreatment %>% 
  select(Emo, EPN, LPP, fp, sess, treat) %>% 
  filter(Emo %in% c('spider', 'neutral')) %>% 
  mutate(fp = as.factor(fp),
         Emo = factor(Emo, levels = c('neutral','spider'))) %>% 
  na.omit()
# Regression Model.
LPP.sess1.model <- brm(LPP ~ 1 + treat*Emo + (1 + Emo | fp), 
                       family = gaussian(),
                       data = detect_sess1,
                       prior = c(prior(normal(0, 4), class = Intercept),
                                 prior(normal(0, 4), class = b)),
                       chains = 4,
                       file = "results/models/LPP.sess1.model", 
                       # file to save/reuse model
                       cores = 4, 
                       iter = 3000,
                       warmup = 1000,
                       init_r = 0.5,
                       save_pars = save_pars(all = TRUE))
# Model Summary.
summary(LPP.sess1.model)
```

### Bayes factor {.tabset}
only spider and neutral

#### computations
```{r}
null.sess1.model <- brm(LPP ~ 1 + (1 + Emo | fp),
                        family = gaussian(),
                        data = detect_sess1,
                        prior = prior(normal(0, 4), class = Intercept),
                        chains = 4,
                        file = "results/models/LPP.sess1.null", 
                        # Specify file to save/reuse model
                        cores = 4, 
                        iter = 3000,
                        warmup = 1000,
                        init_r = 0.5,
                        save_pars = save_pars(all = TRUE))
emo.sess1.model <- brm(LPP ~ 1 + Emo + (1 + Emo | fp),
                       family =  gaussian(),
                       data = detect_sess1,
                       prior = c(prior(normal(0, 4), class = Intercept),
                                 prior(normal(0, 4), class = b)),
                       chains = 4,
                       file = "results/models/LPP.sess1.emo", 
                       # Specify file to save/reuse model
                       cores = 4, 
                       iter = 3000,
                       warmup = 1000,
                       init_r = 0.5,
                       save_pars = save_pars(all = TRUE))
treat.sess1.model <- brm(LPP ~ 1 + treat + (1 + Emo | fp),
                         family =  gaussian(),
                         data = detect_sess1,
                         prior = c(prior(normal(0, 4), class = Intercept),
                                   prior(normal(0, 4), class = b)),
                         chains = 4,
                         file = "results/models/LPP.sess1.treat", 
                         # Specify file to save/reuse model
                         cores = 4, 
                         iter = 3000,
                         warmup = 1000,
                         init_r = 0.5,
                         save_pars = save_pars(all = TRUE))
```

Compute bayes factor approximations (via bridge sampling)
```{r}
# Bayes factor comparisons are in favor of alternative hypothesis.
full.sess1.bayes <- bayes_factor(LPP.sess1.model, null.sess1.model)
treat.sess1.bayes <- bayes_factor(treat.sess1.model, null.sess1.model)
emo.sess1.bayes <- bayes_factor(emo.sess1.model, null.sess1.model)

full.sess1.bayes
treat.sess1.bayes
emo.sess1.bayes
```

#### compare with null
```{r}
tibble(model = c("TreatxEmo", "Treat", "Emo"),
       Compared_To_Null = format(c(full.sess1.bayes$bf, 
                                   treat.sess1.bayes$bf, 
                                   emo.sess1.bayes$bf), scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### compare with Emo
```{r}
tibble(model = c("TreatxEmo", "Treat", "Emo"),
       Compared_To_Emo = format(c(full.sess1.bayes$bf/emo.sess1.bayes$bf, 
                                  treat.sess1.bayes$bf/emo.sess1.bayes$bf,
                                  emo.sess1.bayes$bf/emo.sess1.bayes$bf), 
                                scientific = TRUE), 
           BF01 = format(c(emo.sess1.bayes$bf/full.sess1.bayes$bf, 
                           emo.sess1.bayes$bf/treat.sess1.bayes$bf,
                           emo.sess1.bayes$bf/emo.sess1.bayes$bf), 
                                scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### check assumptions {.tabset}
Linear regression has these assumptions:  

1. Linear association
2. Normality of residuals
3. No heteroskedasticity
4. No multicollinearity

##### linearity
```{r}
# Check linearity
na.omit(detect_sess1) %>%
  add_residual_draws(LPP.sess1.model, ndraws = 1) %>%
  ggplot(aes(x = .row, y = .residual)) +
  stat_pointinterval()
```

##### normality
```{r}
# Check normality
na.omit(detect_sess1) %>%
  add_residual_draws(LPP.sess1.model, ndraws = 1) %>%
  median_qi() %>%
  ggplot(aes(sample = .residual)) +
  geom_qq() +
  geom_qq_line()
```

##### multicollinearity
```{r}
# Check vif and tolerance
check_collinearity(LPP.sess1.model)
```

## treatment comparison {.tabset}
* session 1 and session 2 (session 1 as reference)
* include only treatment groups
* IVET = -.5, VRET = .5
* use neutral pictures as reference emotion
```{r}
model_name <- "only_treat_LPP"
model_formula <- formula("LPP ~ 1 + treat*sess*Emo + (1 + sess * Emo | fp)")
data <- detect_only_treat_recode
if (file.exists(sprintf("results/models/model_%s.RDS", model_name))) {
  assign(get("model_name"), readRDS(sprintf("results/models/model_%s.RDS", model_name)))
} else {
  assign(get("model_name"), lmerTest::lmer(model_formula,
                                           control = lmerControl(optimizer = "Nelder_Mead",
                                                                 optCtrl = list(maxfun = 1e7),
                                                                 calc.derivs = FALSE), 
                                           data = data))
  saveRDS(eval(parse(text = model_name)), sprintf("results/models/model_%s.RDS", model_name))
}
# nloptwrap: Model failed to converge with 4 negative eigenvalues: -1.3e-02 -7.1e-02 -1.7e-01 -7.8e+01
# Nelder_Mead: Model failed to converge with 2 negative eigenvalues: -3.5e+01 -4.4e+01
```

### plot {.tabset}
#### all categories
```{r}
fits <- data %>%
  modelr::data_grid(treat, sess, Emo, fp) %>%
  mutate(predicted_re = predict(get(model_name), .),
         fp_treat = sprintf("%s_%s", fp, treat)) %>%
  filter(fp_treat %in% sprintf("%s_%s", data$fp, data$treat)) %>%
  mutate(sess = ifelse(sess == 0, 'pre', 'post'),
         sess = factor(sess, levels = c('pre', 'post')),
         treat = ifelse(treat == -.5, "IVET", "VRET"))
ggeffects::ggpredict(get(model_name), c("treat", "sess", "Emo")) %>%
  data.frame() %>%
  mutate(group = ifelse(group == 0, 'pre', 'post'),
         group = factor(group, levels = c('pre', 'post')),
         x = ifelse(x == -.5, "IVET", "VRET"),
         Emo = facet) %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat,
                             group = interaction(fp, treat, Emo)), alpha = .3, size = .2) +
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  facet_grid(~Emo) +
  scale_color_manual(values = palette[2:3], name = "treatment") +
  labs(y = "predicted mean amplitude (V)\n", x = "\nsession") +
  plot_aes
```

#### spider and neutral
```{r}
fits <- data %>%
  modelr::data_grid(treat, sess, Emo, fp) %>%
  mutate(predicted_re = predict(get(model_name), .),
         fp_treat = sprintf("%s_%s", fp, treat)) %>%
  filter(fp_treat %in% sprintf("%s_%s", data$fp, data$treat)) %>%
  filter(Emo %in% c("neutral", "spider")) %>%
  mutate(sess = ifelse(sess == 0, 'pre', 'post'),
         sess = factor(sess, levels = c('pre', 'post')),
         treat = ifelse(treat == -.5, "IVET", "VRET"))
ggeffects::ggpredict(get(model_name), c("treat", "sess", "Emo")) %>%
  data.frame() %>%
  filter(facet %in% c("neutral", "spider")) %>%
  mutate(group = ifelse(group == 0, 'pre', 'post'),
         group = factor(group, levels = c('pre', 'post')),
         x = ifelse(x == -.5, "IVET", "VRET"),
         Emo = facet) %>%
  ggplot(aes(group, predicted, color = x)) +
  geom_line(data = fits, aes(x = sess, y = predicted_re, color = treat,
                             group = interaction(fp, treat, Emo)), alpha = .3, size = .2) +
  geom_line(aes(group = x), position = position_dodge(width = .1)) +
  geom_pointrange(aes(ymin = conf.low, ymax = conf.high), position = position_dodge(width = .1)) +
  facet_grid(~Emo) +
  scale_color_manual(values = palette[2:3], name = "treatment") +
  labs(y = "Predicted amp (V)\n", x = "\nsession") +
  plot_aes
ggsave('results/figures/fig_estimated_LPP_treat.png', plot = last_plot())
```

### summarize model
```{r}
summary(get(model_name))
tidied_model <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```

### model table {.tabset}
#### table of labels
```{r}
effectlbls <- data.frame(
  num = as.character(seq(1:16)), 
  original = tidied_model$term[1:16],
  standard = c("intercept (avr_treat, session (1), neutral)",
               "treatment (VRET vs IVET)",
               "session (2)",
               "emotion (spider)",
               "emotion (negative)",
               "emotion (positive)",
               "treatment (VRET vs IVET) x session",
               "treatment (VRET vs IVET) x emotion (spider)",
               "treatment (VRET vs IVET) x emotion (negative)",
               "treatment (VRET vs IVET) x emotion (positive)",
               "session x emotion (spider)",
               "session x emotion (negative)",
               "session x emotion (positive)",
               "treatment (VRET vs IVET) x session x emotion (spider)",
               "treatment (VRET vs IVET) x session x emotion (negative)",
               "treatment (VRET vs IVET) x session x emotion (positive)"),
  condition = c("treatment (avr_treat) / session (1) / emotion (neutral)",
                "treatment (VRET vs IVET) / sess (1) / emotion (neutral)",
                "treatment (avr_treat) / sess (2) / emotion (neutral)",
                "treatment (avr_treat) / sess (1) / emotion (spider)",
                "treatment (avr_treat) / sess (1) / emotion (negative)",
                "treatment (avr_treat) / sess (1) / emotion (positive)",
                "treatment (VRET vs IVET) / sess (2) / emotion (neutral)",
                "treatment (VRET vs IVET) / sess (1) / emotion (spider)",
                "treatment (VRET vs IVET) / sess (1) / emotion (negative)",
                "treatment (VRET vs IVET) / sess (1) / emotion (positive)",
                "treatment (avr_treat) / sess (2) / emotion (spider)",
                "treatment (avr_treat) / sess (2) / emotion (negative)",
                "treatment (avr_treat) / sess (2) / emotion (positive)",
                "treatment (VRET vs IVET) / sess (2) / emotion (spider)",
                "treatment (VRET vs IVET) / sess (2) / emotion (negative)",
                "treatment (VRET vs IVET) / sess (2) / emotion (positive)"),
  stringsAsFactors = F)
effectlbls %>%
  kable() %>%
  kable_styling()
```

#### standard labels
```{r}
table_model(get(model_name), 
            dv_labels = "only treat model",
            pred_labels = paste(effectlbls[,1], effectlbls[,3]))
```

#### condition labels
```{r}
table_model(get(model_name), 
            dv_labels = "only treat model",
            pred_labels = paste(effectlbls[,1], effectlbls[,4]))
```

### interpretation
```{r}
tm <- get(model_name) %>%
  broom.mixed::tidy(conf.int = TRUE)
```
The goal is to examine whether IVET and VRET differ from each other in spider (vs neutral) mean amps in the first session and between the first and second session (but not in any other picture category). 

The formula was **`r paste(deparse(model_formula, width.cutoff = 100))`**.  
Sess * Emo as random effects: This means that emo, session, and the 2-way interaction can differ between subjects. 

Intercept = treatment(avr_treat) / session (1) / emotion (neutral).  
avr_treat is the mean of IVET and VRET.  

The effect for the intercept = **`r myround(tm$estimate[tm$term=="(Intercept)"], 2)`**. This is the mean amp for the intercept that contains the average across treatments in session 1 to neutral pictures.  

The effect of the interaction is added to this together with lower-order terms to get the marginal mean. An interaction parameter is how much it differs from the lower order terms and the *t* test is for the null hypothesis that the difference between these parameters is 0. When testing higher effects, the lower effects are removed. That is, the higher effects test for something over and above the lower effects. Accordingly, the estimated marginal means are the intercept + lower effects + estimate for higher effect. 

We want to see whether the groups showed higher amps to spiders than neutral pictures in session 1.  
`r pickme = "Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  
Indeed, mean amps are relatively positive to spiders.  

Did the groups differ in how they responded to spiders versus neutral pictures in session 1? No.  
`r pickme = "treat:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  

Did the effect of spiders differ between sessions: No difference! 
  `r pickme = "sess:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  

Critically, did this effect vary with treatment? No difference!  
  `r pickme = "treat:sess:Emospider"`
**`r (pickme)`**  
  In the model table with condition labels, this is number 
**`r effectlbls$num[effectlbls$original==pickme]`**.  

`r effectlbls$condition[effectlbls$original==pickme]`.  
- estimate: `r myround(tm$estimate[tm$term==pickme], 2)`  
- p value: `r formatC(tm$p.value[tm$term==pickme], format="e")`  

### estimated means
```{r}
data %>%
  modelr::data_grid(treat, Emo, sess) %>%
  mutate(marginal_mean = predict(get(model_name), ., re.form = NA),
         treat = ifelse(treat == -.5, "IVET", "VRET"),
         sess = ifelse(sess == 0, "1", "2")) %>%
  pivot_wider(names_from = Emo, values_from = marginal_mean) %>%
  kable(digits = 2) %>%
  kable_styling()
```

### Bayes {.tabset}
only spider and neutral

#### gaussian model
```{r}
detect_treat <- detect_only_treat_recode %>% 
  select(Emo, EPN, LPP, fp, sess, treat) %>% 
  filter(Emo %in% c('spider', 'neutral')) %>% 
  mutate(fp = as.factor(fp),
         Emo = factor(Emo, levels = c('neutral','spider'))) %>% 
  na.omit()
# Regression Model.
LPP.treat.model <- brm(LPP ~ 1 + treat*sess*Emo + (1 + sess*Emo | fp), 
                       family = gaussian(),
                       data = detect_treat,
                       prior = c(prior(normal(0, 4), class = Intercept),
                                 prior(normal(0, 4), class = b)),
                       chains = 4,
                       file = "results/models/LPP.treat.model", 
                       # file to save/reuse model
                       cores = 4, 
                       iter = 3000,
                       warmup = 1000,
                       init_r = 0.5,
                       save_pars = save_pars(all = TRUE))
# Model Summary.
summary(LPP.treat.model)
```

### Bayes factor {.tabset}
only spider and neutral

#### computations
```{r}
null.treat.model <- brm(LPP ~ 1 + (1 + sess*Emo | fp),
                        family = gaussian(),
                        data = detect_treat,
                        prior = prior(normal(0, 4), class = Intercept),
                        chains = 4,
                        file = "results/models/LPP.treat.null", 
                        # Specify file to save/reuse model
                        cores = 4, 
                        iter = 3000,
                        warmup = 1000,
                        init_r = 0.5,
                        save_pars = save_pars(all = TRUE))
sess_emo.treat.model <- brm(LPP ~ 1 + sess*Emo + (1 + sess*Emo | fp),
                            family = gaussian(),
                            data = detect_treat,
                            prior = c(prior(normal(0, 4), class = Intercept),
                                      prior(normal(0, 4), class = b)),
                            chains = 4,
                            file = "results/models/LPP.treat.sess_emo", 
                            cores = 4, 
                            iter = 3000,
                            warmup = 1000,
                            save_pars = save_pars(all = TRUE))
emo.treat.model <- brm(LPP ~ 1 + Emo + (1 + sess*Emo | fp),
                       family = gaussian(),
                       data = detect_treat,
                       prior = c(prior(normal(0, 4), class = Intercept),
                                 prior(normal(0, 4), class = b)),
                       chains = 4,
                       file = "results/models/LPP.treat.emo", 
                       cores = 4, 
                       iter = 3000,
                       warmup = 1000,
                       save_pars = save_pars(all = TRUE))
```

Compute bayes factor approximations (via bridge sampling)
```{r}
# Bayes factor comparisons are in favor of alternative hypothesis.
full.treat.bayes <- bayes_factor(LPP.treat.model, null.treat.model)
sess_emo.treat.bayes <- bayes_factor(sess_emo.treat.model, null.treat.model)
emo.treat.bayes <- bayes_factor(emo.treat.model, null.treat.model)

full.treat.bayes
sess_emo.treat.bayes
emo.treat.bayes
```

#### compare with null
```{r}
tibble(model = c("TreatxSessxEmo", "SessxEmo", "Emo"),
       Compared_To_Null = format(c(full.treat.bayes$bf, 
                                   sess_emo.treat.bayes$bf, 
                                   emo.treat.bayes$bf), scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### compare with Treat x Sess x Emo
```{r}
tibble(model = c("TreatxSessxEmo", "SessxEmo", "Emo"),
       Compared_To_Treat.Sess.Emo = 
         format(c(full.treat.bayes$bf/full.treat.bayes$bf, 
                  sess_emo.treat.bayes$bf/full.treat.bayes$bf, 
                  emo.treat.bayes$bf/full.treat.bayes$bf),
                                           scientific = TRUE),
       BF01 = 
         format(c(full.treat.bayes$bf/full.treat.bayes$bf, 
                  full.treat.bayes$bf/sess_emo.treat.bayes$bf, 
                  full.treat.bayes$bf/emo.treat.bayes$bf),
                                           scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### compare with Sess x Emo
```{r}
tibble(model = c("TreatxSessxEmo", "SessxEmo", "Emo"),
       Compared_To_Sess.Emo = format(c(full.treat.bayes$bf/sess_emo.treat.bayes$bf, 
                                       sess_emo.treat.bayes$bf/sess_emo.treat.bayes$bf,
                                       emo.treat.bayes$bf/sess_emo.treat.bayes$bf),
                                     scientific = TRUE),
       BF01 = format(c(sess_emo.treat.bayes$bf/full.treat.bayes$bf, 
                       sess_emo.treat.bayes$bf/sess_emo.treat.bayes$bf,
                       sess_emo.treat.bayes$bf/emo.treat.bayes$bf),
                                     scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### compare with Emo
```{r}
tibble(model = c("TreatxSessxEmo", "SessxEmo", "Emo"),
       Compared_To_Emo = format(c(full.treat.bayes$bf/emo.treat.bayes$bf, 
                                  sess_emo.treat.bayes$bf/emo.treat.bayes$bf, 
                                  emo.treat.bayes$bf/emo.treat.bayes$bf),
                                scientific = TRUE),
       BF01 = format(c(emo.treat.bayes$bf/full.treat.bayes$bf, 
                       emo.treat.bayes$bf/sess_emo.treat.bayes$bf, 
                       emo.treat.bayes$bf/emo.treat.bayes$bf),
                                scientific = TRUE)) %>% 
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                full_width = F, position = 'left')
```

#### check assumptions {.tabset}
Linear regression has these assumptions:  

1. Linear association
2. Normality of residuals
3. No heteroskedasticity
4. No multicollinearity

##### linearity
```{r}
# Check linearity
na.omit(detect_treat) %>%
  add_residual_draws(LPP.treat.model, ndraws = 1) %>%
  ggplot(aes(x = .row, y = .residual)) +
  stat_pointinterval()
```

##### normality
```{r}
# Check normality
na.omit(detect_treat) %>%
  add_residual_draws(LPP.treat.model, ndraws = 1) %>%
  median_qi() %>%
  ggplot(aes(sample = .residual)) +
  geom_qq() +
  geom_qq_line()
```

##### multicollinearity
```{r}
# Check vif and tolerance
check_collinearity(LPP.treat.model)
```